[{
    "title": "Measurable Technical State of the Team",
    "date": "",
    "description": "",
    "body": "Some initial thoughts on how you could evaluate the state of the systems you could own. Put some of these criteria on the Y axis, and the name of the components you own on the X. Give everything a score from 1 to 0. Figure out which components need the most love.\nBuilds: Consistent Build from Dev -\u0026gt; Prod\n The same image/code used in each step, not built at each step  Blocking tests at each phase\n Unit is a good start, acceptance is better  Canary and/or staged releases to production\n Having an \u0026ldquo;alpha\u0026rdquo; or \u0026ldquo;canary\u0026rdquo; production environment can save you a good deal of heartache  Easy, well understood deployment process\n Can you deploy and roll forward in 1 step? Is it fast?  Code Ownership \u0026amp; Quality What is the level of comfort your team has with the code?\n Has your team built the codebase? Have they maintained it in any meaningful way? Do they own it without knowing it?  Well Factored Code\n If an ax weilding maniac who knew where you lived was the next person to maintain the code you\u0026rsquo;re working on, would you be worried?  Health Quality Score\n Does your company have a way to measure code health? If not, could you use something off the shelf? How many bugs per component exist? Is that number increasing or decreasing?  Fully Owned Code\n Are you in a codebase where you share dependencies or entire sections of your code?  Well Documented Code\n Not commenting per se, but diagrams/drawings/something to help folks understand and dive in  Degrading Gracefully\n Circuit Breakers Rate Limiting Retry-After on 429/503\u0026rsquo;s Can the services you rely on fail and you still return a useful response?  On-Call / Triage Everyone is on-call\n\u0026ldquo;Good\u0026rdquo; Runbooks\n Can you actually fix problems from them?  \u0026ldquo;Good\u0026rdquo; Alerting\n Do the alerts identity the issue and point towards resolution, or the tools to resolve?  Non-Noisy Alerts\n Are your on-calls dreading their shifts because of pages day \u0026amp; night?  Low Incident Rate\nService License Agreement (SLO) for Services\n What is the expected response time? What\u0026rsquo;s your TP50? TP95? TP99? 200 rate? is 4 nines enough? Do you alert when you service doesn\u0026rsquo;t perform as expected?  Code is easy to debug\n Easy to plug in debugger? Error messages that make sense? Can you trace calls from start to finish through your systems? Can you time calls from start to finish through your system?  Testing / Tooling Load Testing Tooling in Place\n Can you determine the maximum # of callers while maintaining your SLO\u0026rsquo;s?  Acceptance Tests\n Can you test end to end your services?  Integration Tests\n Do you have tests that bridge layers of your codebase?  High Test Coverage\n What percentage of your code has unit tests?  Non-Noisy Tests\n Do you have tests that inconsistently fail? You should fix or delete them  Metrics/Monitoring Non-Noisy Logging\nUseful Metrics\n Do you track the big metrics?  Response/Run time 200\u0026rsquo;s or successful operations 500\u0026rsquo;s or failed operations    \u0026ldquo;Good\u0026rdquo; Dashboards\n Can you not only track performance, but the rate at which events happen/don\u0026rsquo;t happen that are relevant?  Useful Logging\n Do you use all the information you\u0026rsquo;re logging?  Roadmaps Is there a technical roadmap for each component?\nIs there a product roadmap for each component?\n",
    "ref": "/blog/20210110-measurable-technical-state-of-the-team/"
  },{
    "title": "The importance of clear communication",
    "date": "",
    "description": "",
    "body": "This is based off a talk I gave on improving communications.\nThere is a lot of communication right now With everyone working remotely, the importance of communication has increased. We\u0026rsquo;re communicating more often without meeting, and making your message clear when everyone is deluged with correspondance is the only way to have impact in your organization.\nTo succeed in any organization, you need to be able to tell your story. Whether it’s a status update, an RFC, or an escal question, you need to be able to quickly tell people the state of the world. It’s how you’re going to convince other people to take action or to answer their questions.\nPeople need structure to their stories. In order to follow a story, either written or spoken, people need to understand how all the given information is related. When you present your story, your audience will look for connections between things you\u0026rsquo;re saying, such as: there must be a reason for that statement; or, this is probably an example of the previous point.\nThis structuring can be a conscious or unconscious process by your audience. People automatically look for structure.\nWithout structure to your communication, your message can get lost Communicating information, whether on a Zoom call or in Slack, well it’s hard. If you don’t present a clearly structured story, your audience will look for their own structure, which can lead to problems.\nYour audience could misunderstand your structure and be unable to understand your story. Because of that, they might lose attention, or they may draw false conclusions. Even if your audience understands your story, without structure they’ll have to work hard to do so.\nIf they’re working hard early, they’ll have less attention later on, or stop reading and listening to you all together.\nTo have your audience fully grasp what you are telling them, you need to structure your story as clearly as possible. This requires you to have a clear view on your own story structure.\nWhat’s an effective way to structure communication? Start your storytelling with a simple structure that works. If you need to convince a analytical audience such as your fellow engineers, turn to Barbara Minto and her Pyramid principle.\nShe has spent decades teaching her pyramid principle. Her framework makes your arguments easy to understand and much more convincing.\nI’ll introduce each element and then we will discuss some examples to make it more concrete.\n Start by outlining the S - the situation. The Situation is the starting point of your story. It is important that your audience can easily understand your story and recognize what you are telling them. This introduces them to your topic and how it relates to their world.\nThe Situation is made up of recognizable and mostly agreed-on points. They describe the state of the world and the topic of your work.\nOf course, this is not a story yet. If you only describe a situation as it is, there’s no reason to act.\nFor example, let’s say you get an alert that an API is taking 500ms to respond. if I tell any of you, “An API is taking 500ms to respond”, without any context, there is no motivation to act. 500ms could be good or bad.\nNext outline the C - the Complication. This is the reason that you’re asking people\u0026rsquo;s attention for your story.\nWhat has changed that’s making things harder? What threats do we face if the Situation carries on as it is now? What opportunities do we miss?\nExplaining this in your Complication will give your story its urgency. Also part of the Complication is: what practical hurdles do we need to overcome to prevent those threats or to realize those opportunities?\nWith the previous example with the API alert, adding the complication might sound like, “An API is taking 500ms to respond, it normally responds in 50ms.”\nIf you sharply define the Complication, the Question follows naturally. It asks how the issues of your Complication can be overcome, so that we can either stop the negative effects or seize an opportunity.\nWhen communicating your story, a commonly agreed on SCQ makes sure that the audience understands what you want to do in your Answer, and also why this is relevant.\nThe question also allows your user to take a breath. Many times the Situation and Complication can be quite long. Phrasing out the question simply reminds the user, after all of the explanation, why they are here.\nUsing our previous example, we might add a question such, “An API is taking 500ms to respond, it normally responds in 50ms. Why is the API so much slower?”\nThe A provides the Answer. It explains what we should do and how we can do it. Your Answer should be explicit in how it will solve the Complication that has been raised.\nA simple SCQA for our alert situation:\nAn API is taking 500ms to respond It normally responds in 50ms. Why is the API so much slower? We are under 10x the normal load. We should scale up the cluster to compensate.\nBreaking down the Answer So that’s the basic structure. Now we’re going to focus on the A - the Answer. It seems to me that most folks have a good grasp on the S \u0026amp; C in their writings. The Q naturally falls out of that. But the A sometimes needs more structure to be effective.\nArguments \u0026amp; Evidence Once you have an answer, you can spend your time offering arguments and evidence for your answer.\nAnd it’s going to make your arguments better. The pyramid makes your answer the focal point of the conversation. This is appealing to analytical folks who have a solutions mindset.\nThe pyramid creates a logical structure. Each level of the pyramid supports the level above it. Evidence supports each argument, and the arguments come together to support the answer. If they don’t, you’ll need to find better arguments.\nFor our alert example, you could provide evidence of the response time over the past 30 days, the db load being normal, no long-running tasks in flight, and the traffic from a certain customer being elevated.\nParing down your Answer The Pyramid requires you to pare out all the unnecessary information. Many presentations, status updates, and RFCs contain a lot of information to show that you did a lot of work. In the Pyramid, if your evidence or arguments don’t directly support your answer, take it out.\nFor our alert adventure, let’s say you did hours of work researching technologies such as Consul, Envoy, and Docker. Some people might put what they learned about these systems in their story to show they did a lot of research, but it doesn’t serve your answer, so take it out.\nThink of your Audience If your audience loves analysis, logic, and reason, tell stories this way.\nHow much do I like SCQA? I structured this post using it.\n",
    "ref": "/blog/20200909-pyramid-principle-inaction/"
  },{
    "title": "1:1's aren't enough in a SIP world",
    "date": "",
    "description": "",
    "body": "Back when we were all the office together, it was pretty easy as a manager to get a feel for how the team was doing. Are folks getting along? Are folks stressed? Does everyone have the right balance of work? With folks all around you, it was pretty easy to drop in on a conversation, take someone to lunch, or grab a coffee and talk.\nThese small encounters gave you a chance to make sure your team was running efficiency, it also gave your team a chance to speak to you as a human being outside of formal settings. Usually that level of shared vunerability led to better, more fulfilling conversations in the following 1:1\u0026rsquo;s.\nWith the traditional office gone, all of the luxurious interactions managers had when we shared physical space are gone. I started a new job 9 days before shelther in place, so I didn\u0026rsquo;t have much time to meet my team to get to know them. I noticed quickly that the level of trust and sharing wasn\u0026rsquo;t where I expected it to be.\nGiven I had none of the in-person tools for building trust with my team that I had developed over the years, I knew I had to be more prescriptive in building trust with my team. So what did I do?\nOvershare (a bit) I\u0026rsquo;m a relatively private person. I don\u0026rsquo;t like to talk about my personal life in group settings. However, to build trust with a group, it helps to show that you trust them and can confide small details about your life with them.\nWould I tell my team that my partner and I had a fight? No. I don\u0026rsquo;t want to overshare or make them uncomfortable.\nHowever, details of my life I normally wouldn\u0026rsquo;t broadcast, I\u0026rsquo;ve shared more in an attempt to be a bit vunerable and build closeness with my team. Things like:\n Whether I\u0026rsquo;ve been sleeping well or not How my dogs are doing How I\u0026rsquo;m dealing with being remote (or not dealing with it)  Some moments of vunerability to allow the team to get to know me, and hopefully feel comfortable enough to be themselves around me as well.\nBe more prescriptive in getting to know them I found with my move to remote working that 1:1\u0026rsquo;s, even once a week, wasn\u0026rsquo;t enough to get to know my team on any appreciable level.\nSo I had to be very prescriptive in my approach. Not only breaking up 1:1\u0026rsquo;s into a format where I could \u0026ldquo;force\u0026rdquo; organic conversation.\nA normal format I\u0026rsquo;ve been following that has worked for me, in a 30 minute 1/1:\n10 min: Personal chit-chat 10 min: Whatever is on their agenda 10 min: Whatever is on my agenda/requesting feedback/etc\nIf you\u0026rsquo;re looking for questions to ask, my co-worker (Cyriel Dikoume)[https://www.linkedin.com/in/cyriel-dikoume/] created this (great site)[https://1on1.fyi/#/] with 1:1 prompts if you ever get stuck with nothing to say or ask.\nMake more time for them When with being prescriptive with your 1:1\u0026rsquo;s, you might find that you still don\u0026rsquo;t have enough time to cover everything you want in your 1:1\u0026rsquo;s, such as career development for instance. If you find this is the case, schedule recurring time to talk about the specific issues that you find are getting short-changed. For me, I have a dedicated time for career development outside of my regular 1:1 time as I felt that wasn\u0026rsquo;t getting the time and attention it deserved.\nSet reminders to yourself One last thing I\u0026rsquo;ve found useful: setting regular reminders to be human with your team. Whether that\u0026rsquo;s thanking them for their work, checking in on their family and friends, or writing birthday cards or work anniversaries, it\u0026rsquo;s nice to take the worry out of remembering to appreciate your team for the great work they\u0026rsquo;re doing.\n",
    "ref": "/blog/20200606-remote-management-lessons-learned/"
  },{
    "title": "Kickoff Docs",
    "date": "",
    "description": "",
    "body": "What is a Project Kickoff?  What is a project kick-off? A project kick-off meeting is the first meeting with the project team and the client of the project where applicable. This meeting is the time to establish common goals and the purpose of the project.\n Taken from the Atlassian Project Kickoff reference.\nWhy a Project Kickoff? A project kickoff sets a clear outline of project goals and milestones.\nIt\u0026rsquo;s a celebration of where you\u0026rsquo;re going as a group. You get your chance to outline what you want to build as a team and why you\u0026rsquo;re doing it. The how isn\u0026rsquo;t important at this step - either from a management or engineering side. You\u0026rsquo;re just trying to let everyone know where you want to end up once the project is complete.\nA kickoff generally will be a forcing function to think about timelines. Have you planned for design? Testing? Customer Sign-off? Quality Assurance? If not, you can always call that out - we\u0026rsquo;ll deliver a finalized timeline and design by XXX date, instead of trying to figure out when you\u0026rsquo;ll deliver before you\u0026rsquo;ve started. If you\u0026rsquo;re not being pushed to deliver by a certain date but instead to deliver certain functionality this can be a great way to go.\nIf you\u0026rsquo;ve already committed to a delivery date, the kickoff can be a great way to acknowledge that we have to find a way to meet the goal in a certain amount of time. It can act as an immediate forcing function to cut functionality you can\u0026rsquo;t afford or won\u0026rsquo;t need.\nFinally, a project kickoff can help your team have something to fall back on when things get unorganized. If someone is unsure what to do at any point, the project kickoff docs can be a greate reference to refocus everyone.\nRoles and Responsibilities In a project kickoff, you should lay who\u0026rsquo;s responsible for various aspects of the project. This is a great opportunity for a manager to try out assigning leadership to folks who haven\u0026rsquo;t been in those positions before. You can break up the responsibilities of the project into many small pieces that you dole out to your entire team so one person is responsible for everything. Some ways I\u0026rsquo;ve broken up responsibilities in the past:\n Product Design Feature Delivery Standups Leadership Team Updates Internal/External Comms Development Code Reviews Tech Specs, Architectural diagrams Tech Spec reviews Backlog maintenance, review Testing (automation, manual) Driving Resolution on technical issues (aka making sure bugs get fixed)  Goals and Outcomes When setting out the goals of your project, you should tie the project into any company wide OKR\u0026rsquo;s you might have. Most likely the project is tied to a key result or results - those should be stated for the team. There shouldn\u0026rsquo;t be any surprises about what the deliverables are.\nAny deadline driven deliverables should also be called out. If you have hard customer commitments those should be highlighted.\nIf you\u0026rsquo;re lucky enough to work on a project with no deadline, you should at least endeavor to provide a rough timeline to give the team your expectations around delivery.\nA rough timeline like this has worked for me:\nDesign, Research done by Late June Development Done by Late July Load Testing by End of July Medium Confidence in shipping by End of Quarter The progress you make over the first 2-4 weeks of an unplanned project will have a compounding effect on the overall project timeline and risk. Make the most of it.\nWorking Together It\u0026rsquo;s good to highlight how everyone is going to work together, and what to do when you\u0026rsquo;re not working together as effectively as you could be. How often do you plan on meeting? Where are you documenting your decisions? How much process do you want to put into place? How will you review if things are going well outside of the deliverables? Where is your backlog of work stored?\nA high level example:\nStaying in Sync * When in doubt, jump on a Zoom * Bring everything back to the development channel * Daily standups * Start with minimal process * Periodic Retros Executing * Iterations (2 weeks) * One planning session per iteration * Jira is the source of truth, everything should be in there Next Steps Once you\u0026rsquo;ve kicked off the project, what are you next steps? What are the actions you need to take now? Finish the kickoff making sure everyone is empowered to act the moment the meeting ends.\n",
    "ref": "/blog/20200404-kickoff-docs/"
  },{
    "title": "Measuring Backlog Health",
    "date": "",
    "description": "",
    "body": "Backlog Grooming Some thoughts on how you could evaluate the state of your backlog.\nSmall, well groomed backlog\n Are the tickets in the backlog going to be actioned in the near term? If you deleted the tickets that aren\u0026rsquo;t in your near-term roadmap, how long would it take you to recreate it? Is the Backlog consistently growing or shrinking? Are the tickets all in a state to be actioned immediately, or do they need additional work?  Ticket \u0026amp; Project Health\n Is the average age of your tickets staying constant? Increasing? Is the average time your tickets staying open consistent? Increasing? How many projects are in progress? Is it less than 1 / person? How many tickets are in progress? Is it less than 1 / person?  ",
    "ref": "/blog/20200101-measuring-backlog-health/"
  },{
    "title": "Pyramid Principle Examples",
    "date": "",
    "description": "",
    "body": "I use SCQA all the time in my communications both up to leadership and down to my teams.\nThis TED talk from Derek Sivers is a great example of someone using SCQA to communicating a problem and a suggested solution in a short amount of time. Worth watching if you\u0026rsquo;re looking to use SCQA in your own communications.\nAnother example of an SCQA structured communication is something I received at work:\nPhishers and scammers are actively targeting employees on LinkedIn and email (work and personal) in hopes of accessing valuable information. Every employee, whether you realize it or not, has insider knowledge - it may be access to financial data, technical resources, customer contacts, intellectual property, customer data, or other resources – and there are people who will try to exploit that. What can you do? Do not click the link, open the attachment, or respond to the sender Forward a copy to phishing@company-corp.com Use the Spam button in GMail If it’s a LinkedIn message, text message, or other non-Company-Corp message that feels suspicious, please report it to security ...Additional Evidence... ",
    "ref": "/blog/20191111-pyramid-principle-examples/"
  },{
    "title": "Further Engineering Management Classes",
    "date": "",
    "description": "Further Engineering Management Classes",
    "body": "Some further classes I recommend for potential new engineering managers.\nhttps://www.harrisonmetal.com/library/objectives-key-results\nSo many companies want to set up goals in the OKR (Objective-Key Result) format. This shows some great examples how to format yours.\nhttps://www.harrisonmetal.com/library/storytelling-amp-presenting-1-thank-you-barbara-minto\nI use SCQA all the time in my communications both up to leadership and down to my teams. Highly recommend taking this class or reading The Pyramid Principle.\nhttps://www.harrisonmetal.com/classes/gm2-setting-goals-measuring-performance\nIf you\u0026rsquo;re a manager, you\u0026rsquo;re going to have to figure out a way to set goals for your teams and measure the performance of those goals. This will help.\nhttps://www.harrisonmetal.com/classes/business-leadership\nA three-day class on how to be a better leader for your group.\nhttps://www.harrisonmetal.com/classes/performance-review-lab\nHow to give great performance reviews (and how you shouldn\u0026rsquo;t be talking about performance once a year).\nhttps://www.eventbrite.com/e/influence-without-authority-online-workshop-registration-125979033681?aff=ebdsoporgprofile\nI had a former colleague say the true measure of someone\u0026rsquo;s effectiveness is not how they manage their direct reports, but how they manage to get their agenda done in the larger organization, and motivate people who don\u0026rsquo;t report to them to work on tasks that are important to them. This class helps with those skills.\n",
    "ref": "/blog/20190607-further-engineering-management-classes/"
  },{
    "title": "Project Planning Notes",
    "date": "",
    "description": "",
    "body": "More Shared Knowledge on Projects  Include more people in code reviews even if they\u0026rsquo;re not actively picking up development tasks \u0026ndash; this shares out knowledge of the changes and gets another set of eyes that can ask good questions Break team silos, share knowledge Do Team PR\u0026rsquo;s for big PR\u0026rsquo;s Do team share of projects for tech projects, share knowledge Team Collab!  Metrics/Monitoring/Data  Implement monitoring and error visibility to make it easier to debug problems down the road. Data driven approach whenever we can to illustrate impact. 🤔 Maybe this can be something we start collection at the beginning and continue through out the project. Data Driven the whole time  highlighting impact   implement monitoring \u0026amp; debugging for every milestone, every deliverable  Testing \u0026amp; Tech Debt  Automated testing early in the process Test Plan/Test Matrix up-front Fix broken windows along the way  broker time for tech debt    Status Update/Communication  Constant, detailed, concise status updates in channel \u0026ndash; this is particularly helpful when rolling new people on because you can say \u0026ldquo;please go back and read the content of the channel for the past week\u0026rdquo; Frequent check-ins/deliverables Customers/Users to consult with along the way highlight risks early and often  Clear Communication of Risks, Early \u0026amp; Often   Roll out plans Disorganization from not knowing what work streams are in progress and who is working on what tasks Clear Status Updates in Channel  Nice for on-boarding new folks   clear comms, high vis  Kickoff \u0026amp; Milestones  Clear Milestones Clear outline of project goals and milestones, this helps us fall back on the main objective when things get unorganized Kick Off!  Celebration, where we\u0026rsquo;re going Outline what we want to build Why we\u0026rsquo;re doing it Is how that important? What you\u0026rsquo;re going to do is not that important   🎉 Continue celebrating small wins! More time to design, review, write tech specs  there is no time to do this   Longer Pre-Planning timeline  We need more time to pre-plan, design, etc   Clear Project Goals \u0026amp; Milestones  when things get disorganized, what to do    Project Task Tracking Doc  Keeping a separate project doc that tracks tasks and stories, it can be a bit of a pain to manage and sometimes is a couple days out of date, but I\u0026rsquo;ve found it very helpful in keeping alignment on the work left to do for a project Project tracking with tickets, i specially like the way Lauren creates them. Breaking down tasks in a document outside of JIRA too much breakdown of tasks? Take into accounts bugs and broken windows you can fix along the way Separate Project Doc  keep track of tasks \u0026amp; stories   Project tracking with tickets Don’t be too fine grained on certain tasks  Things can be rough if clear. You don’t need a page long ticket for a one line change Tech Specs / RFCs   Pre-planning for any project should begin much before the actual work  Getting familiar with code base Setting up environment etc etc   Tech specs or brain storming sessions that involve the entire team in the design process. Create a detailed design doc to iron out the implementation details  no matter how small the feature/project is take them through the appropriate design reviews   RFCs  Full RFC overview right before the official kick-off. could be an engineering focused project where we comb through assumptions and highlight any risks. This might also help with setting original expectations on delivery date    Swarming  Full Team Swarming Single Developers on Projects Attempting to breakdown work or introduce parallelism for projects that were not initially designed that way. Figuring out work that can be done in parallel (planning for multiple developers) Multiple developers on projects Team collaboration is superb. Everyone jumps on board as required. When we try to make parallel when things were not planned to be swarmed  ",
    "ref": "/blog/20190202-project-planning-notes/"
  },{
    "title": "Manager Conference Links",
    "date": "",
    "description": "Manager Manager Conference Links",
    "body": "A couple of EM conferences folks might find useful:\nSFELC Summit\nAn annual celebration for engineering leaders.\nA wide range of topics. One day, multiple tracks. Great speaker lineup. A refresher on management fundamentals. Workshops and Breakouts.\nCalibrate\nYou’re a great engineer. Become a great leader. Calibrate is aimed at practicing engineering managers, responsible for the people on their team.\nYou can find videos of previous years here.\nTEMSCON\nResearch-focused engineering management conference.\n",
    "ref": "/blog/20180115-manager-conference-links/"
  },{
    "title": "ElasticSearch Perf - Highlighter Edition",
    "date": "",
    "description": "Examine sharding and highlighting strategy with ES",
    "body": "Wanted to share the results of the work we\u0026rsquo;ve been doing to improve performance and stabilize our ES cluster.\nShort Version: Changing sharding and \u0026ldquo;highlighting\u0026rdquo; strategies when doing FreeText searches dramatically impacts performance.\nLong Version: We\u0026rsquo;ve been load testing various aspects of search to pinpoint features we use that create large amounts of load on the system. Our initial research pointed at normal searches and freetext searches as being problematic.\nOne of the tests we ran examined \u0026ldquo;highlighting\u0026rdquo; in freetext search. \u0026ldquo;Highlighting\u0026rdquo; is the selection of relevant criteria when you search for words or phrases in a document.\nThe graph below is an illustration of some load testing we did around highlighting. The red squares represent, in order of appearance:\n 5 shards, highlighting freetext results 1 shard, highlighting freetext results 5 shares, no highlighting, freetext results 1 shard, no highlighting, freetext results  Our conclusions from these graphs:\n 5 shards w/ highlighting takes a long time and a lot of resources 1 shard w/o highlighting is fast and doesn\u0026rsquo;t use many resources  In researching highlighting, we found there are different ways to highlight results. We were using the default highlighter - the \u0026ldquo;plain\u0026rdquo; highlighter. There are other highlighters - the \u0026ldquo;unified\u0026rdquo; highlighter, for some example - that along with some index changes, promised significant performance improvements.\nIn this graph, the dots on the left represent the performance of the \u0026ldquo;plain\u0026rdquo; highlighter, while the dots on the right represent the \u0026ldquo;unified\u0026rdquo; highlighter.\nIt appears that a \u0026ldquo;unified\u0026rdquo; highlighter strategy is more performant than our original \u0026ldquo;plain\u0026rdquo; highlighter.\nLate today, we launched a new experiment with three indices:\n Control (5 Shards, \u0026ldquo;plain\u0026rdquo; highlighter) Variant 1 (1 Shard, \u0026ldquo;plain\u0026rdquo; highlighter) Variant 2 (1 Shard, \u0026ldquo;unified\u0026rdquo; highlighter)  Here is a graph of the overall performance of the experiment so far:\nRed line (top): Variant 1. TP95: 1.7 seconds A single sharded strategy with the \u0026ldquo;plain\u0026rdquo; highlighter is much slower, though it consumes less ES resources than the 5 shard strategy.\nOrange line (middle): Control. TP95: 600 ms 5 shards with the \u0026ldquo;plain\u0026rdquo; highlighter responds must faster than a single shard, but it consumes more ES resources to run than the 1 shard strategy.\nBlue line (bottom): Variant 2. TP95: 150 ms A single shard, using the \u0026ldquo;unified\u0026rdquo; highlighter, is much more performant, and uses less system resources, than the other two variants.\n",
    "ref": "/blog/20181121-elasticsearch-perf-work/"
  },{
    "title": "Moment.js alternatives",
    "date": "",
    "description": "Moment.js alternatives",
    "body": "If you\u0026rsquo;re looking for moment.js alternatives, I\u0026rsquo;d recommend reading this article about smaller, lighter-weight moment.js alternatives.\n",
    "ref": "/blog/20180908-moment-js-alternatives/"
  },{
    "title": "Manager READMEs",
    "date": "",
    "description": "Manager READMEs",
    "body": "A friend recently introduced me to the ideas of creating a Manager README.\nThe idea is that for coworkers and new team members, you give a rundown of how you like to work and what they can expect.\nSome of the canonical READMEs that are frequently used as templates can be found here.\nA list of the current READMEs out in the wild (including mine), as well as some links to guides to help write them, can be found here.\nYou can read about my management style here.\n",
    "ref": "/blog/20180601-manager-readme/"
  },{
    "title": "ElasticSearch sharding work",
    "date": "",
    "description": "ElasticSearch sharding work",
    "body": "Wanted to share some insights my team has found with changing sharding strategies for ElasticSearch (ES).\nToday we moved 100% of my work\u0026rsquo;s search and autocomplete queries from a mutli-sharded index to a single-sharded index.\nShort version: Reducing shard count reduces system load, CPU usage, mostly positive results on performance.\nMedium version: In moving 100% of our searches and autocomplete queries from a mutli-sharded index to a single-sharded index, we saw drops in cluster load, queries generated by ES, and overall ES CPU usage.\nWe saw improvements in response time for retrieval and ranking from search.\nAlong with response time drops, we saw a smoothing of response times from search in general.\nAverage query \u0026amp; fetch times increased. While we reduced the total number of queries ES generated, each of those queries and fetches was doing more work.\nWe managed to reduce response from search but autocomplete (which uses the same indice) saw its average response time increase. The response time is now much more stable, and the service performs better under high load. In the graph below, the red line is autocomplete with a single shard, the yellow line is the 5-shard autocomplete response time. As our load increased during the day today, you can see the 5-shard performance steadily decrease while the single shard response remained steady.\n",
    "ref": "/blog/20180305-elasticsearch-sharding-work/"
  },{
    "title": "Engineering Management Classes",
    "date": "",
    "description": "Engineering Management Classes",
    "body": "Two classes I recommend for potential new engineering managers.\nhttps://www.harrisonmetal.com/classes/foundations-general-management\n3 days, great teacher, learn some basic skills to run a small business or team.\nhttps://bradfieldcs.com/courses/leadership/\ntwice a week for a month, great tactical skills for first time engineering managers.\n",
    "ref": "/blog/20171229-engineering-management-classes/"
  },{
    "title": "ElasticSearch Garbage Collection issues?",
    "date": "",
    "description": "Seeing high garbage collection with ElasticSearch?",
    "body": "Seeing high garbage collection with ElasticSearch? My team was seeing periodic 300ms+ garbage collection pauses. We found out that we had misconfigured our ES instances.\nIf you\u0026rsquo;re encountering this, make sure you\u0026rsquo;ve disabled memory swapping:\nhttps://www.elastic.co/guide/en/elasticsearch/reference/5.0/setup-configuration-memory.html\n",
    "ref": "/blog/20170813-elasticsearch-garbage-collection/"
  },{
    "title": "Moment.js instantiation slowness",
    "date": "",
    "description": "Moment.js instantiation slowness",
    "body": "Was doing some test speedup/performance improvement work recently on the search API and found out something; the moment.js library takes around 100 microseconds (or .1 milliseconds) to create a new instance.\nWhy is 100 microseconds a big deal?\nIf you\u0026rsquo;re processing:\n 100 records Where each record has 7 date fields Then you\u0026rsquo;ve created 70,000 microseconds of work Or 70 milliseconds of processing delay.  By doing some memoization of date formatting in our API, we\u0026rsquo;ve seen these performance improvements:\nResponse Times     Before After     Fastest 211ms 194ms   Max 651ms 597ms   Average 309ms 268ms    Without making any significant changes, we\u0026rsquo;ve managed to shave 41ms off of our response time on average!\nHope this helps someone else.\n",
    "ref": "/blog/20170504-moment-js-instantiation-slowness/"
  },{
    "title": "Performance Improvement via node 4 to node 6",
    "date": "",
    "description": "Performance improvement via babel tranpilation removal",
    "body": "My team at work recently upgraded our codebase to use to node 6.9, as node 6 has recently gone to LTS.\nIn the picture below, the 1st line is the upgrade from node 4 to node 6, and the corresponding flattening of memory usage vs. load.\nThe 2nd line is our removal of redis connection queueing in the application.\nAll of all, the memory consumption of our application is now averaging around 150MB, down from a high of 1GB!\nHope this information helps all those teams considering upgrading their node projects.\n",
    "ref": "/blog/20161109-performance-improvement-via-babel-tranpilation-removal/"
  },{
    "title": "Superagent/Request Memory Leaks",
    "date": "",
    "description": "Superagent/Request Memory Leaks",
    "body": "Superagent/Request Memory Leaks The last several weeks Thomas Hunter and myself have spent some of our nights and weekends trying to track down memory leaks in an API we both work on.\nWe were seeing a distinct pattern, that when the API was put under a certain amount of load, that we would start slowly bleeding memory.\nWe\u0026rsquo;ve found three results:\n  Superagent, when put under a certain threshold of load and then connections timeout, can leak memory.\n The PR to fix this issue has been merged: https://github.com/visionmedia/superagent/pull/1084    Request, when put under a certain threshold of load and then connections timeout, can leak memory.\n The PR to fix this issue has been merged: https://github.com/request/request/pull/2420    Superagent, when not explicitly assigned a timeout parameter, can hold connections open and therefore leak memory\n The fix for this is to call req.timeout(YOUR_TIMEOUT_VALUE) to resolve.    The fixes for these issues are all in the latest versions of the libraries\n",
    "ref": "/blog/20161017-superagent-request-memory-leaks/"
  },{
    "title": "Node 4 and Babel 6 in Harmony",
    "date": "",
    "description": "A note for the upgrade from Node 4 and Babel 6",
    "body": "Pun in title intentional I upgraded a heap of projects I was working on to node 4.2.3 and babel 6.\nAs I did a quick and dirty upgrade, I kept thinking to myself: doesn\u0026rsquo;t node 4/5 have pretty good support for es6/2015?\nAs I was looking around the internet for Hello Kitty Formalwear babel 6 upgrade tips, I came across this package which read my mind.\nSo if you\u0026rsquo;re a node 4/5 user, by doing this:\nnpm install --save-dev babel-preset-es2015-node4 Then changing your .babelrc to look something like this:\n{ \u0026quot;presets\u0026quot;: [\u0026quot;es2015-node4\u0026quot;] } you\u0026rsquo;ll get the minimal tranpilation needed to use the latest ES6 features with node 4/5.\n",
    "ref": "/blog/20160116-node-4-and-babel-6/"
  },{
    "title": "Guide to upgrading from Babel 5 = 6",
    "date": "",
    "description": "Guide to upgrading from Babel 5 = 6",
    "body": "Because it\u0026rsquo;s changed since October There have been a bunch of guides on upgrading to babel 5.\nEven those written in the last two months are already out of date. Babel moves annoyingly fast.\nPlease note: this is up to date as of 6.3.13. As I write this, it might also be obsolete.\nSkip babel-core and babel-loader. User babel-register. Due to some complaints about the various ways you could bootstrap babel into an app, there is now babel-register.\nIf you\u0026rsquo;ve held onto using babel 5 until now, porting over couldn\u0026rsquo;t be easier:\nReplace require('babel/register') with require('babel-register').\nAssuming you\u0026rsquo;ve installed the babel-register package.\n.babelrc You\u0026rsquo;ll want to create a .babelrc file to store your babel settings. For most folks, the easiest port from 5 =\u0026gt; 6 looks like this:\n{ \u0026quot;presets\u0026quot;: [\u0026quot;es2015\u0026quot;] } This also assumes you\u0026rsquo;ve installed the babel-preset-es2015 package. This will give you most of the es2015 behavior you had. With caveats.\nExporting and Destructing Objects? Whoops Apparently in ES6 you can\u0026rsquo;t export and then destructure objects.\nWhich means if you have any code that looks like this:\nexport default { a: 1, b: 2, c: 3 } with an import like this:\nimport {a,b,c} from \u0026#39;./terrible-json-object\u0026#39;; you\u0026rsquo;re in a bit of a pickle. You could upgrade your code to ES6 standards, OR you can install babel-plugin-add-module-exports in your codebase, and add the plugin to your .babelrc:\n{ \u0026quot;presets\u0026quot;: [\u0026quot;es2015\u0026quot;], \u0026quot;plugins\u0026quot;: [\u0026quot;add-module-exports\u0026quot;] } This restores the behavior of Babel 5 in this case, which while not strictly ES6 compliant, will at least allow you to upgrade without having to change a ton of code.\nCrisis adverted.\nPLEASE NOTE: Some Babel 5 features are missing from Babel 6 One method I\u0026rsquo;ve found missing is Object.values.\nObject.values is an ES7 stage 3 proposal and is part of Babel 5 but there is no support for this functionality in Babel 6. Yet. Again, this might be out of date as of the writing of this article.\nAs of today this has not appeared in the official Stage 3 plugin from Babel.\n",
    "ref": "/blog/20151231-for-real-upgrade-babel-5-to-6/"
  },{
    "title": "Move your Open Source work to Node 4",
    "date": "",
    "description": "Move your Open Source work to Node 4",
    "body": "Now that Node 4 has been released, isn\u0026rsquo;t it time you upgraded your OS (Open Source) projects to use it?\nStep 1 - package.json If you\u0026rsquo;re not already using it, the engines field in your package.json allows you to specify what version of node you designed your package to run on. The engines field is not strict - you can\u0026rsquo;t force your consumers to use a preferred engine, but you can warn them if your package uses features that aren\u0026rsquo;t available in all version of node.\nMost people won\u0026rsquo;t need to upgrade this to use Node 4, but it\u0026rsquo;s good to be aware of.\n.travis.yml I use travis to build and test my open source projects. To get my OS work running on thew new version of node, I needed to update my .travis.yml files to specify the new version of node.\nThe first part was easy:\nnode_js: - \u0026quot;4\u0026quot; I pushed my travis change, and I was hoping for a big fat green build message. Not so fast. Errors.\nLong story short - to compile native modules in Node 4, you need a C++ compiler. Luckily you can configure travis to use one.\nAdd the following to your .travis.yml files\nenv: - CXX=g++-4.8 addons: apt: sources: - ubuntu-toolchain-r-test packages: - g++-4.8 BOOM!!! Big green build. Hope this helps folks out there.\n",
    "ref": "/blog/20150910-upgrade-travis-and-os-for-node-4/"
  },{
    "title": "The (0, func) operation in transpiled code",
    "date": "",
    "description": "Figuring out JS quirks",
    "body": "Was looking at some decompiled code from ES6 the other day, when I saw a line that looked like this:\nvar x = (0, anObject.aFunc)(params); WTF? I had never seen syntax like this before in JavaScript. Time to dig into the docs.\nParaphrasing from Mozilla and StackOverflow:\n When you write expressions separated by a comma (,) JavaScript evaluates all the expressions in order and returns the value of the last expression.\n Meaning the expression (x=1, y=2, anObject.aFunc) would set the variables x and y, and return anObject.aFunc to the caller.\nNow that we know what is going on, why?\nHere is the explanation I cobbled together from the Interwebs:\n When you call anObject.aFunc(), this is equal to anObject because aFunc is coupled to anObject.\nWhen you call (0, anObject.aFunc)(), you have decoupled aFunc from anObject, so this is no longer equal to anObject in aFunc.\nIn this case, this would be equal to the global object - window in the browser, or global in node.\n So in the example given above:\nvar x = (0, anObject.aFunc)(params); Code that would have the same output (in the browser):\nvar x = anObject.aFunc.call(window, params); Or, even more trivially:\nvar boundToWindow = anObject.aFunc; var x = boundToWindow(params); ",
    "ref": "/blog/20150420-0-func-operator-and-decoupling/"
  },{
    "title": "Replaying changes from one git branch onto another",
    "date": "",
    "description": "Replaying changes from one git branch onto another",
    "body": "Or rebasing without rebasing Where I work, we use git (like everyone else), and we follow this common pattern for development:\n Create a feature branch off of master Work on your feature in the branch When getting ready to submit a Pull Request, squash your commits Rebase master against your branch Open PR Get feedback After feedback corrected (if present), merge branch into master  Pretty standard practice. 99% of the time, this is a frictionless process.\nThe other day I picked up a story which, while small in scope, touched a ton of files.\nThe path to failure I created a branch, did the work, but never squashed my commits - I basically skipped step 3 - and tried to rebase master against my branch. I got the common enemy of every PR - merge conflicts.\nCompounding failure I had 5+ commits in the branch. The idea of wading through multiple failing rebase steps left me queasy, so I abandoned the rebase and went to merge master.\nSo to add to my failure at step 3, now I had skipped step 4 as well.\nAfter getting the code working I pushed my PR. I received some minor feedback, updated my code, and went to merge master again. More merge conflicts.\nI fixed those conflicts, but now I had a convoluted history of un-squashed commits and two merges. This was both out of practice and felt sloppy.\nFinding a solution When you have a messed up git history, you normally do a git rebase --interactive, fix your commit history, and move on.\nBut with the merges scattered between commits, an interactive rebase would be difficult.\nIt also won\u0026rsquo;t give you what you want - a single commit.\nThe solution Enter git symbolic-ref.\nThis command, while well documented, doesn\u0026rsquo;t give away the true beauty of this command.\nHiding on this line is the heart of the command:\n Given two arguments, creates or updates a symbolic ref \u0026lt;name\u0026gt; to point at the given branch .\n What does this do? Let\u0026rsquo;s say you\u0026rsquo;re working on a sloppy branch. You want to carry over those changes onto another branch (like master), without changing the history of the that branch.\ngit symbolic-ref HEAD refs/heads/master sets the state of the current branch onto master. You haven\u0026rsquo;t changed the history - git modifies the files on master to match the state of your branch. The commit history doesn\u0026rsquo;t change. What this means is that doing something like this:\ngit checkout super-sloppy-work-branch //this causes you to 'checkout' master, but with your current file changes from the sloppy branch git symbolic-ref HEAD refs/heads/master git checkout -b new-branch-that-is-great git add -A git commit -m 'I totally did this work in one pass' Will give you a one-commit branch with all the work you did in the sloppy branch, but against the latest version of master. Pretty cool!\n",
    "ref": "/blog/20150216-git-rebasing-without-rebasing/"
  },{
    "title": "Code coverage for CoffeeScript and JavaScript without pre-compiling",
    "date": "",
    "description": "Code coverage for CoffeeScript and JavaScript using gulp and istanbul without pre-compiling",
    "body": "If you\u0026rsquo;re not aware of your code coverage when building a serious application, you\u0026rsquo;re not building a serious app.\nSo I love istanbul and gulp-istanbul.\nOne problem - you have to compile your CoffeeScript, then point you tests at the compiled assets to get coverage metrics.\nNot anymore. Introducing gulp-coffee-istanbul. This allows in place CoffeeScript test coverage.\nHave tests in coffee? Great. Have tests in JS? Great too. Same with your dependencies - it\u0026rsquo;ll take both, in place, and run coverage.\nA quick and dirty example:\nistanbul = require(\u0026#39;gulp-coffee-istanbul\u0026#39;) # We\u0026#39;ll use mocha here, but any test framework will work mocha = require(\u0026#39;gulp-mocha\u0026#39;) jsFiles = [\u0026#39;config/**/*.js\u0026#39;, \u0026#39;controllers/**/*.js\u0026#39;, \u0026#39;models/**/*.js\u0026#39;, \u0026#39;app.js\u0026#39;] specFiles = [\u0026#39;spec/**/*.coffee\u0026#39;] coffeeFiles = [\u0026#39;src/**/*.coffee\u0026#39;] gulp.task \u0026#39;test\u0026#39;, -\u0026gt; gulp.src jsFiles.concat(coffeeFiles) .pipe istanbul({includeUntested: true}) # Covering files  .pipe istanbul.hookRequire() .on \u0026#39;finish\u0026#39;, -\u0026gt; gulp.src specFiles .pipe mocha reporter: \u0026#39;spec\u0026#39; .pipe istanbul.writeReports() # Creating the reports after tests run Which will give you\nNotice that both coffee and js files are shown in the output.\n",
    "ref": "/blog/20141204-gulp-coffee-istanbul/"
  },{
    "title": "It took pivotal 3 years to close a pull request",
    "date": "",
    "description": "jasmine-node, beforeAll & afterAll",
    "body": "On Feb 9, 2011, Fat (Jacob Thornton, one of the creators on Bootstrap) opened a pull request to add beforeAll and afterAll statements to the jasmine library.\nPivotal, at the time, thought that they were just about to implement:\nThat tweet was from December 2010.\nSince then, a couple people have come up with workarounds.\nAnd now, over three years later, pivotal is about to release beforeAll/afterAll.\nYou can check out the work here.\n",
    "ref": "/blog/20141013-jasmine-node-before-all-after-all/"
  },{
    "title": "express-coffee-react-views",
    "date": "",
    "description": "Express View Engine for Rendering JSX Components written in CoffeeScript",
    "body": "This is an Express view engine which renders React components written in CoffeeScript on the server. It renders static markup and does not support mounting those views on the client.\nThis was derived from express-react-views\nThis is intended to be used as a replacement for existing server-side view solutions, like jade, ejs, or handlebars.\nUsage npm install express-coffee-react-views react Note: You must explicitly install react as a dependency. react is a peer dependency here. This is to avoid issues that may come when using incompatible versions.\nAdd it to your app. # app.coffee  app = express() app.set \u0026#39;view engine\u0026#39;, \u0026#39;cjsx\u0026#39; app.engine \u0026#39;cjsx\u0026#39;, require(\u0026#39;express-coffee-react-views\u0026#39;).createEngine() Options You can pass options in when creating your engine.\n   option values default     extension any file extension with leading . \u0026quot;.cjsx\u0026quot;   doctype any string that can be used as a doctype, this will be prepended to your document \u0026quot;\u0026lt;!DOCTYPE html\u0026gt;\u0026quot;   beautify true: beautify markup before outputting (note, this can affect rendering due to additional whitespace) false    The defaults are sane, but just in case you want to change something, here\u0026rsquo;s how it would look:\noptions = extension: \u0026#39;.csx\u0026#39; app.engine \u0026#39;cjsx\u0026#39;, require(\u0026#39;express-coffee-react-views\u0026#39;).createEngine options Views Your views should be node modules that export a React component. Let\u0026rsquo;s assume you have this file in views/index.cjsx:\n/** @cjsx React.DOM */ HelloMessage = React.createClass render: -\u0026gt; \u0026lt;div\u0026gt;Hello {this.props.name}\u0026lt;/div\u0026gt; module.exports = HelloMessage Routes Your routes would look identical to the default routes Express gives you out of the box.\n# app.coffee  app.get \u0026#39;/\u0026#39;, require(\u0026#39;./routes\u0026#39;).index # routes/index.coffee  exports.index = (req, res) -\u0026gt; res.render \u0026#39;index\u0026#39;, { name: \u0026#39;John\u0026#39; } That\u0026rsquo;s it! Layouts follow really naturally from the idea of composition.\nLayouts Simply pass the relevant props to a layout component.\nviews/layouts/default.cjsx:\n/** @cjsx React.DOM */ DefaultLayout = React.createClass render: -\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;{this.props.title}\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt;{this.props.children}\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; module.exports = DefaultLayout views/index.cjsx:\n/** @cjsx React.DOM */ DefaultLayout = require \u0026#39;./layouts/default\u0026#39; HelloMessage = React.createClass render: -\u0026gt; \u0026lt;DefaultLayout title={this.props.title}\u0026gt; \u0026lt;div\u0026gt;Hello {this.props.name}\u0026lt;/div\u0026gt; \u0026lt;/DefaultLayout\u0026gt; module.exports = HelloMessage Questions What about partials \u0026amp; includes? These ideas don\u0026rsquo;t really apply. But since they are familiar ideas to people coming from more traditional \u0026ldquo;templating\u0026rdquo; solutions, let\u0026rsquo;s address it. Most of these can be solved by packaging up another component that encapsulates that piece of functionality.\nWhat about view helpers? I know you\u0026rsquo;re used to registering helpers with your view helper (hbs.registerHelper('something', ...))) and operating on strings. But you don\u0026rsquo;t need to do that here.\n Many helpers can be turned into components. Then you can just require and use them in your view. You have access to everything else in CoffeeScript. If you want to do some date formatting, you can require('moment') and use directly in your view. You can bundle up other helpers as you please.  Where does my data come from? All \u0026ldquo;locals\u0026rdquo; are exposed to your view in this.props. These should work identically to other view engines.\nUsing this.props follows the pattern of passing data into a React component, which is why we do it that way.\nRemember, as with other engines, rendering is synchronous. If you have database access or other async operations, they should be done in your routes.\nCaveats  I\u0026rsquo;m saying it again to avoid confusion: this does not do anything with React in the browser. This is only a solution for server-side rendering. This uses require to access your views. This means that the plugin caches the contents for the lifetime of the server process. You need to restart your server when making changes to your views. In development, we clear your view files from the cache so you can refresh your browser to see changes. React \u0026amp; JSX have their own rendering caveats. For example, inline \u0026lt;script\u0026gt;s and \u0026lt;style\u0026gt;s will need to use dangerouslySetInnerHTML={{__html: 'script content'}}.  \u0026lt;script dangerouslySetInnerHTML={{__html: \u0026#34;\u0026#34;\u0026#34; # google analtyics # is a common use \u0026#34;\u0026#34;\u0026#34;}} /\u0026gt;  It\u0026rsquo;s not possible to specify a doctype in JSX. You can override the default HTML5 doctype in the options.  ",
    "ref": "/blog/20141008-express-coffee-react-views/"
  },{
    "title": "React and the annoyances of JSX",
    "date": "",
    "description": "React and JSX. class vs className, for vs htmlFor",
    "body": "I\u0026rsquo;ve been writing a bunch of React code and a heap of JSX at work.\nReact (coupled with Flux) has been a joy to work with. The uni-directional data flow makes understanding the state of your application at any point easy to understand. The gradual componentization of our UI codebase is a beautiful thing to witness. That, coupled with a component based CSS system (using BEM guidelines for naming classes) has removed the messy bleed over we were having with some of our old css code.\nOne thing that has consistently annoyed my team has been JSX. Basically, we wish we had something like handlebars that React could use on top of its virtual DOM.\n(And yes, we know about Ractive.js. If there was better community support for it, we\u0026rsquo;d probably be using it).\nWhat is annoying us?\n You can write template code ANYWHERE.  We found some places where we had five different methods in one component that contained JSX. Maybe that\u0026rsquo;s just development, but because JSX is just JavaScript, and you can use JavaScript in your JSX, the reverse is also true. You can hide markup anywhere in your components you feel like it.\nIt\u0026rsquo;s just close enough to HTML to annoy you.  This should be a minor annoyance. But when you\u0026rsquo;re copying between HTML and React on a massive rewrite of a legacy system, it becomes painful.\nHow is this a problem? I take the markup for an existing component. I copy the markup into React, convert over some fields, get everything working, and then I open up my browser console to get waylaid with tons of React warnings. About what? About my using \u0026ldquo;for\u0026rdquo; or \u0026ldquo;class\u0026rdquo; attributes in my markup.\nThese are valid HTML attributes, but in React, you have to use \u0026ldquo;htmlFor\u0026rdquo; and \u0026ldquo;className\u0026rdquo; respectively.\nWhy? Because Facebook hates you and decides against logical arguments.\nApparently at some point, you could at least use \u0026ldquo;class\u0026rdquo; in your JSX. But at some point the executive decision was made that because JSX is JavaScript, you shouldn\u0026rsquo;t be able to use reserved words in JSX (like \u0026ldquo;class\u0026rdquo; and \u0026ldquo;for\u0026rdquo;). Even though JSX gets interpolated into JavaScript. And it\u0026rsquo;s got angle brackets. And it almost identically resembles HTML.\n",
    "ref": "/blog/20140909-react-jsx-class-classname-for-htmlfor/"
  },{
    "title": "Ember.Data Model Issues",
    "date": "",
    "description": "Ember.Data Model Issues",
    "body": "I was working with some older Ember.Data code, and I came across a model like this:\nApp.MyFancyModel = DS.Model.extend({ isSelected: false, isSomethingElse: DS.attr(\u0026#39;boolean\u0026#39;, {defaultValue: false}) }); I thought this code was a bit strange, and then went and played with it a bit:\naFancyModel.get(\u0026#39;isSelected\u0026#39;); //returns false aFancyModel.set(\u0026#39;isSelected\u0026#39;, true); aFancyModel.get(\u0026#39;isSelected\u0026#39;); //returns true aFancyModel.get(\u0026#39;isSomethingElse\u0026#39;); //returns false aFancyModel.set(\u0026#39;isSomethingElse\u0026#39;, true); aFancyModel.get(\u0026#39;isSomethingElse\u0026#39;); //returns true I got identical behavior from the two properties. Then, I tried this:\naFancyModel.set(\u0026#39;isSelected\u0026#39;, true); aFancyModel.get(\u0026#39;isDirty\u0026#39;); //RETURNS FALSE aFancyModel.set(\u0026#39;isSomethingElse\u0026#39;, true); aFancyModel.get(\u0026#39;isDirty\u0026#39;); //RETURNS TRUE!!! My question was this: was this the expected behavior? I can\u0026rsquo;t find any documentation on setting boolean values directly on the model like this anywhere in the Ember.Data docs.\nAfter asking around on discuss.emberjs.com, I got an answer.\nThis behavior is by design. Fields designated with just a variable (e.g. isSelected) are local attributes. You can use them just like an other attribute.\nThe difference with fields declared this way is they won\u0026rsquo;t dirty the model and they aren\u0026rsquo;t sent across the wire on save or update.\n",
    "ref": "/blog/20140708-ember-data-model-issue-boolean/"
  },{
    "title": "Ember.Data Promise-Aware Properties (Cheaters Edition)",
    "date": "",
    "description": "Ember.Data Promise-Aware Properties (Cheaters Edition)",
    "body": "I have models like this:\nModels App.Child = DS.Model.extend({ parent: DS.belongsTo(\u0026#39;parent\u0026#39;, {async: true}) }); App.Parent = DS.Model.extend({ children: DS.hasMany(\u0026#39;child\u0026#39;, {async: true}) }); App.Nursery = DS.Model.extend({ children: DS.hasMany(\u0026#39;child\u0026#39;) }); Then a controller like this:\n###Controller\nApp.NurseryController = Ember.Controller.extend({ uniqueParents = function() { return this.get(\u0026#39;children\u0026#39;).mapBy(\u0026#39;parent\u0026#39;).uniq(); }.property(\u0026#39;children\u0026#39;), somethingLikeReliesOnUniqueParents = function() { .... }.property(\u0026#39;uniqueParents\u0026#39;) } The Problem The property somethingLikeReliesOnUniqueParents was never getting unique values. I found two problems here:\n uniq() couldn\u0026rsquo;t figure out uniqueness - much like the problems with filter. The parents promises, once they resolved, weren\u0026rsquo;t updating properties that relied on them.  The first problem I solved the same way I solved in the filter case - filter uniqueness by id, not by object.\nThe second problem I found a somewhat hacky workaround. All promises in the system have a isFulfilled flag. Setting the properties to observe that field allowed the properties to update.\nThe Solution My code ended up looking like this:\n###Controller\nApp.NurseryController = Ember.Controller.extend({ uniqueParents = function() { return this.get(\u0026#39;children\u0026#39;).mapBy(\u0026#39;parent\u0026#39;).uniq(function(parent) { return parent.get(\u0026#39;id\u0026#39;); }); }.property(\u0026#39;children\u0026#39;), somethingLikeReliesOnUniqueParents = function() { .... }.property(\u0026#39;uniqueParents.@each.isFulfilled\u0026#39;) } This solved the issue and still allowed the async behavior I was looking for.\n",
    "ref": "/blog/20140711-ember-data-promise-aware-properties/"
  },{
    "title": "Stuff to mind when writing ES6 code",
    "date": "",
    "description": "Stuff to mind when writing ES6 code",
    "body": "These are some good tips I picked up browsing the ember and ember.data commits. Nice if you\u0026rsquo;re looking for best practices in writing ES6 code.\nexample: diverging bindings\nthis is an issue when dealing with cycles.\nbad: (diverges bindings)\nimport { foo } from \u0026#39;bar\u0026#39;; var otherFoo = foo; foo: (if the rename is actually needed) good:\nimport { foo as otherFoo } from \u0026#39;bar\u0026#39;; example: closure compiler dead code remove friendly:\nbad: closure compile wont drop, bar if foo is used, or foo if bar is used\nexport default { foo: function() { }, bar: function() { } } good: closure compile will drop whats not used correctly.\nexport function foo() { } export function bar() { } Some other interesting tidbits (not sure of the validity of all of these, but this is what some of the Ember guys claim):\n re-using argument variables makes it quite hard to see the original value re-using argument variables has some negative performance side-effects. using the comma operator for long variable declarations makes it impossible to easily set breakpoints.  ",
    "ref": "/blog/20140701-stuff-to-mind-es6/"
  },{
    "title": "Post about Songbird on npmawesome",
    "date": "",
    "description": "Post about Songbird on npmawesome",
    "body": "The folks at npmawesome wrote a blog post about the Songbird library I wrote.\nSongbird is a library that mixes in promise helpers in the Function and Object prototypes on JavaScript. This is a technique that not everybody loves, and I think the author made a great observation about Songbird (and this technique in general).\n While I think it\u0026rsquo;s a great idea to mix in the promise property to Object and Function, however with great power comes great responsibility. I strongly urge against using songbird in modules that you would distribute on npm because it would have a very big side effect on anyone who dares to install your code. However, when used on a project that isn\u0026rsquo;t made available publicly, songbird would be a great asset.\n Check out the blog post here.\n",
    "ref": "/blog/20140626-post-about-songbird-on-npmawesome/"
  },{
    "title": "WriteGooder for Sublime Text",
    "date": "",
    "description": "WriteGooder for Sublime Text",
    "body": "Simple grammar checking for your documentation.\nPrerequisites: write-gooder and Sublime Package Control\nMac OS X: Installing node with homebrew or macports is assumed. The path to write-gooder is hardcoded in this plugin as /usr/local/share/npm/bin:/usr/local/bin:/opt/local/bin. You can change the path to the executable in settings.\nLinux: Make sure write-gooder is in your environment path.\nWindows: Installing node with the Windows Installer from nodejs.org is assumed.\n##Install write-gooder with npm\nnpm install -g duereg/write-gooder\n##Install WriteGooder with Package Control in Sublime Text\n command-shift-P or control-shift-P in Linux/Windows* type install p, select Package Control: Install Package type WriteGooder, select WriteGooder  Note: Without Sublime Package Control, you could manually copy this project to your Packages directory as \u0026lsquo;WriteGooder\u0026rsquo;.\n##Run WriteGooder on an active Markdown file in Sublime Text\n control-shift-W or Tools/Contextual menus or the Command Palette F4 jump to next error row/column shift-F4 jump to previous error row-column  ",
    "ref": "/blog/20140622-sublime-text-write-gooder/"
  },{
    "title": "Ember Model.isDirty - or not",
    "date": "",
    "description": "Ember Model.isDirty - or not",
    "body": "In Ember, if you have models like this:\nvar Tag = DS.Model.extend({ name: DS.attr(\u0026#39;string\u0026#39;), person: DS.belongsTo(\u0026#39;person\u0026#39;) }); var Person = DS.Model.extend({ name: DS.attr(\u0026#39;string\u0026#39;), tags: DS.hasMany(\u0026#39;tag\u0026#39;) }); Then did something like this:\nvar tag1 = this.store.find(\u0026#39;tag\u0026#39;, 1); tag1.get(\u0026#39;isDirty\u0026#39;); //returns false tag1.get(\u0026#39;name\u0026#39;); //return null tag1.set(\u0026#39;name\u0026#39;, \u0026#39;foo\u0026#39;); tag1.get(\u0026#39;isDirty\u0026#39;); //returns true That would be the obvious outcome, right?\nHowever, if you do this:\nvar tag1 = this.store.find(\u0026#39;tag\u0026#39;, 1); var thatGuy = this.store.find(\u0026#39;person\u0026#39;, 1); tag1.get(\u0026#39;isDirty\u0026#39;); //returns false tag.get(\u0026#39;person\u0026#39;); //returns null tag1.set(\u0026#39;person\u0026#39;, thatGuy); //set person on tag tag1.get(\u0026#39;isDirty\u0026#39;); //returns false Because Ember does not check relationships when figuring out isDirty.\nHere is the issue on github\nHere is a solution proposed by someone else (that I do not think solves the problem)\n",
    "ref": "/blog/20140605-ember-model-isdirty-or-not/"
  },{
    "title": "Ember Data Contributions",
    "date": "",
    "description": "Ember Data Contributions",
    "body": "My contributions to Ember.Data!\nHad three pull requests accepted in the last couple of days.\nNow only if they\u0026rsquo;d release version 1.0 \u0026hellip;\n",
    "ref": "/blog/20140518-ember-data-contributor/"
  },{
    "title": "Ember Official Contributor!",
    "date": "",
    "description": "Ember Official Contributor!",
    "body": "Check Out My Contribution to Ember!\n(Not sexy but I\u0026rsquo;m happy to be helping out.)\n",
    "ref": "/blog/20140505-ember-official-contributor/"
  },{
    "title": "Ember FilterBy Fun",
    "date": "",
    "description": "Ember FilterBy Fun",
    "body": "If you happen to be writing filterBy statements in Ember against an object, you will want to use this syntax:\nskusForStyle: function(style) { return this.get(\u0026#39;mergedSkus\u0026#39;).filterBy(\u0026#39;style.id\u0026#39;, style.get(\u0026#39;id\u0026#39;)); } Instead of this similar looking but exceptionally evil and non-functioning cousin:\nskusForStyle: function(style) { return this.get(\u0026#39;mergedSkus\u0026#39;).filterBy(\u0026#39;style\u0026#39;, style); } ",
    "ref": "/blog/20140429-ember-filterby-fun/"
  },{
    "title": "Ember - Test Teardown Error",
    "date": "",
    "description": "Ember - Test Teardown Error",
    "body": "Cannot read property \u0026lsquo;addObject\u0026rsquo; of null If you see the following error in Ember.Data 1.0.0-beta.7:\nCannot read property 'addObject' of null TypeError: Cannot read property 'addObject' of null at Ember.ArrayProxy.extend.addRecord at Ember.Object.extend.updateRecordArray at null.\u0026lt;anonymous\u0026gt; I found this had to do with Test teardown. A monkey patch that solves the issue:\nDS.RecordArray.reopen({ addRecord: function(record) { var thing = Ember.get(this, \u0026#39;content\u0026#39;); if(thing) { this._super(record); } } }); ",
    "ref": "/blog/20140410-ember-test-teardown-errors/"
  },{
    "title": "Ember - The content property of DS.PromiseArray should be set before modifying it",
    "date": "",
    "description": "Ember - The content property of DS.PromiseArray should be set before modifying it",
    "body": "The content property of DS.PromiseArray should be set before modifying it If you see the following error in Ember.Data 1.0.0-beta.7:\nThe content property of DS.PromiseArray should be set before modifying it\nThe issue is with changing the contents of an async field.\n//program.js Program = DS.Model.extend({ styles: DS.hasMany(\u0026#39;style\u0026#39;, {async: true}), }); Style = DS.Model.extend({}); and then used like so:\nprogram.get(\u0026#39;styles\u0026#39;).pushObject(style); That code will throw the exception listed above. To work around this behavior, do the following:\nprogram.get(\u0026#39;styles\u0026#39;).then(function(styles){ styles.pushObject(style); }); A gist talking about the issue is here.\n",
    "ref": "/blog/20140408-ember-the-content-property-of-ds-promise-array/"
  },{
    "title": "Ember vs Knockout - Property Comparison",
    "date": "",
    "description": "Ember vs Knockout - Property Comparison",
    "body": "A small, appropriate comparison At ModCloth, I\u0026rsquo;ve been working on an internal application that uses Ember.js as its front end framework. In learning Ember I\u0026rsquo;ve noticed some interesting architectural decisions they\u0026rsquo;ve made.\nThis article will concentrate on their Observable Models in comparison with how Knockout built the same functionality.\nTANGENT\nEmber.js and Knockout are great contrasts in the library vs framework debate in JS development.\nEmber is\n A framework for creating ambitious web applications.\n (emphasis is mine).\nKnockout is a library whose goal is to\n Simplify dynamic JavaScript UIs with the Model-View-View Model (MVVM) pattern.\n Ember is outspoken and proud of its framework status. Knockout makes it clear that it is a small library for building dynamic JavaScript UIs.\nEmber, while a year younger than Knockout, has SIX TIMES as many commits as Knockout. It\u0026rsquo;s also 4 times the size (71kb vs 17kb, once minified and gzipped).\n/TANGENT\nRead-only computed properties Ember firstName: null, lastName: null, fullName: function() { return this.get(\u0026#39;firstName\u0026#39;) + \u0026#39; \u0026#39; + this.get(\u0026#39;lastName\u0026#39;); }.property(\u0026#39;firstName\u0026#39;, \u0026#39;lastName\u0026#39;) Knockout this.firstName = ko.observable(\u0026#39;Bob\u0026#39;); this.lastName = ko.observable(\u0026#39;Smith\u0026#39;); this.fullName = ko.computed(function() { return this.firstName() + \u0026#39; \u0026#39; + this.lastName(); }, this); The differences here are trivial. Ember doesn\u0026rsquo;t need you to tell it what properties to observe (all properties added to your models are observed). Ember uses getters and setters for each property.\nKnockout asks you to state which properties you want to observe. Knockout then uses a named observable function instead of getters and setter.\nRead/write computed properties Ember firstName: null, lastName: null, fullName: function(key, value) { // setter  if (arguments.length \u0026gt; 1) { var nameParts = value.split(/\\s+/); this.set(\u0026#39;firstName\u0026#39;, nameParts[0]); this.set(\u0026#39;lastName\u0026#39;, nameParts[1]); } // getter  return this.get(\u0026#39;firstName\u0026#39;) + \u0026#39; \u0026#39; + this.get(\u0026#39;lastName\u0026#39;); }.property(\u0026#39;firstName\u0026#39;, \u0026#39;lastName\u0026#39;) Knockout this.firstName = ko.observable(\u0026#39;Planet\u0026#39;); this.lastName = ko.observable(\u0026#39;Earth\u0026#39;); this.fullName = ko.computed({ read: function () { return this.firstName() + \u0026#34; \u0026#34; + this.lastName(); }, write: function (value) { var lastSpacePos = value.lastIndexOf(\u0026#34; \u0026#34;); if (lastSpacePos \u0026gt; 0) { // Ignore values with no space character  this.firstName(value.substring(0, lastSpacePos)); // Update \u0026#34;firstName\u0026#34;  this.lastName(value.substring(lastSpacePos + 1)); // Update \u0026#34;lastName\u0026#34;  } }, owner: this }); I think this scenario shows where Knockout really shine. I find the Knockout code easily readable. The fact that the Ember code needs comments to explain what part of the code is the setter vs getter is damning.\nAlso, the fact that the Ember code has to explicitly call out what properties it is watching is frustrating as well.\nForcing a Property to Recompute Every Time its Called Knockout myViewModel.fullName = ko.computed(function() { return myViewModel.firstName() + \u0026#34; \u0026#34; + myViewModel.lastName(); }).extend({ notify: \u0026#39;always\u0026#39; }); Ember fullName: function() { return this.get(\u0026#39;firstName\u0026#39;) + \u0026#39; \u0026#39; + this.get(\u0026#39;lastName\u0026#39;); }.property(\u0026#39;firstName\u0026#39;, \u0026#39;lastName\u0026#39;).volatile() I think Ember gets the node here for the chainable extension method. Knockout\u0026rsquo;s choice of passing in a extended configuration, while readable, seems a bit clunky to me.\nConclusion The biggest difference I see in the two frameworks in regards to Observable Models is the need of Ember to register property dependencies. This seems like a huge drawback to me - what if you change your code and forget to update the dependencies? Or what if you have a typo in writing in the dependencies?\nSince Knockout existed before Ember, it makes me wonder why the Ember creators didn\u0026rsquo;t incorporate Knockout into their framework.\nSolving a problem again after it\u0026rsquo;s been solved by someone else reminds me of this famous XKCD cartoon:\n##Side Note - How does Knockout get away without explicitly defining dependencies?\nKnockout\u0026rsquo;s Algorithm for Dependency Tracking It’s actually very simple and rather lovely. The tracking algorithm goes like this:\n  Whenever you declare a computed observable, KO immediately invokes its evaluator function to get its initial value. While your evaluator function is running, KO keeps a log of any observables (or computed observables) that your evaluator reads the value of. When your evaluator finishes, KO sets up subscriptions to each of the observables (or computed observables) that you\u0026rsquo;ve touched. The subscription callback is set to cause your evaluator to run again, looping the whole process back to step 1 (disposing of any old subscriptions that no longer apply). KO notifies any subscribers about the new value of your computed observable.   ",
    "ref": "/blog/20140320-ember-vs-knockout-property-comparison/"
  },{
    "title": "New Blog!",
    "date": "",
    "description": "New Blog!",
    "body": "I\u0026rsquo;ve just ended a very long relationship that was hideously overdue for some closure. That\u0026rsquo;s right - I\u0026rsquo;ve left wordpress.\nIt\u0026rsquo;s a great platform if you can\u0026rsquo;t make a website or just don\u0026rsquo;t care about the details. But it\u0026rsquo;s a little less than I was looking for.\nSo I\u0026rsquo;ve decided to get minorly techy and build a nice static site to hold all my blog entries. A thousand thanks goes to @dreikanter for writing a simple converter of the wordpress XML format to markdown.\nThis site is so cool! It\u0026rsquo;s powered by a heap of great tech:\n Docpad to serve my posts CoffeeScript whenever I need to write code Twitter Bootstrap for easy styling and reactive handling Markdown for easy blog writing Eco for cool templating Less and Stylus for my css  The only thing I couldn\u0026rsquo;t take with me - all the old comments. I\u0026rsquo;ve tried to go back and edit the old entries where the comments where useful.\n",
    "ref": "/blog/20140112-new-blog/"
  },{
    "title": "A/B Testing and Random Selection",
    "date": "",
    "description": "A/B Testing or Random Selection in the browser and on the server",
    "body": "Are you looking for an A/B framework? Something you can use in the browser to toggle a user experience - do they see marketing promotion #1, or a picture of a cat?\nOr are you interested in random selection - you want to send our 5000 emails of differing types, and see how users respond?\nEither way, enter laboratory. A simple framework that allows random selection or A/B testing. With the added bonus of being usable anywhere you can load JavaScript.\nAn example for random selection:\nlaboratory = new Laboratory() laboratory.addExperiment(\u0026#34;FuzzyBunnies\u0026#34;) .variant \u0026#34;variant0\u0026#34;, 50, name: \u0026#34;Peter Rabbit\u0026#34; type: \u0026#34;Wooly\u0026#34; .variant \u0026#34;variant1\u0026#34;, 50, subject: \u0026#34;Briar Rabbit\u0026#34; type: \u0026#34;Silky\u0026#34; experiment = laboratory.run(\u0026#34;FuzzyBunnies\u0026#34;) experiment.value # Either Peter or Briar Rabbit In this example, the user would get either Peter or Briar. If you ran the experiment again you\u0026rsquo;d get another set of random values irregardless of the user.\nTo use the A/B features you need to provide laboratory with some kind of storage mechanism to store the selected options for the user. On the client side, we usually use a thin wrapper over localStore.\nYour storage needs to implement two methods:\nclass Store # stores the experiment results (as the variant name selected) for this user  addResult: (experimentName, variantName) -\u0026gt; {} # retrieves a variant result if the user has already seen this experiment  get: (experimentName) -\u0026gt; {} If you want to give the user the same experiment every time they come to your site simply pass in your storage to the laboratory when you declare it.\nlaboratory = new Laboratory(new Store()) ",
    "ref": "/blog/20131211-a-b-testing-and-random-selection/"
  },{
    "title": "Instrumenting Backbone for better error handling",
    "date": "",
    "description": "Instrumenting Backbone for better error handling",
    "body": "At work we\u0026rsquo;ve been having some issues tracking down some nasty client side bugs. We know they\u0026rsquo;re happening in our Backbone views, but we\u0026rsquo;ve been unable to locate them with any accuracy due to the errors bubbling all the way to the window.onerror handler.\nEnter Stackbone. A simple bit of code to instrument Backbone’s event loops to better locate client side errors.\nTo use:\nStackbone.start({ Backbone: Backbone jQuery: jQuery onError: function (err) { // ... log the error ...  } }); You can either Stackbone = require(‘stackbone’) or simply include the .js file in a script tag.\nEnjoy!\n",
    "ref": "/blog/20131127-instrumenting-backbone-for-better-error-handling/"
  },{
    "title": "Source maps in node.js",
    "date": "",
    "description": "Source maps in node.js",
    "body": "One of the projects I\u0026rsquo;m working on deals with source maps.\nIf you don\u0026rsquo;t know anything about source maps this link is a good introduction to what source maps are and why they\u0026rsquo;re useful.\nLooking at the article date (March 21st, 2012), it\u0026rsquo;s not like source maps are some new hot thing. But the tooling around them is still pretty raw as is their use.\nSo why would you want to use source maps?\n Source maps are great for client side development. You can minify/mangle your code, use it in dev, and still debug. Faster dev environments while still being able to debug. Source maps can give you decent stack traces in your production environment without hurting your site\u0026rsquo;s performance. And without exposing any of your unminified source code to the end user.  Read that last point again. This is the killer feature we were looking for at work - being able to track down client side errors reliably on production.\nTo do this you have to jump through a few hoops. At least in a node.js environment.\nThe three ways to use source maps There are three ways you can include source maps in your project.\n You can imbed the source map directly in a .js file. You can add a comment to the .js to that points to the appropraite source map. You can set a header in the response for the .js file that points the browser to a source map.  If you use Browserify you can turn on option 1 just by setting debug: true in your configuration. You\u0026rsquo;ll probably notice the performance degradation almost immediately. That\u0026rsquo;s because browserify includes your source map (with includes all your source) along with the combined .js you\u0026rsquo;re given it. Which is a pretty huge payload compared to just .js.\nMaking source maps work in development If you strip out that source map from the .js file and move the code to an external .map file you still have the ability to debug your browserify-ied code without hurting your performance.\nBrowsers only download external source maps (source maps included via option 2 or 3) when they are needed. So even in development your app will load quickly if you have external source maps. Once you open your debugger in the browser then you\u0026rsquo;ll go and download the source maps you need to debug the current page.\nMaking source maps work in production However, the source maps you generate for development aren\u0026rsquo;t appropriate for production. Why? Two reasons.\n All of your source code is available for download from the source map. The .js browserify generates in debug mode is unminified.  Even if you want to use source maps in production you wouldn\u0026rsquo;t want to push unminified code up. You also don\u0026rsquo;t want to expose your source code to the public. Luckily there is a solution: UglifyJS.\nSo Uglify (or more correctly Uglify 2) can take your unminified code and minify for you. If given a source map as input it can rewrite the source map to now point at the minified file. Pretty good.\nThat would still leave us with the problem with the embedded source code in your source map. Except for one thing - they\u0026rsquo;re a bug in Uglify. It strips out the embedded source code when it does it second run on your source map to get it match to the newly minified code.\nWhich means an uglified, external source map can be pushed to production. You won\u0026rsquo;t be able to debug production - you won\u0026rsquo;t have any source to look at - but an error that occurs will at least give you a decent stack trace.\n",
    "ref": "/blog/20131019-source-maps-in-node-js/"
  },{
    "title": "My ongoing relation with CoffeeScript - and a gotcha",
    "date": "",
    "description": "",
    "body": "CoffeeScript, what can I tell ya - I didn\u0026rsquo;t want to love it.\nI have an unreasonable grudge against significant whitespace.\nI couldn\u0026rsquo;t figure out the value of a language that compiles to another reasonable language.\nAnd don\u0026rsquo;t even get me started on the for of/in thing. I still don\u0026rsquo;t understand that.\nBut the more I use CoffeeScript, the more I love it.\nThe lambdas are probably my biggest love - how can you not love them, in comparison to what JavaScript makes you do?\nHowever, I found something out the other day that seems slightly counter-intuitive to me.\nsupposedToBeArray = null if foo in supposedToBeArray # You will never reach this code, because the line above throws an exception. I guess my thought would be if foo in supposedToBeArray would return false. But nope, throws when the object is not an array (or is not array-like).\n",
    "ref": "/blog/20130502-coffeescript-gotcha/"
  },{
    "title": "Docco Fork - All JS, all the time",
    "date": "",
    "description": "",
    "body": " EDIT: My fork is no longer needed. The folks at docco saw the same thing and recently ported over the library to use highlight.js.\n I love documentation generators for code. You know what I\u0026rsquo;ve talking about to - something which gives you a split screen of the code and the comments, side by side, for easy reading and scrolling. Like jasmine uses for their documentation:\nSince I\u0026rsquo;ve mostly been working in JavaScript lately I\u0026rsquo;ve been looking for something to help document the packages I create easily. In comes docco.\nA CoffeeScript + Python library to help generate good-looking documentation from comments in your code. One thing bothered me about this project - the python part. Docco uses a python library to highlight the syntax. There are plenty of decent syntax highlighters out there - why not use one written in a JavaScript flavor? So I forked docco and plugged in a JS highlighter. Pretty happy with the results.\nYou can check out the fork here.\n",
    "ref": "/blog/20130303-docco-fork-all-js-all-the-time/"
  },{
    "title": "Esvalidate Library - Standalone Validation Library Using Esprima",
    "date": "",
    "description": "",
    "body": "I spent a good bit of time working on the Esvalidate code that comes with Esprima, trying to get it to work smoothly with my sublime plugin. After submitting a massive pull request to the author of Esprima and our reviewing my code we came to a conclusion - the new code was better served in its own library.\nIt\u0026rsquo;s still in its early stages but please check out the progress I\u0026rsquo;m making here: Esvalidate Library\n",
    "ref": "/blog/20130215-esvalidate-library-standalone-validation-library-using-esprima/"
  },{
    "title": ".Net Gotcha - Private Classes With Access To Containing Classes's Protected Variables (Or Not)",
    "date": "",
    "description": "",
    "body": "A friend and I were working on some code together when we found an interesting edge case in .Net that neither of us knew about. This is what we knew: if you have a class with a protected field in it, if you declare a private class inside of that class, the private class can access the protected variable. The example below shows what this looks like.\npublic class ParentClassWithProtectedField { protected readonly int protectedField; private class PrivateClassInParentClass { public void Method(ParentClassWithProtectedField parent) { Console.WriteLine(parent.protectedField); //Me Work Good!  } } } And this is what we learned: If you create a child class that inherits from the parent class, and declare another Private class in the child class, you cannot access the parent\u0026rsquo;s protected field from the private class in the child class. I know that was a ton of Parent/Child/Private classes in a short sentence, so here\u0026rsquo;s an example, building on the previous one, of what won\u0026rsquo;t work in .NET.\npublic class ChildClassOfParentClass : ParentClassWithProtectedField { private class PrivateClassInChildClass { public void Method(ParentClassWithProtectedField parent) { Console.WriteLine(parent.protectedField); // NO WORK!  } } } ",
    "ref": "/blog/20130115-net-gotcha-private-classes-with-access-to-containing-classess-protected-variables-or-not/"
  },{
    "title": "Portfolio Spotlight on Pathbrite = Cool?",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;ve recently created a portfolio on Pathbrite. If you haven\u0026rsquo;t heard of Pathbrite, they are a company aiming to:\n Collect, organize and share a lifetime of learning and achievement.\n I think this section of their mission statement sums up how they are relevant to working professionals.\n \u0026hellip; employers rely on our Pathbrite Portfolio Platform to get a holistic view of candidates, and to better evaluate their readiness for and organizational fit to the opportunity at hand.\n How does it work? The sites allows you to import data (from LinkedIn and other sites) as well as other documents (such as images and PDFs) and lay them out in whatever manner you see fit. It can also import websites you\u0026rsquo;ve written as well. It\u0026rsquo;s a great tool for a web software developer to showcase what they\u0026rsquo;re about. The link to the article: http://www.pathbrite.com/2012/12/03/portfolio-spotlight-julie-marciel-rozzi-matt-blair/\n",
    "ref": "/blog/20121204-portfolio-spotlight-on-pathbrite-cool/"
  },{
    "title": "Esprima Plugin for Sublime Text",
    "date": "",
    "description": "",
    "body": "In relation to my previous posts confessing my love for sublime, and my enjoyment of Esprima, here is some code that showcases both: An Esprima plugin for Sublime Test!\nhttp://github.com/duereg/sublime-jsvalidate\nThis has been included in the official list of Sublime Plugins. So you can install this from Sublime using Packages Control.\n",
    "ref": "/blog/20121201-esprima-plugin-for-sublime-text/"
  },{
    "title": "Added JavaScript syntax checking via Esprima and a Git pre-commit hook",
    "date": "",
    "description": "",
    "body": "I came across a brilliant project the other day - Esprima from Ariya Hidayat, the author of PhantomJS. What is Esprima? Esprima is a JavaScript Parser written in JavaScript Syntax Validator. It forms the basis of several different tools - a minifier, a code coverage tool, a syntax validator - just to name a few. I was immediately interested in the syntax validation tool. It\u0026rsquo;s not a linter - it just checks that the JavaScript written is syntactically correct. Why would you want this if you already have JsHint and JsLint?\n It is extremely fast. Validating three.js (800 KB source) takes less than a second on a modern machine. It looks only for syntax errors, it does not care about coding style at all. It handles generated files as the result of minification or compilation (CoffeeScript, Dart, TypeScript, etc). It tries to be tolerant and not give up immediately on the first error, especially for strict mode violations.  Esprima is available as an npm package, so installing it only takes a second: sudo npm install -g esprima Using Esprima from the command line is simple: esvalidate file.js\nThe only thing to note about running from the command line: if the validation succeeds, you won\u0026rsquo;t get much in the way of confirmation. Which can be painful if you are processing a whole directory. You only get useful feedback in the default mode on error. If you don\u0026rsquo;t mind reading a little XML: esvalidate lib/*.js --format=junit\nPrints junit XML which at least you can visually parse to see which files were validated. Where would I use this where I might not use JsHint? As a pre-commit hook to screen my checkins. Instead of going through a check-in, building everything, then running JSHint just to hear that something is not up to spec, I can add a little script that will do a quick sanity check of my JS before I go to commit anything to git.\nIf you\u0026rsquo;ve never created a pre-commit hook before, it\u0026rsquo;s pretty easy. Two lines in bash will give you a pre-commit file: touch .git/hooks/pre-commit chmod +x .git/hooks/pre-commit\nThis is windows version of the code for the pre-commit hook: #!/bin/sh files=$(git diff-index --name-only HEAD | grep -l '\\\\.js$') for file in $files; do esvalidate $file if [ $? -eq 1 ]; then echo \u0026quot;Syntax error: $file\u0026quot; exit 1 fi done\nTo make this work on Linux, just remove the remove the #!/bin/sh line. For more information about Esprima, check out this article by the author.\n",
    "ref": "/blog/20121120-added-javascript-syntax-checking-via-esprima-and-a-git-pre-commit-hook/"
  },{
    "title": ".Net SQL Parsing - Using the TSqlParser library",
    "date": "",
    "description": "",
    "body": "A preface to this post: it is hard to find a free SQL Parser for .NET. There is a company that has a terrible library that they charge $150 bucks for. There are a couple of incomplete implementations done for school projects or for narrowly focused tasks. So if you want a no-strings attached free parser for SQL, you\u0026rsquo;re out of luck. However, since most people who want a .NET parser are writing code on a Windows machine, and use Visual Studio, there is (lightly documented) hope: the TSqlParser library that ships with Visual Studio.\nThis is a fully featured parsing library for SQL Server SQL syntax. I\u0026rsquo;m not sure about the support of other DB\u0026rsquo;s SQL syntax, but I would imagine it\u0026rsquo;s poor. On an x64 Windows machine, using Visual Studio 2010, the dll\u0026rsquo;s which contain the TSqlParser library are located at: C:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\VSTSDB The class TSql100Parser in Microsoft.Data.Schema.ScriptDom.Sql gets you the parser for Sql Server 2008. To instantiate an instance of the TSql100Parser class, you have to supply the constructor with one parameter:\npublic TSql100Parser(bool initialQuotedIdentifiers ) The docs for this are better than trying to figure out what initialQuotedIdentifiers means:\n Specifies whether quoted identifier handling is on.\n I\u0026rsquo;m guessing this has to do with declaring aliases for columns like this:\nselect bar as \u0026#39;This is the alias for foo.bar\u0026#39; from tblFoo \\--instead of like this: select bar as [This is the alias for foo.bar] from tblFoo Using the parser is relatively simple. Once you reference the correct dll\u0026rsquo;s in your project:\nvar parser = new TSql100Parser(true); var script = parser.Parse(reader, out errors) as TSqlScript; foreach (TSqlBatch batch in script.Batches) { foreach (TSqlStatement statement in batch.Statements) { //At this point, you have a collection of SQL Statements...  //that can contain collections of SQL Statements...  } } My comment in the code above is to help you understand something about parsing SQL - almost every relationship is expressed as a tree, where something contains more of the same thing, and that thing may contain more of the same thing, or maybe not. Which means the easiest way to navigate the data is recursively. In other words, the Rules for using TSqlParser:\n LEARN TO LOVE THE RECURSION. Refer to the Rules for using TSqlParser  I\u0026rsquo;ll give you an example scenario to show you what you\u0026rsquo;re up against. One common scenario is searching your code for SELECT statements. Select statements can be contained in:\n Stored Procedures If Statements While Statements BEGIN statements Try/Catch Blocks  I\u0026rsquo;m sure I\u0026rsquo;m missing some cases. So it\u0026rsquo;s not as simple as saying \u0026ldquo;give me all the statements that are select statements\u0026rdquo;. Instead, you have to write something like:\nfunction ProcessStatements(statements) foreach(statement in statements) if statement is a Stored Procedure ProcessStatements(statement.MyStatements) if statement is an If Statement ProcessStatements(statement.MyStatements) if statement is a While Statement ProcessStatements(statement.MyStatements) if statement is a Select Statement ProcessSelect( statement) So once you get your select statement (or your collection of select statements), how do you process them? Well unfortunately it\u0026rsquo;s not straightforward. The SelectStatement class contains a field called QueryExpression - this field contains what kind of Select we\u0026rsquo;re dealing with. As far as I can determine, there are three types of QueryExpressions:\n QuerySpecification  This is an actual SELECT statement\n BinaryQueryExpression  This is a UNION or similar expression between two SELECT statements\n QueryParenthesis  This is a SELECT surrounded by parenthesis. In other words, a sub-select\nSo again, if you only want SELECT statements, you have to weed through the three types of QueryExpressions until you get to the underlying SELECT statements. So eventually you\u0026rsquo;ll get to a list of QuerySpecifications (which represent the SELECT statements from your original query). Now here comes the good stuff: you can now weed through the SELECT fields programmatically and get out whatever information you want. Here are some of the fields on QuerySpecification:\n|FromClauses| Gets a list of FROM clauses.| |GroupByClause| Gets or sets a GROUP BY clause.| |HavingClause| Gets or sets a HAVING clause.| |Into| Gets or sets the into table name.| |SelectElements| Gets a list of the selected columns or set variables.| |TopRowFilter| Gets or sets the usage of the top row filter.| |UniqueRowFilter| Gets or sets the unique row filter value.| |WhereClause| Gets or sets a WHERE clause.|  Just tons of SELECT goodness. However, be warned: each of these fields contains lists with multiple subclasses. So more recursive diving if you want to get something very specific out of this select data. To get farther you might have to dive into the docs. Link to MSDN Namespace Docs\n",
    "ref": "/blog/20121101-net-sql-parsing-using-the-tsqlparser-library/"
  },{
    "title": "Free Collection of Microsoft E-Books",
    "date": "",
    "description": "",
    "body": "If you\u0026rsquo;re a Microsoft Dev, want to learn a bit more about the following products:\n SharePoint 2010 Sql Server 2012 Visual Studio 2010 Windows 8 Windows Phone 7 Office 365 Office 2010 ASP.NET 4.5 Web Forms ASP.NET MVC 4 Microsoft Dynamics CRM 2011 (God Rest Your Soul)  Microsoft has released a bunch of free e-books about these technologies (and more).\nThe links to the e-books:\n Microsoft Free E-Books - Page 1 Microsoft Free E-Books - Page 2  ",
    "ref": "/blog/20121030-free-collection-of-microsoft-e-books/"
  },{
    "title": "Derby.js - The Ready() Function, and Adding Client-Side Scripts to your App",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;ve found a neat feature of derby dealing with the ready() function. I\u0026rsquo;ve been creating a derby app, and in my application I need to load up a client-side calendar. With a standard HTML web page this is straightforward thing to do. On the page you wanted the calendar, you would include the client js for the calendar, some code to load it, and that would be that. Derby introduced some complexity to this relatively simple task. On my first attempt, I put my scripts in the section of the page that I needed the calendar on. I added a script to load the calendar as well. When I went to the url of the page, it loaded immediately. Success! (I thought).\nThen I clicked a link away from my calendar, and then clicked back. No calendar. What happened? When I loaded the link originally, the page was rendered from the server. The second time, the page was rendered client side. Something wasn\u0026rsquo;t working with loading the calendar on the client-side render. You need a place to put your code that guarantees that it will load on the client-side. The app.ready() function is designed to handle this scenario. What is the purpose of the app.ready() function? From the derby documentation:\n Code that responds to user events and model events should be placed within the app.ready() callback. This provides the model object for the client and makes sure that the code is only executed on the client. This function is called as soon as the Derby app is loaded on the client. Note that any code within this callback is only executed on the client and not on the server.\n I\u0026rsquo;ve bolded the part I think is particularly important. This code is run as soon as the client is loaded. Which means if you have more than a single-page app, using app.ready() to load a feature might not work out. So what to do? An undocumented feature of Derby - app.on(). What does it do? It allows you to load code AFTER a specific page has loaded. Which is exactly what I\u0026rsquo;m looking for. So here\u0026rsquo;s what I ended up writing in my app.ready():\napp.on(\u0026#39;render:calendar\u0026#39;, function(ctx) { logger.log(\u0026#34;rendering calendar client-side...\u0026#34;); new Timeline(\u0026#34;timeline\u0026#34;, new Date()); }); In this example this code will run after rendering the calendar view. On the Calendar page, there is a script block which loads the Timeline function. After writing this code, I tried my page again. Still no luck. I wasn\u0026rsquo;t getting the calendar to load on both the client and server load. On a lark, I moved the block containing my Timeline javascript to my index view, and tried again. Success. Which makes sense. If you are rendering pages via the client side load, additional resources aren\u0026rsquo;t going to be loaded. So by putting my script into the index view, it\u0026rsquo;s unfortunately loaded for all my pages, but at least it\u0026rsquo;s available for both the client and server side rendering of my cool control.\n",
    "ref": "/blog/20121017-derby-js-the-ready-function-and-client-side-scripts/"
  },{
    "title": "Cracking the Coding Interview - The Tower of Hanoi and Poor Editing",
    "date": "",
    "description": "",
    "body": "I just finished the Stack section of Cracking the Coding Interview and came across an old puzzle - The Tower of Hanoi. I struggled with solving this problem. I wrote this elaborate, strange algorithm to try to solve it (which should have been a dead give-away that I had it wrong). Ironically enough, hidden in the 20-30 lines of code I wrote were the three lines of code I needed to solve the problem. Anyways, after beating my head in trying to solve this, I ended up going to the back of the book and looking up the solution. And found this pile of shit psuedocode. I\u0026rsquo;ve shortened the comments, but the content is the same.\nmoveDisks(int n, Tower origin, Tower destination, Tower buffer) { if (n \u0026lt;= 0) return; //Move top n - 1 disks from 1 to 2 \tmoveDisks(n-1, tower 1, tower 2, tower 3); //Move top from 1 to 3 \tmoveTop(tower 1, tower 3); //Move top n - 1 disks from 2 to 3 \tmoveDisks(n-1, tower 2, tower 3, tower 1); } In this tiny amount of code, in over five revisions to her book, the author has managed to miss two errors.\n In the first line, Variables origin, destination, and buffer are declared, but then tower 1, tower 2, and tower 3 are used. Which is which? In line 5, the comment says \u0026ldquo;Move top n-1 disks\u0026rdquo;. Then, in lines 8-9, the author indicates that you move the top. Since you\u0026rsquo;ve already moved all the items in the stack but one, the bottom element, that line should read \u0026ldquo;move bottom\u0026rdquo;.  Maybe these aren\u0026rsquo;t huge issues, but since I was pretty frustrated with this problem, having to correct the solution didn\u0026rsquo;t help my frustration. The correct code:\nmoveDisks(int n, Tower origin, Tower destination, Tower buffer) { if (n \u0026lt;= 0) return; //Move top n - 1 disks from origin to buffer \tmoveDisks(n-1, origin, buffer, destination); //Move nth disk (the bottom disk) from origin to destination \tmoveBottom(origin , destination); //Move top n - 1 disks from buffer to destination \tmoveDisks(n-1, buffer, destination, origin); } I hope this helps somebody else who\u0026rsquo;s working on this problem.\n",
    "ref": "/blog/20120915-cracking-the-coding-interview-the-tower-of-hanoi-and-poor-editing/"
  },{
    "title": "Cracking the Coding Interview - Linked Lists - The Runner Technique",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;ve been going over the Linked List section of Cracking the Coding Interview and most times I get stumped with a problem the solution is the Runner Technique (or slow/fast pointers).\nThe idea behind the runner technique is simple; use two pointers that either move at different speeds or are a set distance apart and iterate through a list.\nWhy is this so useful? In some linked list problems you need to know the position of a certain element or the length of the list. Given that you don\u0026rsquo;t always have the length of the list you are working on, the runner technique is an elegant way to solve these type of problems (and in some cases it is the only solution). Here are some examples of linked list problems where the runner technique provides an optimal solution:\n Given two lists of different lengths that merge at a point, determine the merge point Determine if a linked list contains a loop Determine if a linked list is a palindrome Determine the kth element of a linked list  Where do you use it? If you get handed a linked list question, and you find yourself asking these questions:\n How do I figure out where these two things meet? How do I figure out the midpoint? How do I figure out the length?  You\u0026rsquo;re likely dealing with a problem where you need to use the runner technique.\nHow does it work? I\u0026rsquo;ll illustrate one of the examples above. Given two lists of different lengths that merge at a point, determine the merge point Start a node at the beginning of each list on the left. Count how many nodes each pointer encounters. (The top list should be 5, the bottom list 4.) The difference between the two numbers is the difference in length of the two lists before the merge point (the difference is 1) Move your nodes to the beginning of each list, but the longer list should get a headstart equal to the amount of difference. (so the top list would start on its 2nd element, while the bottom list would start on its 1st). Move each node forward at the same speed until they meet. Where they meet is the collision point.  Each of the links above contains code and solutions to each of the problems. I hope this example and the ones above show the usefulness of this approach. There are also some examples located here of linked list algorithms problems and solutions written in JavaScript.\n",
    "ref": "/blog/20120913-cracking-the-coding-interview-linked-list-the-runner-technique/"
  },{
    "title": "How to install Sublime Text 2 on Ubuntu 12.04 (Unity)",
    "date": "",
    "description": "",
    "body": "Sublime Text has rapidly become my favorite text editor. Cross platform, easy to use, great feature set. The Command Palette feature, where you can search for a feature without having to know where it is in the application, is an piece of usability brilliance. Somebody cobbled together a great step-by-step set of directions on how to install sublime on ubuntu. I wanted to give a shout-out to them and their work.\nHow to install Sublime Text 2 on Ubuntu 12.04 (Unity) | Technoreply.\n",
    "ref": "/blog/20120911-how-to-install-sublime-text-2-on-ubuntu-12-04-unity/"
  },{
    "title": "Setting up MongoDB to work with Derby.js",
    "date": "",
    "description": "",
    "body": "This post is going to cover installing and configuring MongoDB to use with Derby. If you\u0026rsquo;re reading this post looking to add model persistence to your Derby application but don\u0026rsquo;t know much about MongoDB, understanding MongoDB will help you understand Derby and the model system it uses.\nWhat\u0026rsquo;s MongoDB? From their website:\n MongoDB (from \u0026ldquo;humongous\u0026rdquo;) is a scalable, high-performance, open source NoSQL database.\n If you\u0026rsquo;ve never used MongoDB before, you should immediately go here. This is the easiest, fastest way to learn the basics of what mongo is and how it works. And it only takes about fifteen minutes. It\u0026rsquo;s even interactive to keep you from getting bored. Go give it a play.\nDerby and MongoDB Now that you have an idea about how MongoDB works, many of the conventions Derby uses for models should make sense. If you scan through the Derby Query Readme now, hopefully is makes a bit more sense (like where the term \u0026ldquo;gte\u0026rdquo; came from).\nInstalling MongoDB If you still need to install MongoDB go here for downloads and installation directions.\nConfiguring Derby to use MongoDB Now that you know about MongoDB, let\u0026rsquo;s get MongoDB set up to work with Derby. This is straightforward and takes about two minutes. To add MongoDB to your Derby application, you\u0026rsquo;ll need to include the racer-db-mongo package in your project. Update your package.json file to look something like this:\n{ \u0026#34;name\u0026#34;: \u0026#34;potluck\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;./server.js\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;derby\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;derby-ui-boot\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;express\u0026#34;: \u0026#34;3.0.0beta4\u0026#34;, \u0026#34;gzippo\u0026#34;: \u0026#34;\u0026gt;=0.1.7\u0026#34;, \u0026#34;racer-db-mongo\u0026#34;: \u0026#34;*\u0026#34; //this is the line. Glory in its beauty. }, \u0026#34;private\u0026#34;: true } Then, at the command prompt, update your project (and download the recently added racer-db-mongo dependency) using the following command:\n npm update  You\u0026rsquo;ll have to update your server configuration (by default in /lib/server/index.js) to use the new dependency. This requires TWO new lines of code\nderby.use(require(\u0026#39;racer-db-mongo\u0026#39;)); // This line is new app.createStore({ listen: server , db: {type: \u0026#39;Mongo\u0026#39;, uri: \u0026#39;mongodb://localhost/database\u0026#39;} /* This line is new */ }); That\u0026rsquo;s all the changes you need to make to add MongoDB to your project. So why I\u0026rsquo;d bother with a blog post?\nWhat About Troubleshooting? Now, if you go and start your Derby application, you might see the following error:\nError: failed to connect to [localhost:27017]  Which means:\n You\u0026rsquo;ve installed the racer-db-mongo dependency correctly! You now need to: * Install MongoDB * Turn on MongoDB * OR Fix MongoDB If you\u0026rsquo;ve forgotten to install Mongo, if you look around, you\u0026rsquo;ll probably find a link somewhere which will help you out.  Starting/Stopping/Statusing MongoDB If you\u0026rsquo;ve installed Mongo, you have to start the service before Derby can use it. On Ubuntu, you start Mongo using the following command:\n sudo start mongodb  Remember to stop Mongo later with:\n sudo stop mongodb  If you\u0026rsquo;ve started Mongo, then loaded your Derby application, and you\u0026rsquo;re still getting an error, it\u0026rsquo;s possible that Mongo did not start correctly. Typing:\n sudo status mongodb  will let you know if Mongo is running or not. If you\u0026rsquo;ve run the Mongo Start command, yet the status command is telling you that Mongo is stopped, the most likely cause is Mongo did not shut down gracefully last time it was run. You\u0026rsquo;ll have to go and repair your installation (luckily, this is pretty easy).\nRepairing MongoDB To repair your installation, run the following commands:\n$ sudo rm /var/lib/mongodb/mongod.lock $ sudo -u mongodb mongod -f /etc/mongodb.conf --repair  The code above was taken from this great article At this point, you should have a working copy on MongoDB along with a working integration with Derby. Congrats!\nMongoDB is working great - now Derby hates me If your application loads, but you\u0026rsquo;re getting a strange error whenever you add to a collection that looks something like this:\nError: No persistence handler for push(FIRST_WORD.SECOND_WORD, [object Object], 18)  It means that you are pushing to the wrong portion on an model path. You can only use push to arrays, and arrays are not objects, and you can only use objects for the first and second words of your model path. In the case shown above, a push is attempting to be made to\n FIRST_WORD.SECOND_WORD  which equates to\n FIRST_WORD.SECOND_WORD.push(object)  which means SECOND_WORD is an array (which isn\u0026rsquo;t allowed). If this last bit of explanation might have well been in Latin, check out this post. It\u0026rsquo;ll explain a little bit about how to declare models and what Derby is expecting you to do. Unfortunately, you CAN use the second word of a model path as an array without persistence support. So this kind of bug will only surface once you\u0026rsquo;ve got MongoDB integrated with Derby.\n",
    "ref": "/blog/20120906-setting-up-mongodb-to-work-with-derby-js/"
  },{
    "title": "Javascript Strings - Using Array Accessor '[]' to set characters",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;ve been learning quite a bit about JavaScript in writing algorithms from Cracking the Coding Interview. I learned something new about strings in JavaScript and how they can be accessed. From MDN:\n Character access There are two ways to access an individual character in a string. The first is the charAt method:\n return \u0026#39;cat\u0026#39;.charAt(1); // returns \u0026#34;a\u0026#34; The other way is to treat the string as an array-like object, where individual characters correspond to a numerical index:\nreturn \u0026#39;cat\u0026#39;[1]; // returns \u0026#34;a\u0026#34; Array-like character access (the second way above) is not part of ECMAScript 3. It is a JavaScript and ECMAScript 5 feature. For character access using bracket notation, attempting to delete or assign a value to these properties will not succeed. The properties involved are neither writable nor configurable.\nI highlighted the important part. I know that strings are immutable in JavaScript, but why give me array access if you won\u0026rsquo;t let me use it? So if you want to use the array accessor with a string, there is a way to do it, but it requires a bit of overhead.\nvar sentence = \u0026#34;this is a proper JavaScript string.\u0026#34;; sentence = sentence.split(\u0026#34;\u0026#34;); //split into array sentence[18] = \u0026#39;j\u0026#39;; //changing values to lowercase sentence[22] = \u0026#39;s\u0026#39;; sentence = sentence.join(\u0026#34;\u0026#34;); //make the array a string again ",
    "ref": "/blog/20120905-javascript-strings-using-array-accessor-to-set-characters/"
  },{
    "title": "Cracking the Coding Interview - JavaScript Trie",
    "date": "",
    "description": "",
    "body": "I finished my third algorithm from Cracking the Coding Interview - the Trie.\nTries are a useful algorithm, if not all that well known. They can be used for efficient spell checking, auto suggestion, as well as the sorting of a collection of strings.\nThis algorithm was more complex to implement than the Linked List, but a little simpler than the Max/Min Binary Heap to implement.\nThe trie\u0026rsquo;s structure is easy to understand - it\u0026rsquo;s a word tree, where each leaf of the tree is a letter of a word. Where words share common prefixes (such as fresh and freedom), those words share a common \u0026ldquo;branch\u0026rdquo; of prefix letters, and split where the words differ.\n(This image is from Wikipedia) The insert and hasWord operations are easy to implement. Complicating the removal of words operation is the shared nature of the word prefixes.\nInsert goes something like this: For each letter in the word:\n if the letter exists on the tree, go to the letter. If it does not exist, create it. If there is another letter, return to the previous step. If not, add a word terminating marker.  Here is my implementation of insert:\nvar trie = function() { this.head = {}; }; trie.prototype.validate = function(word) { if((word === undefined) || (word === null)) throw \u0026#34;The given word is invalid.\u0026#34;; if (typeof word !== \u0026#34;string\u0026#34;) throw \u0026#34;The given word is not a string\u0026#34;; } trie.prototype.add = function(word) { this.validate(word); var current = this.head; for (var i = 0; i \u0026lt; word.length; i++) { if(!(word[i] in current)) { current[word[i]] = {}; } current = current[word[i]] }; current.$ = 1; //word end marker }; The hasWord algorithm is like the insert algorithm. For each letter in the word:\n if the letter exists on the tree, go to the letter. If it does not exist, the word does not exist. If there is another letter, return to the previous step. If not, check for the word terminating marker.  trie.prototype.hasWord = function(word) { this.validate(word); var current = this.head; for (var i = 0; i \u0026lt; word.length; i++) { if(!(word[i] in current)) { return false; } current = current[word[i]] }; return current.$ === 1; //word end marker }; Delete isn\u0026rsquo;t much more complicated, though the recursive nature of the algorithm does make it a bit of a pain. You have to go to the end of the word, and if no other letters are hanging off your word, delete from the end towards the head. As soon as you find a shared element, you stop the deletion.\ntrie.prototype.remove = function(word) { this.validate(word); canDelete(word, -1, this.head); function canDelete(word, index, node){ if(word === undefined ) throw \u0026#34;Bad Word\u0026#34;; if(index \u0026gt;= word.length) throw \u0026#34;Bad index to check for deletion.\u0026#34;; if(node === undefined ) throw \u0026#34;Bad Node at \u0026#34; + index + \u0026#34; for \u0026#34; + word; if(index === word.length - 1) { //last letter  //always delete word marker (as we are deleting word)  return (delete node.$) \u0026amp;\u0026amp; noKids(node); //if last letter of word, should be empty.  } else { //any other letter in word  //check child, and after child check, I am now empty  if(canDelete(word, index + 1, node[word[index + 1]]) ) { //delete me  return (delete node[word[index + 1]]) \u0026amp;\u0026amp; noKids(node); } } return false; }; function noKids(node) { return Object.keys(node).length === 0; }; }; My favorite advantage of using a trie is the ease in generating a sorted list of words. All you have to do is output all the letters by Pre-Order Traversal. And sorting using a trie is fast - the worst case sorting is O(kn), where k is the length of the longest word in the trie.\ntrie.prototype.sort = function() { var word = \u0026#34;\u0026#34;; var sorted = []; sortTrie(this.head, word, sorted); function sortTrie(node, word, sorted) { for(var letter in node) { if (letter == \u0026#39;$\u0026#39;) { sorted.push(word); } else { sortTrie(node[letter], word + letter, sorted); } } } console.log(sorted); return sorted; }; The source code for the project and the tests are here.\n",
    "ref": "/blog/20120901-cracking-the-coding-interview-javascript-trie/"
  },{
    "title": "Cracking the Coding Interview - JavaScript Min/Max Binary Heap",
    "date": "",
    "description": "",
    "body": "I finished my second algorithm from Cracking the Coding Interview - the Binary Heap. This algorithm racketed up the complexity from the Linked List.\nThe heap\u0026rsquo;s structure is easy to understand - it\u0026rsquo;s a binary tree (a tree where each node can have at most two children). In the case of a max heap, the parents have a greater value than their children. The values in a Max Heap decrease as you move down the tree from the parent to children.\n(This image is from Wikipedia) The complexity comes from the behavior. Though the algorithms are easy to understand, there is enough going on in each one that it\u0026rsquo;s easy to sneak in bugs. It took me a bit of time to get each of my implementations the way I wanted it. The insert operation is the easiest to implement. The algorithm is also straight forward.\n Add the element to the bottom of the heap. Compare the added element with its parent; if they are in the correct order, stop. If not, swap the element with its parent and return to the previous step.  Here is part of my implementation of insert:\nbinaryHeap.prototype.add = function(data) { if (data === undefined) { throw \u0026#34;data must be valid to add\u0026#34;; } this.array.push(data); this.bubbleUp(this.array.length - 1, data); }; binaryHeap.prototype.bubbleUp = function(childIndex, childData) { if(childIndex \u0026gt; 0) { var parentIndex = this.getParentIndex(childIndex); var parentData = this.array[parentIndex]; if (this.shouldSwap(childData, parentData)) { this.array[parentIndex] = childData; this.array[childIndex] = parentData; this.bubbleUp(parentIndex, childData); } } }; binaryHeap.prototype.getParentIndex = function (childIndex) { return Math.floor((childIndex - 1) / 2); }; Delete is more complicated though the algorithm reads about the same. To delete the top of a heap:\n Replace the root of the heap with the last element on the last level. Compare the new root with its children; if they are in the correct order, stop. If not, swap the element with one of its children and return to the previous step. * Swap with its smaller child in a min-heap and its larger child in a max-heap.  binaryHeap.prototype.removeHead = function() { var headNode = this.array[0]; var tailNode = this.array.pop(); this.array[0] = tailNode; this.bubbleDown(0, tailNode); return headNode; }; binaryHeap.prototype.bubbleDown = function(parentIndex, parentData) { if(parentIndex \u0026lt; this.array.length) { var targetIndex = parentIndex; var targetData = parentData; var leftChildIndex = this.getLeftChild(parentIndex); var rightChildIndex = this.getRightChild(parentIndex); if(leftChildIndex \u0026lt; this.array.length) { var leftChildData = this.array[leftChildIndex]; if (this.shouldSwap( leftChildData, targetData )) { targetIndex = leftChildIndex; targetData = leftChildData; } } if(rightChildIndex \u0026lt; this.array.length) { var rightChildData = this.array[rightChildIndex]; if(this.shouldSwap(rightChildData, targetData )) { targetIndex = rightChildIndex; targetData = rightChildData; } } if(targetIndex !== parentIndex) { this.array[parentIndex] = targetData; this.array[targetIndex] = parentData; this.bubbleDown(targetIndex, parentData); } } }; binaryHeap.prototype.getLeftChild = function (parentIndex) { return parentIndex * 2 + 1; }; binaryHeap.prototype.getRightChild = function (parentIndex){ return parentIndex * 2 + 2; }; There is more code needed to delete the top element and reshuffle the list into the correct order. With all the extra comparisons there are many places where bugs can sneak into the code. The source code for the project and the tests are here.\n",
    "ref": "/blog/20120829-cracking-the-coding-interview-javascript-minmax-binary-heap/"
  },{
    "title": "Derby.js - Starting out with Components; Creating a Twitter Bootstrap Input Component",
    "date": "",
    "description": "",
    "body": "In working with Twitter Bootstrap Forms, one of my favorite ways to lay out a form is using the Horizontal form layout. The layout requires a bit of css/html to get each of the form elements (the text boxes and what not) to play nicely. To add form elements to the horizontal form layout, you need the following html structure for each field:\n\u0026lt;div class=\u0026#34;control-group\u0026#34;\u0026gt;\u0026lt;!-- additional classes here to change state --\u0026gt; \u0026lt;label class=\u0026#34;control-label\u0026#34;\u0026gt;INPUT_LABEL_TEXT_HERE\u0026lt;/label\u0026gt; \u0026lt;div class=\u0026#34;controls\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; /\u0026gt; \u0026lt;!-- This is the control you want to display --\u0026gt; \u0026lt;span class=\u0026#34;help-inline\u0026#34;\u0026gt;ERROR_OR_INFORMATIONAL_MESSAGE_HERE\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; That\u0026rsquo;s a hefty amount of markup to copy and paste all over your pristine views. Which makes this a great place to use a Component.\nSo what\u0026rsquo;s a Component? A component is basically a derby template you can supply parameters to. Those parameters are supplied in the form of HTML attributes and HTML content.\nThere are two types of components: application and library. Application components can only be used in a single project. Library components can be re-used across multiple projects.\nFor my project I\u0026rsquo;m going to create an application component. Eventually if I need the component on another project I\u0026rsquo;ll add it to a component library. But that process is more complicated and less documented so I\u0026rsquo;ll save that for another day.\nThere are two ways to create an application component:\n Inline  If your component is only being used on a single view, you can add it to the same file as your view.\n External  If your component is going to be used on multiple views, you should create a separate file for your component. Apparently there are two ways to create a library component as well:\n The ui directory contains a component library, which can be used to create custom components for the containing project. These are re-usable templates, scripts, and styles that can be used to create custom HTML tags for use in applications. General purpose component libraries can be created as separate npm modules.\n All components run under the scope of the context in which they are called. Which means you can bind model data to your component without having to pass your component any values. For example:\n\u0026lt;h2\u0026gt;All toys:\u0026lt;/h2\u0026gt; {each toys as :toy} \u0026lt;!-- Alias :toy available to the component --\u0026gt; \u0026lt;app:toyStatus\u0026gt; \u0026lt;!-- All application components live in the app namespace --\u0026gt; {/} \u0026lt;toyStatus:\u0026gt; \u0026lt;!-- this tag says I am a component --\u0026gt; \u0026lt;!-- I\u0026#39;m using alias :toy here, defined above --\u0026gt; \u0026lt;span\u0026gt;The toy is located at {:toy.location}\u0026lt;/span\u0026gt; If all of this \u0026ldquo;Model-Bindy\u0026rdquo; stuff is foreign to you, check out my post Working with Views, Models, and Bindings.\nI don\u0026rsquo;t like the way you used a scoped alias from your view in your component. What if my component is in another file? What if I want to use a field with a different name? Is there a better way to pass values to a component? From the derby documentation:\n Literal values or variable values can be passed to components. These component attributes are available through “macro” template tags, which have triple curly braces.\n What does that look like? Again, from the docs:\n\u0026lt;Body:\u0026gt; \u0026lt;h1\u0026gt; \u0026lt;app:greeting message=\u0026#34;Hello\u0026#34;\u0026gt; \u0026lt;/h1\u0026gt; \u0026lt;greeting:\u0026gt; I was passed this message as an attribute: {{{message}}} You can also pass html to your component as well. That is a two-part trick: First, write your component with an opening and closing tag. Put the value you want to pass to your component between the tags. Then, in your component, you use the special triple-curly bracket {{{content}}} macro-tag to reference what you passed in. For example:\n\u0026lt;Body:\u0026gt; \u0026lt;app:fancyButton\u0026gt; \u0026lt;b\u0026gt;Click me now!\u0026lt;/b\u0026gt; \u0026lt;/app:fancyButton\u0026gt; \u0026lt;fancyButton: nonvoid\u0026gt; \u0026lt;button class=\u0026#34;fancy\u0026#34;\u0026gt; {{{content}}} \u0026lt;/button\u0026gt; But I already knew all that. How do I make a component? The easiest way is to just add the component to your page, as show in the simple example above. This example is taken from the derby website, and it shows you how to reference a component in a separate file:\nshared.html (This is your component, which is located in your views folder.) \u0026lt;profile:\u0026gt; \u0026lt;div class=\u0026#34;profile\u0026#34;\u0026gt;...\u0026lt;/div\u0026gt; home.html (This is the view that will use your component.) \u0026lt;!-- This line imports your component into the view --\u0026gt; \u0026lt;import: src=\u0026#34;shared\u0026#34;\u0026gt; \u0026lt;Body:\u0026gt; Welcome to the home page \u0026lt;!-- include component from an imported namespace --\u0026gt; \u0026lt;app:shared:profile\u0026gt; The  tag at the top, used to include your component into your view, can be called with variety of parameters. For more information on the \u0026lt;import\u0026gt;  tag go to http://derbyjs.com/#importing_templates.\nDidn\u0026rsquo;t you say something about Twitter Bootstrap? Oh yeah. Got sidetracked there. As you can see, creating a component is relatively easy. Since I already have all the Twitter Bootstrap markup ready, I might as well create a Twitter Bootstrap Component for Derby. To do this, all you have to do is figure out what you want to be able to customize.\nboot.html \u0026lt;input:\u0026gt; {{{#with data}}} \u0026lt;div class=\u0026#34;control-group {{cssClass}}\u0026#34;\u0026gt; \u0026lt;label class=\u0026#34;control-label\u0026#34;\u0026gt;{{label}}\u0026lt;/label\u0026gt; \u0026lt;div class=\u0026#34;controls\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;{{type}}\u0026#34; value=\u0026#34;{{value}}\u0026#34; /\u0026gt; \u0026lt;span class=\u0026#34;help-inline\u0026#34;\u0026gt;{{message}}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {{{/}}} As you can see, I added bindings for {{cssClass}}, {{label}}, {{type}}, {{value}}, and {{message}}. Why did I use a #with block to set the scope of my object being passed in? There is a bug in the derby code right now (documented here) where you can\u0026rsquo;t reference an object\u0026rsquo;s child properties with the triple curly brackets syntax. So {{{data}}} will work, but {{{data.value}}} won\u0026rsquo;t. The object being bound to the component:\nvar data = function(value, label, type) { this.label = label; this.value = value; this.message = \u0026#34;\u0026#34;; this.cssClass = \u0026#34;\u0026#34;; this.type = type || \u0026#34;text\u0026#34;; }; And I call it in my view like this:\n\u0026lt;app👢input data=\u0026#34;{:person.firstName}\u0026#34;\u0026gt; Where firstName is an object like data described above. With just a little bit of markup and code, I have a reusable component that I can use to style my application without having to copy and paste code everywhere.\nI hope this it helps some of the fledging Derby developers out there.\n",
    "ref": "/blog/20120825-derby-js-starting-out-with-components-creating-a-twitter-bootstrap-input-component/"
  },{
    "title": "Cracking the Coding Interview - JavaScript Singly Linked List",
    "date": "",
    "description": "",
    "body": "I finished my first algorithm from Cracking the Coding Interview - the almighty Singly Linked List.\nThis is the low-hanging fruit of the data structures I mean to tackle. Even implementing this simple structure, I managed to somehow squeeze in a bug that luckily I caught in my testing. An unfortunate case of premature optimization.\nThe code doesn\u0026rsquo;t look as cool as it did, but at least it does the job. One thing I found in reading a bit about Linked Lists on wikipedia, which I had never heard of before; Hash Linking.\n The link fields need not be physically part of the nodes. If the data records are stored in an array and referenced by their indices, the link field may be stored in a separate array with the same indices as the data records.\n At first I thought it was a silly way to implement a linked list; if you have an array storing your values, what value are you getting from the list?\nOnce I thought a little more, I realized the value of the link field being stored in a separate array. You can easily re-order your list by changing the values in the array, without traversing and without touching your data.\nThis might be a valuable solution if the relationship between items constantly changes but the size of the data remains somewhat static. In the notes of various implementations of this pattern I\u0026rsquo;ve seen, people have commented on how they expand the array when more spots are needed.\nI have yet to see any information about if you shrink the array once the \u0026ldquo;list\u0026rdquo; contracts to a certain point. The source code for the project and the tests is here.\n",
    "ref": "/blog/20120824-cracking-the-coding-interview-javascript-singly-linked-list/"
  },{
    "title": "Derby.js - Integrating Twitter Bootstrap into your Application",
    "date": "",
    "description": "",
    "body": "As I\u0026rsquo;ve mentioned in a previous post, I\u0026rsquo;m a big fan of Twitter Bootstrap. Lately I\u0026rsquo;ve been playing been with JavaScript and Derby. I want to integrate bootstrap with the POC site I\u0026rsquo;m building, and the creators of Derby have already figured out a way to do this.\nStep 1: Add a dependency to the derby-ui-boot package, which is a Derby component library based on Twitter Bootstrap.\n{ .... \u0026#34;dependencies\u0026#34;: { \u0026#34;derby\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;derby-ui-boot\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;express\u0026#34;: \u0026#34;3.0.0beta4\u0026#34;, \u0026#34;gzippo\u0026#34;: \u0026#34;\u0026gt;=0.1.7\u0026#34; }, .... } Step 2: Update your project with the downloaded ui-boot code This is as simple as running npm update in your project folder, which will read package.json, and download any missing dependencies (like the derby-ui-boot entry you just added).\nStep 3: Add the derby-ui-boot component to your project. At the top of your application JavaScript (for me, this is the file located at /lib/app/index.js), after your var derby = require(\u0026quot;derby\u0026quot;); line, add the following line of code to your file:\nvar derby = require(\u0026#34;derby\u0026#34;); derby.use(require(\u0026#39;derby-ui-boot\u0026#39;)); Step 4: Profit! That should be it for you. When you load your application up, the default twitter bootstrap css and js should have loaded. To correctly style your application, you\u0026rsquo;ll have to follow the guidelines laid out here and here.\n",
    "ref": "/blog/20120818-derby-js-integrating-twitter-bootstrap-into-your-application/"
  },{
    "title": "Cracking the Coding Interview: JavaScript Data Structures",
    "date": "",
    "description": "",
    "body": "A friend and co-worker of mine (one of the best and brightest I\u0026rsquo;ve worked with) recently left our company to go work for Microsoft. Having gone through the Microsoft interview process myself (hilariously unprepared, to the enjoyment of my interviewer), I wondered what he had done to get ready for the process. He recommended one book - Cracking the Coding Interview - which he said had been recommended to him as the bible for preparation.\nInterested in what his holy grail had to offer, I picked up a copy. In the first couple of pages there is a chart that lists a bunch of CS staples (linked lists, trees, hash tables, stacks, queues, etc). After listing these concepts out (which every good programmer should know), it then goes on to say\n These are concepts you have to understand and be able to implement.\n Now, being a couple of years out of college, I realized that I think I have a handle on these data structures, I haven\u0026rsquo;t implemented any of them in code in a LONG while. And I\u0026rsquo;m sure I haven\u0026rsquo;t implemented them all.\nIt sounds like a fun little project, and will give me an excuse to freshen up on my data structures. Since I\u0026rsquo;ve already done some of these a long time ago in C++, I decided this time around I\u0026rsquo;d give it a go in JavaScript. If you want to track my progress, I\u0026rsquo;ll be putting the JavaScript I write here.\n",
    "ref": "/blog/20120817-cracking-the-coding-interview-javascript-data-structures/"
  },{
    "title": "Derby.js - Working with Views, Models, and Bindings",
    "date": "",
    "description": "",
    "body": "In my previous post about derby, I talked a bit about how to create a model in derby and one rule you need to follow when creating models (the first two path segments should be an object).\nI\u0026rsquo;m creating a test application to help me learn derby here. In the process of doing absolutely everything wrong to start I\u0026rsquo;ve learned a bit about how Derby binds to models. Let\u0026rsquo;s say you\u0026rsquo;re got some markup like this that you\u0026rsquo;d like to bind to.\n\u0026lt;div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;firstName\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;lastName\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;tel\u0026#34; id=\u0026#34;phoneNumber\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;date\u0026#34; id=\u0026#34;birthDate\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Nothing sexy but you get the idea. You can post this information into a view and everything will show up the way you\u0026rsquo;d expect it to. If you want to bind this to a model, such as myApp.stuff.newGuy, changing the code is straight forward.\n\u0026lt;div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;firstName\u0026#34; value=\u0026#34;{myApp.stuff.newGuy.firstName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;lastName\u0026#34; value=\u0026#34;{myApp.stuff.newGuy.lastName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;tel\u0026#34; id=\u0026#34;phoneNumber\u0026#34; value=\u0026#34;{myApp.stuff.newGuy.phoneNumber}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;date\u0026#34; id=\u0026#34;birthDate\u0026#34; value=\u0026#34;{myApp.stuff.newGuy.birthDate}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Note that you don\u0026rsquo;t have to write any js code in your /lib/ folder to create this model. The binding [the {} information in the value attribute] will automatically wire up these fields to the myApp.stuff.newGuy model. If you want to add some default values to these fields you could accomplish this like so:\nget(\u0026#39;/\u0026#39;, function(page, model, params) { //set some default values for my model  model.set(\u0026#39;myApp.stuff.newGuy\u0026#39;, { firstName: \u0026#39;John\u0026#39;, lastName: \u0026#39;Smith\u0026#39; }); //render my template containing the model above  page.render(); }); When you browsed to the page you would see John in the firstName input and Smith in the lastName input. How would you render a similar collection of models? There are a couple of ways. To iterate through a collection of objects, you\u0026rsquo;ll most likely want to use the #each binding.\n{#each myApp.stuff.people} \u0026lt;div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value=\u0026#34;{.firstName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value=\u0026#34;{.lastName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;tel\u0026#34; value=\u0026#34;{.phoneNumber}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;date\u0026#34; value=\u0026#34;{.birthDate}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/} Several things to note here.\nFirst, you have to remove the id\u0026rsquo;s from the html inputs you are binding to. Each input needs to have a unique id. If you omit the id field from the markup, derby will generate a unique id for you. Otherwise you\u0026rsquo;ll be repeating the same id over and over again (and get strange behaviour as a result).\nSecond, in an #each binding you don\u0026rsquo;t use the full path to the model field you want to bind to (e.g. {myApp.stuff.people.firstName}), just the field with a dot prepended. (e.g. {.firstName}). Note that the dot is very important. If you just put {firstName} as your binding, because of the automatic model creation we noticed above, you will bind to a model called {firstName} for every item in the myApp.stuff.people collection. This will show itself by the very annoying behavior of every edit being mirrored in every row (since every row is binding to the same model).\nAnother way to do binding with #each is by using an alias. The documentation of creating an alias:\n Aliases to a specific scope may be defined, enabling relative model path references within nested sections. Aliases begin with a colon (:), and can be defined at the end of a section tag with the as keyword.\n What would this look like?\n{#each myApp.stuff.people as :person} \u0026lt;div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value=\u0026#34;{:person.firstName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value=\u0026#34;{:person.lastName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;tel\u0026#34; value=\u0026#34;{:person.phoneNumber}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;date\u0026#34; value=\u0026#34;{:person.birthDate}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/} Note that when you declare your alias with your each statement (as :person) you have to keep the colon for your subsequent bindings ({:person.firstName})\n",
    "ref": "/blog/20120807-derby-js-working-with-view-templates-models-and-bindings/"
  },{
    "title": "HTML5 'formaction' attribute - An easy Modernizr test",
    "date": "",
    "description": "",
    "body": " EDIT NOTE: This no longer needs to be done outside of Modernizr. This was added to the Modernizr package about a month ago. Link to issue\n I\u0026rsquo;ve been writing some Html Forms, and in playing with submit buttons came across an interesting attribute in the HTML 5 specs: formaction. The definition, from HTML Living Standard Doc\n The action and formaction content attributes, if specified, must have a value that is a valid non-empty URL potentially surrounded by spaces. The action of an element is the value of the element\u0026rsquo;s formaction attribute, if the element is a submit button and has such an attribute, or the value of its form owner\u0026rsquo;s action attribute, if it has one, or else the empty string.\n What does that mean? It means you can have a form on your page, and supply the formaction attribute to various `` buttons, and each button will post the same form to a different URL! Pretty neat, and has global acceptance in all browsers but one; Internet Explorer. Whoops. I really want to use this functionality, so I\u0026rsquo;ll come up with a shim to replace the functionality that IE is missing. For now, the only part of this problem I\u0026rsquo;ve solved is how to detect whether or not your browser supports this feature, via Modernizr\n// input[formaction] attribute // When used on an \u0026lt;input type=\u0026#39;submit\u0026#39;\u0026gt;, // this attribute signifies that the form containing // the input should post to the URL contained in the attribute // rather than the URL defined in the form\u0026#39;s \u0026#39;action\u0026#39; attribute. // By Matt Blair - Modernizr.addTest(\u0026#39;inputformaction\u0026#39;, \u0026#39;formAction\u0026#39; in document.createElement(\u0026#39;input\u0026#39;)); ",
    "ref": "/blog/20120801-html-input-formaction-attribute-an-easy-modernizr-test/"
  },{
    "title": "Australian vs US Coffee Terms Comparison",
    "date": "",
    "description": "",
    "body": "This took me a while to figure out when I first moved to Australia. I still remember the look on the barista\u0026rsquo;s face when I tried to order an Americano, and then the absolute puzzlement over what the hell a flat white vs a long black was. I hope this helps other visitors to Australia from the US order a decent cup of coffee!\n   Description Australian Name US Name     A shot of espresso. Short Black Espresso   A shot of espresso mixed with hot water. Long Black Americano   A shot of espresso topped with milk froth. Macchiato -\u0026ndash;   A cup of hot milk with a shot of expresso poured in. -\u0026ndash; Macchiato   A shot of espresso with steamed milk. Flat White Latte No Foam   A shot of espresso with steamed milk and a little milk froth. Latte Latte   A shot of espresso with steamed milk, milk froth, and cocoa powder. Mocha Mocha   A shot of espresso with half steamed milk, half milk froth. Cappuccino Cappuccino   A shot of espresso with cold milk and ice cream. Iced Coffee -\u0026ndash;   A cup of drip coffee over ice. -\u0026ndash; Iced Coffee    ",
    "ref": "/blog/20120727-australian-vs-us-coffee-terms-comparison/"
  },{
    "title": "Derby.js - Playing with Models",
    "date": "",
    "description": "",
    "body": "Been playing around with Derby in my spare time. The idea behind the platform is smart - using node and express, you write one set of code, and that code automatically syncs data between browsers, servers, and a database.\nDerby is still raw. The documentation is comprehensive but puts important information about the same topic in different places.\nI\u0026rsquo;ve culled the following eight lines of documentation of defining models from the documentation:\n Racer Paths Racer paths are translated into database collections and documents using a natural mapping: collection.documentId.document All synced paths (anything that doesn’t start with an underscore) must follow this convention. In other words, all model data stored at the first two path segments should be an object and not a string, number, or other primitive type.\n  ** Private paths** Paths that contain a segment starting with an underscore (e.g. _showFooter or flowers.10._hovered) have a special meaning. These paths are considered “private,” and they are not synced back to the server or to other clients. Private paths are frequently used with references and for rendering purposes.\n Now, this information is useful if you\u0026rsquo;re trying out the model system for the first time. The most important line (at least for my initial playing around), was this one:\nIn other words, all model data stored at the first two path segments should be an object and not a string, number, or other primitive type.\nWhat this means: if, in creating your first model, you trying something like this: model.set('people', []); you will get an error. model.set('myApp.containers.people', []); will work just fine.\nA follow up to this post is here.\n",
    "ref": "/blog/20120722-derby-js-playing-with-models/"
  },{
    "title": "Some node.js and express.js beginner help",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;ve just started using node.js with express.js on both Windows (with iisnode) and Ubuntu.\nI love the stack (one programming language from front to back!), but some of the documentation has been frustrating for me. I wanted to document what I\u0026rsquo;ve learned so far in the hopes that it\u0026rsquo;ll help someone else down the line.\nGenerate the starter app At first, I wanted to just hack away some of the existing example apps that were out there.\nThis ended up being a pretty frustrating experience as most of the basic examples were just sending \u0026lsquo;Hello World\u0026rsquo; back to the browser. I didn\u0026rsquo;t want to do much more than that when I was starting out, but I did at least want to load a basic page with some basic information I passed in.\nAfter hours of browsing blogs and the express documentation, I managed what I wanted. Right after I did this from scratch, I found out that express can generate the basic application I wanted.\n**From the express.js documentation: ** The quickest way to get started with express is to utilize the executable express(1) to generate an application as shown below:\nCreate the app: $ npm install -g express $ express /tmp/foo \u0026amp;\u0026amp; cd /tmp/foo\nInstall dependencies: $ npm install -d\nStart the server: $ node app.js But what does \u0026ldquo;generate an app\u0026rdquo; mean? When I first read those lines, I skipped right past this step, as I though I already had express and its dependencies setup correctly.\nThese commands create the basic structure of a web app (with all the basic files, folders, and dependencies installed).\nLet\u0026rsquo;s walk the commands to get a better idea what each of them does\nThe installation commands, explained npm install -g express  NPM, or the Node Package Manager, is a tool that comes with node that allows your install node packages quickly and easily from the command line. This command installs express, the popular MVC-ish framework for node.\nexpress /tmp/foo \u0026amp;\u0026amp; cd /tmp/foo This line of code installs express into /tmp/foo, then changes the directory to /tmp/foo. You can also run this command from the folder you want to install express in (just run express from the command line). You can also specify some options when you generate your starter app, such as the templating and stylesheet language you want to use.\nexpress -t jade -c stylus This command tells express you want to install in the current directory, using Jade as your template language, and Stylus as your stylesheet language.\nnpm install -d  This command installs any dependencies that express needs for the instance you have installed. Express has a couple js packages that it needs to run, so this command goes and downloads the latest version of these dependencies.\nWhat \u0026ldquo;Generate An App\u0026rdquo; Gives You  node_modules  This folder contains all the js dependencies (like express, stylus, jade, etc) that you need to run express on node.\n public  This is where your static files go (by default). By default, this folder contains three sub-folders: 1. images 2. javascripts 3. stylesheets\n routes  This is where your routing logic goes. Initially this contains one route (to your example view).\n views  This folder is the default location for the views you\u0026rsquo;ll use in your application. Views usually contain dynamic content and are often written in a templating language.\nThe last thing that\u0026rsquo;s generated is app.js, which contains a good sample of configuration code as well as the only route your example route contains:\nvar express = require('express') , routes = require('./routes'); ... app.get('/', routes.index); \nIf you jump into the routes folder, and open index.js, you\u0026rsquo;ll see your index route:\nexports.index = function(req, res) { res.render('index', { title: 'Express' }) };\nBut what does this code mean? The first line of code defines two variables, express and routes.\nThe first is a registered node module, express, and the second is just a js file.\nLater in app.js, the line app.get tells node that when the base Url of your application (something like http://localhost:3123/) is called in a browser, that the routes.index method should be called.\nBut how does routes variable in the first file get the index method, when in index.js in the routes folder only defines the index function on something calls exports?\nTo keep the system loosely coupled, node uses something called the CommonJS module format to inject dependencies into an application. One way to do this is create a function you want to be able to export to the rest of your application, then simply add your function to the exports object in your code. When you call require(PATH_TO_YOUR_FILE), any methods you added to exports will be added to the object returned by your call to require.\nThe final code is the call to res.render. This is a call to express, which is telling express to load the file \u0026lsquo;index.jade\u0026rsquo; (because in this instance, jade is the default render engine). The second parameter is a JavaScript object containing one element, title. This object is passed to the index.jade template to be rendered.\n",
    "ref": "/blog/20120710-some-node-js-and-express-js-beginner-help/"
  },{
    "title": "Using StructureMap to collect and use all instances of a given type",
    "date": "",
    "description": "",
    "body": "Had an issue at work where I wanted to store my rules and handlers for a class outside of the class definition, so I could better test the component. Found an easy way to add all your rules into StructureMap, and then retrieve those rules as a list via constructor injection.\nusing System.Collections.Generic; using System.Linq; using System.Text; using StructureMap; using StructureMap.Configuration.DSL; public class TravelRegistry : Registry { public TravelRegistry() { For\u0026lt;ITransportHandler\u0026gt;().Add\u0026lt;ApprovedAccommodationHandler\u0026gt;(); For\u0026lt;ITransportHandler\u0026gt;().Add\u0026lt;ApprovedCharterFlightHandler\u0026gt;(); For\u0026lt;ITransportHandler\u0026gt;().Add\u0026lt;ApprovedCommercialFlightHandler\u0026gt;(); For\u0026lt;ITransportHandler\u0026gt;().Add\u0026lt;ApprovedGroundTransportHandler\u0026gt;(); For\u0026lt;IEnumerable\u0026lt;ITransportHandler\u0026gt;\u0026gt;().Use(x =\u0026gt; x.GetAllInstances\u0026lt;ITransportHandler\u0026gt;()); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;StartLessThanEndRule\u0026gt;(); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;CurrentEndsAfterPreviousRule\u0026gt;(); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;CurrentStartAfterPreviousEndRule\u0026gt;(); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;UniqueEndsRule\u0026gt;(); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;UniqueStartAndEndRule\u0026gt;(); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;UniqueStartsRule\u0026gt;(); For\u0026lt;IEnumerable\u0026lt;ITravelRule\u0026gt;\u0026gt;().Use(x =\u0026gt; x.GetAllInstances\u0026lt;ITravelRule\u0026gt;()); } } ",
    "ref": "/blog/20120618-using-structuremap-to-collect-and-use-all-instances-of-a-given-type/"
  },{
    "title": "Why use Twitter Bootstrap?",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;m a fan of Twitter Bootstrap, the simple and flexible CSS, HTML, and JavaScript user interface framework.\nWhat\u0026rsquo;s not to like? Out of the box, you\u0026rsquo;ll get:\n Cross-Platform Support  IE 7 to IPhone and everything else (sorry IE6)\n12-Column Grid  A good grid system takes most of the pain out of laying out your site. Getting labels, inputs, and other pieces of your ui to layout consistently across different browsers at different resolutions can be one of the most painful parts of web development.\nSave yourself the work of trying to figure this stuff out on your own. The twitter kids have it under control.\nResponsive design  One of my favorite parts. If you craft your css/html a certain way, as the size of your browser changes (you can see this just by resizing the browser on your desktop), the layout adapts to display the information in a consistent manner as the screen size drops.\nViewing on a tablet and want to hide a left nav bar? No problem. Viewing on a phone and want to hide the menu bar? Too easy.\nBaked In Best Practices  Basically, if you want to get anything out of Bootstrap, you\u0026rsquo;ll have to adhere to their best practices. Following someone\u0026rsquo;s best practices is better than just hacking away at your CSS.\njQuery Plugins  Great interactive components, built on everyone\u0026rsquo;s favorite JS framework, that look and interactive fantastically with the rest of Bootstrap.\nLESS Infrastructure  I am a proponent of LESS/SASS/Stylus etc. If you\u0026rsquo;ve never used one, they allow you to do all sort of great software developy things with your CSS. Like set variables in one place for all the colors and sizes used by your app. Or re-use common styles without copy and paste. Or display certain styles if certain conditions are met.\nWhat are you waiting for? Check out some of the docs here and here to get started.\n",
    "ref": "/blog/20120504-why-use-twitter-bootstrap/"
  },{
    "title": "Posting an IEnumerable of Interfaces back from your Views by extending the DefaultModelBinder",
    "date": "",
    "description": "",
    "body": " Please note I came across a bug in the code, and revised this post on 31/07/2012.\n Came across an interesting problem today. In ASP.Net MVC, you can easily pass an enumerable of interfaces to your views from your controllers. As long as you have DisplayTemplates and EditorTemplates defined for the subclasses, then those classes will be rendered correctly from your enumerable of the parent interfaces.\nHowever, if you then POST to a controller method that accepts an IEnumerable, you\u0026rsquo;ll get the error message:\n Cannot create an instance of an Interface\n In looking for a solution, I found some examples online that handled abstract classes. Unfortunately, none of those examples had a way to post data back without modifying the views, and I couldn\u0026rsquo;t figure out a way either.\nHere is my solution:\n Modify your EditorTemplates to use the Type extension method defined below. This will write a hidden field to the view that defines the class being used. Example:   @Html.Type(Model)\n Register the SectionModelBinder below in Global.asax. Example:   ModelBinders.Binders.DefaultBinder = new SectionModelBinder();\n That\u0026rsquo;s it! You should be on your way to POSTing a generic list of different subclasses to a controller method.  using System; using System.Collections; using System.Collections.Generic; using System.Linq; using System.Web.Mvc; namespace ProofOfConcept { public class SectionModelBinder : DefaultModelBinder { public const string ModelTypeNameKey = \u0026#34;ModelTypeName\u0026#34;; ///\u0026lt;summary\u0026gt;  /// Creates the model.  /// \u0026lt;/summary\u0026gt;  /// The controller context.  /// The binding context.  /// Type of the base.  /// The instantiated model  ///  /// You must create a hidden field named \u0026#39;ModelTypeName\u0026#39; on the View,  /// where the value is the Full name of the class you are trying to create.  /// The HtmlHelper extension method \u0026#39;Type\u0026#39; was designed to create this field  /// and hide the implementation details.  ///  /// Currently the model you trying to create must inherit from a base class  /// that is the same assembly.  ///  protected override object CreateModel(ControllerContext controllerContext, ModelBindingContext bindingContext, Type baseType) { if (baseType.IsInterface \u0026amp;\u0026amp; (baseType != typeof(IEnumerable)) \u0026amp;\u0026amp; !baseType.GetInterfaces().Any(t =\u0026gt; t == typeof(IEnumerable)) \u0026amp;\u0026amp; !(baseType.IsGenericType \u0026amp;\u0026amp; baseType.GetGenericTypeDefinition() == typeof(IEnumerable))) { var modelTypeValue = bindingContext.ValueProvider.GetValue(bindingContext.ModelName + \u0026#34;.\u0026#34; + ModelTypeNameKey); if (modelTypeValue == null) throw new Exception(\u0026#34;View does not contain \u0026#34; + bindingContext.ModelName + \u0026#34;.\u0026#34; + ModelTypeNameKey + \u0026#34; field.\u0026#34;); var subclassName = modelTypeValue.AttemptedValue; if(string.IsNullOrWhiteSpace(subclassName )) throw new Exception(\u0026#34;View for \u0026#34; + bindingContext.ModelName + \u0026#34; does not have a value set for the \u0026#34; + ModelTypeNameKey + \u0026#34; field.\u0026#34;); var subclassType = baseType.Assembly.GetTypes().SingleOrDefault(x =\u0026gt; (x.FullName == subclassName)); var model = CreateInstance(baseType, subclassType, subclassName); if (model != null) { bindingContext.ModelMetadata = ModelMetadataProviders.Current.GetMetadataForType(() =\u0026gt; model, subclassType); } return model; } return base.CreateModel(controllerContext, bindingContext, baseType); } protected virtual object CreateInstance(Type baseType, Type subclassType, string subclassName) { if (subclassName == null) throw new ArgumentNullException(\u0026#34;subclassName\u0026#34;); if (subclassType == null) throw new Exception(\u0026#34;Could not find model \u0026#34; + subclassName); if (!subclassType.GetInterfaces().Any(t =\u0026gt; t == baseType)) throw new Exception(\u0026#34;The model of type \u0026#34; + subclassName + \u0026#34; does not implement \u0026#34; + baseType.FullName); return Activator.CreateInstance(subclassType); } } } namespace System.Web.Mvc.Html { public static class HtmlHelperExtension { public static MvcHtmlString Type(this HtmlHelper htmlHelper, object value) { if (htmlHelper == null) throw new ArgumentNullException(\u0026#34;htmlHelper\u0026#34;); if (value == null) throw new ArgumentNullException(\u0026#34;value\u0026#34;); return htmlHelper.Hidden(SectionModelBinder.ModelTypeNameKey, value.GetType().FullName); } } } ",
    "ref": "/blog/20120426-posting-an-ienumerable-of-interfaces-back-from-your-views-by-extending-the-defaultmodelbinder/"
  },{
    "title": "Horrible, Slow, Stupid, Scary Build Process",
    "date": "",
    "description": "",
    "body": "So we\u0026rsquo;ve rolled out a new build process at work. I\u0026rsquo;ve started working with a new company, and when I arrived, the build process for a new environment consisted of a 20 page manual somebody had written. The process of putting a build on an environment was slow, the manual had steps missing that everyone just \u0026lsquo;knew\u0026rsquo;, the process had multiple failure points, and was more or less a complete disaster. Every other release to PRODUCTION would have some release process error that would force devs to spend all night at work on release night, sometimes having to come in during the weekend as well.\nUsing the manual deploy to production, it took me four hours to deploy our code. I made a small mistake along the way, and it took two hours to recover.\nWith the latest release to production, we used the first iteration of a new release process. We automated the whole process, taking no more than three manual steps. While not the one step recommended in The Joel Test, a noticeable improvement and an increase in productively and reliability.\nFrom start to finish, the new process takes about a half hour. Much shorter than the manual process.\nWhy am I writing about this? Today we had a meeting about the new release process. Assigned to the next release to production was one of my co-workers, who has been with this company for a while. They made the following comment:\n \u0026ldquo;The old build process was horrible, slow, stupid and scary, but at least I knew it.\u0026rdquo;\n And was serious. I guess I don\u0026rsquo;t have to wonder anymore why no one had fixed the build process earlier.\n",
    "ref": "/blog/20120303-horrible-slow-stupid-scary-build-process/"
  },{
    "title": "Windows 7 - Problem Steps Recorder",
    "date": "",
    "description": "",
    "body": "Just found out about a good tool that ships with Windows 7.\nOne of the hardest things about debugging software can be getting the users to document what went wrong so you can test the scenario. Problem Steps Recorder - which ships with Windows 7 - records a user\u0026rsquo;s actions and documents them in an easy to understand format. It even gives the user the option of sending the recording via e-mail right from the program.\nProblem Steps Recorder takes screen shots and records input, timings, comments, app versions. It outputs them in a zipped web package. Pretty cool for recording steps to reproduce a bug! To use: start \u0026gt; run \u0026gt; psr\n",
    "ref": "/blog/20120216-windows-7-problem-steps-recorder/"
  },{
    "title": "Setting up a .NET build server WITHOUT installing Visual Studio",
    "date": "",
    "description": "",
    "body": "My client tasked me with upgrading their build server. Today, their platform builds VS 2080 solutions in .NET 3.5 - and I\u0026rsquo;ve been pushing to upgrade everyone to Visual Studio (VS) 2010 and eventually .NET 4.0. I want to upgrade the server to build a VS 2010 solution in .NET 3.5.\nThis will allow everyone to upgrade to VS 2010 while leaving the task of upgrading the production web servers to another day. I tried the easy approach. I install .NET 4.0 on the build server and run the MSBuild scripts that already exist. Nothing good happens.\nI do a little digging and find out that you need to install the Windows SDK to get MSBuild to work. I get the Windows SDK - Microsoft Windows SDK for Windows 7 and .NET Framework 4 - and install it. Nothing good happens.\nI dig a little further and find out that by default MSBuild installs pointing at the VS version of the Windows SDK whether it is there or not. Also, the Windows SDK does not care about the settings of MSBuild, so when you install the SDK it doesn\u0026rsquo;t fix this or update this. Which I understand from the SDK team\u0026rsquo;s point of view, but it would have been a nice fix.\nThe important thing to note is the keys which have \u0026ldquo;7.0a\u0026rdquo; in their values. 7.0a is the version of the Windows SDK that ships with Visual Studio 2010. If you download the SDK from Microsoft you get version 7.1. I go in and manually change all those 7.0a to 7.1. It builds! But it fails.\nFor some reason, I can\u0026rsquo;t get any of the XmlSerializers dll (web projects that have web services or WCF need these) to generate correctly. The normal dll\u0026rsquo;s compile into .NET 3.5 versions (which is what I want), but the XmlSerializers dlls all generate in .NET 4.0. What\u0026rsquo;s going on here? Another bug.\nThe Windows SDK installer, by default, installs the WRONG keys into the registry. This apparently only affects certain edge cases, like trying to generate XmlSerializer dll\u0026rsquo;s with MSBuild from .NET 4.0 into .NET 3.5. I\u0026rsquo;m guessing the Visual Studio installer fixes this when it runs. The issue is documented here: Windows 7.1 SDK targeting .NET 3.5 generates wrong embedded Resources.\nSo, another trip to the registry. This time, to the Microsoft-SDKS section. There are two bugs here:\n All the keys need to have a dash after the \u0026ldquo;WinSDK\u0026rdquo; portion Some of the fields have an \u0026ldquo;-86\u0026rdquo; in their key, which needs to be \u0026ldquo;-x86\u0026rdquo;   One more try. Build successful. :)\nValuable Old Comment Note: Antek: Unfortunately the changes in the MsBuild/ToolVersions/4.0 section can (and will) be lost when .NET patches are applied through Windows Update.\n",
    "ref": "/blog/20111031-setting-up-a-net-build-server-without-installing-visual-studio/"
  },{
    "title": "Enable/Disable jQuery buttons in Knockout with a Custom Binding Handler",
    "date": "",
    "description": "",
    "body": "Still working on those jQuery buttons. Trying to update old ASP.Net Webforms using jQuery, Knockout, and Amplify.\nNew problem today.\nI was having problems getting Knockout to enable/disable my jQuery buttons using the Knockout \u0026lsquo;enable\u0026rsquo; bindingHandler. It would enable/disable the underlying element that I had run the .button() method on, but it had no idea about the div that jQuery had wrapped my element in, or how to handle it.\nI wrote a custom bindingHandler for Knockout to handle this case. It also can handle non-jQuery elements as well, so you could change the declaration from \u0026lsquo;jEnable\u0026rsquo; to \u0026lsquo;enable\u0026rsquo;, and this would work as a all-comers enable function.\nSince this method uses jQuery (and is more expensive than the plain old \u0026lsquo;enable\u0026rsquo;), I figured the extra binding was the best approach.\nif (ko \u0026amp;\u0026amp; ko.bindingHandlers) { ko.bindingHandlers[\u0026#39;jEnable\u0026#39;] = { \u0026#39;update\u0026#39;: function(element, valueAccessor) { var value = ko.utils.unwrapObservable(valueAccessor()); var $element = $(element); $element.prop(\u0026#34;disabled\u0026#34;, !value); if ($element.hasClass(\u0026#34;ui-button\u0026#34;)) { $element.button(\u0026#34;option\u0026#34;, \u0026#34;disabled\u0026#34;, !value); } } }; } An example on how to use this:\n\u0026lt;input id=\u0026#34;btnToEnable\u0026#34; type=\u0026#34;button\u0026#34; data-bind=\u0026#34;jEnable: isEnabled\u0026#34; /\u0026gt; \u0026lt;script\u0026gt; $(\u0026#34;#btnToEnable\u0026#34;).button(); var viewModel = { isEnabled: ko.observable(true) }; ko.applyBindings(viewModel); \u0026lt;/script\u0026gt; A gist of this code is here.\n",
    "ref": "/blog/20111021-enabledisable-jquery-buttons-in-knockout-with-a-custom-binding-handler/"
  },{
    "title": "Auto Creation of jQuery Buttons using Knockout Templates",
    "date": "",
    "description": "",
    "body": "While converting ASP.NET Webforms to be more clienty using HTML 5, Knockout, and jQuery, I came across a problem.\nI want to use jQuery buttons on my Knockout-rendered rows, but whenever a new row gets added via a template, the buttons were not created as jQuery buttons. The issue was that I was calling a method to create the buttons after the page was fully rendered but never again. All the new rows wouldn\u0026rsquo;t have the .button method run on them, and thus no sparkly jQuery buttons.\nWhat to do? I\u0026rsquo;ve got button markup that looks like this:\n\u0026lt;div class=\u0026#34;jButton\u0026#34; data-icon-name=\u0026#34;refresh\u0026#34; data-bind=\u0026#34;click: refresh\u0026#34;\u0026gt; Refresh \u0026lt;/div\u0026gt; And some existing code, that given an element with class \u0026ldquo;jButton\u0026rdquo; and optionally the data-icon-name set the icon you want, creates buttons out of divs. I saw one person handle this via a new binding on the button, but I didn\u0026rsquo;t want to have to change to my existing template to get the behavior I was looking at.\nI tried a couple of different options, and while looking through the Knockout examples for other options came across the afterAdd option in the template binding. A quick change to my template binding:\n\u0026lt;tbody data-bind=\u0026#34;template: {name:\u0026#39;rowCostItem\u0026#39;, foreach: CostItems, afterAdd: function(elem) { var row = $(elem); Buttons.createFrom(row); }}\u0026#34;\u0026gt; Now I get nice jQuery buttons for all my new rows. P.S. The heart of the Buttons.createFrom() method:\nvar btn = $(this); var iconName = btn.data(\u0026#34;iconName\u0026#34;); if (iconName) { btn.button({ icons: { primary: \u0026#39;ui-icon-\u0026#39; + iconName} }); } else { btn.button(); } ",
    "ref": "/blog/20111019-auto-creation-of-jquery-buttons-using-knockout-templates/"
  },{
    "title": "Alas, it was not to be",
    "date": "",
    "description": "",
    "body": "My jQuery bug was already documented. :(\n",
    "ref": "/blog/20111014-alas-it-was-not-to-be/"
  },{
    "title": "Finished the Nike+ Importer for www.runningahead.com",
    "date": "",
    "description": "",
    "body": "I finished up the Nike+ data importer for www.runningahead.com. You can check out the code for the importer at this Github repository:\nhttps://github.com/duereg/NikePlusImporter\nI got a small test project up for this. It walks through everything but doesn\u0026rsquo;t Mock up the calls to the Nike+ service (I couldn\u0026rsquo;t be bothered). Let me know what you think.\n",
    "ref": "/blog/20111010-finished-the-nike-importer-for-www-runningahead-com/"
  },{
    "title": "jQuery UI Bug - 1.8.16, buttonset() method",
    "date": "",
    "description": "",
    "body": "I love to find bugs in good software! Came across a little jQuery UI bug today. It\u0026rsquo;s for one browser, but it always excited to be able to create an easy-to-replicate bug. The bug is small - it deals with the buttonset() method.\nThe buttons, instead of having the rounded corners on the outside, have the rounded corners on the inside. Not critical but it made the UI I was working on look strange. If you have Chrome, and are dealing with jQuery 1.6.3 and jQuery UI 1.8.16, check out the bug here:\nhttp://jsfiddle.net/AJbff/14/\n",
    "ref": "/blog/20111006-jquery-ui-bug-1-8-16-buttonset-method/"
  },{
    "title": "Beautiful LINQ to Xml",
    "date": "",
    "description": "",
    "body": "Is there anything better in life than finding a better way to do something? An easier commute, a better night\u0026rsquo;s sleep, a tastier cake recipe? In starting the Nike+ importer for www.runningahead.com, I knew I was going to have to deal with a bit of XML. Which used to mean XPath. Not so much anymore. LINQ to XML, you rock my world. It turns XML like this\u0026hellip;\n\u0026lt;extendedDataList\u0026gt; \u0026lt;extendedData dataType=\u0026#34;distance\u0026#34; intervalType=\u0026#34;time\u0026#34; intervalUnit=\u0026#34;s\u0026#34; intervalValue=\u0026#34;10\u0026#34;\u0026gt; 0.0, 0.0372, 0.0705, 0.1041, .... \u0026lt;/extendedData\u0026gt; \u0026lt;extendedData dataType=\u0026#34;speed\u0026#34; intervalType=\u0026#34;time\u0026#34; intervalUnit=\u0026#34;s\u0026#34; intervalValue=\u0026#34;10\u0026#34;\u0026gt; 0.0, 13.3866, 12.6856, 12.4970, .... \u0026lt;/extendedData\u0026gt; \u0026lt;extendedData dataType=\u0026#34;heartRate\u0026#34; intervalType=\u0026#34;time\u0026#34; intervalUnit=\u0026#34;s\u0026#34; intervalValue=\u0026#34;10\u0026#34;\u0026gt; 0, 88, 108, 115, .... \u0026lt;/extendedData\u0026gt; \u0026lt;/extendedDataList\u0026gt; With a little bit of code like this:\nwork.Snapshots = from n in extendedData.Elements(\u0026#34;extendedData\u0026#34;) select new Workout.SnapShot { DataType = n.Attribute(\u0026#34;dataType\u0026#34;).Value, Interval = (int) n.Attribute(\u0026#34;intervalValue\u0026#34;), IntervalType = n.Attribute(\u0026#34;intervalType\u0026#34;).Value, IntervalUnit = n.Attribute(\u0026#34;intervalUnit\u0026#34;).Value, Intervals = n.Value.Split(\u0026#39;,\u0026#39;).Select(p =\u0026gt; Convert.ToSingle(p.Trim())) }; into something useful. The best part - no more XPath string literals in your code. 2nd best part - that (int) cast. That isn\u0026rsquo;t really a cast - it\u0026rsquo;s actually an indirect call to Convert.ToInt32. It parses the underlying value contained in the Attribute (or Element), then converts it into the correct type. That\u0026rsquo;s the kind of coding magic I like.\n",
    "ref": "/blog/20110924-beautiful-linq-to-xml/"
  },{
    "title": "Working on Nike+ Importer for RunningAhead.com",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;m a fan of the website www.runningahead.com. I use it to track all my sporting life activities. The primary reason I use this site, instead of one of the hundreds like it, is that you can track anything - yoga, rowing, running, P-90x, underwater hockey, tiddlywinks, whatever. Throw in some customizable reporting and some great hardware integration, and it\u0026rsquo;s free, and you\u0026rsquo;ve got a winner.\nThat doesn\u0026rsquo;t mean there aren\u0026rsquo;t things I don\u0026rsquo;t like about the site, and things I wish could be better. But since it\u0026rsquo;s a free site, I\u0026rsquo;d like to help out and make the site better. I\u0026rsquo;ve talked to the site\u0026rsquo;s creator (Eric Yee) and volunteered to help craft some plugins for the site for him.\nFirst up: a Nike+ data importer. I will write the importer in C#, calling some RESTful web services, parsing XML, etc etc.\n",
    "ref": "/blog/20110921-working-on-nike-importer-for-runningahead-com/"
  },{
    "title": "",
    "date": "",
    "description": "",
    "body": "title = \u0026quot;Introducing Songbird\u0026quot; description = \u0026quot;How to have promises everywhere, all the time\u0026quot; date = 2014-02-09 post_name = \u0026quot;introducing-songbird\u0026quot; status = \u0026quot;publish\u0026quot; tags = [\u0026quot;development\u0026quot;,\u0026quot;software\u0026quot;,\u0026quot;coding\u0026quot;,\u0026quot;web\u0026quot;,\u0026quot;html\u0026quot;,\u0026quot;JavaScript\u0026quot;,\u0026quot;CoffeeScript\u0026quot;,\u0026quot;EMCAScript\u0026quot;,\u0026quot;Songbird\u0026quot;,\u0026quot;Bluebird\u0026quot;,\u0026quot;Promises\u0026quot;,\u0026quot;Generators\u0026quot;,\u0026quot;EMCAScript\u0026quot;] categories = [\u0026quot;engineering\u0026quot;, \u0026quot;technical\u0026quot;, \u0026quot;javascript\u0026quot;] layout = \u0026quot;post\u0026quot; +++ Would you rather write this: ```javascript var updateUser = function(id, attributes, callback) { User.findOne(id, function (err, user) { if (err) return callback(err); user.set(attributes); user.save(function(err, updated) { if (err) return callback(err); console.log(\u0026quot;Updated\u0026quot;, updated); callback(null, updated); }); }); }); +++ Or this: ```coffeescript User.promise.findOne(id).then( (user) → user.set(attributes) user.promise.save() ).then (user) -\u0026gt; console.log(\u0026quot;Updated\u0026quot;, user) Songbird allows you to easily mix asynchronous and synchronous programming styles in node.js.\nI based Songbird on the bluebird promise library (hence the name).\nInstall Songbird requires node version 0.6.x or greater.\nnpm install songbird Examples Without Songbird Using standard node callback-style APIs without Songbird, we write (from the fs docs):\nfs.readFile(\u0026#39;/etc/passwd\u0026#39;, function (err, data) { if (err) throw err; console.log(data); }); Using the promise property Using Songbird, we write:\nfs.promise.readFile(\u0026#39;/etc/passwd\u0026#39;).then(console.log); Object \u0026amp; Function mixins Songbird mixes promise into Function.prototype so you can use them directly as in:\nreadFile = require(\u0026#39;fs\u0026#39;).readFile; readFile.promise(\u0026#39;/etc/passwd\u0026#39;).then(console.log); Songbird adds promise to Object.prototype correctly so they are not enumerable.\nThese proxy methods also ignore all getters, even those that may return functions. If you need to call a getter with Songbird that returns an asynchronous function, you can do:\nfunc = obj.getter func.promise.call(obj, args) Handling Multiple Promises Requiring the songbird library updates the Object and Function prototype and returns a Promise library. This library allows you to carry out certain actions that are hard to handle from the promise property.\nFor example: You\u0026rsquo;re dealing with multiple promises but don\u0026rsquo;t care what order they complete in.\nPromise = require(\u0026#34;songbird\u0026#34;); Promise.all([task1, task2, task3]).spread(function(result1, result2, result3){ }); Normally when using .then the code would look like:\nPromise = require(\u0026#34;songbird\u0026#34;); Promise.all([task1, task2, task3]).then(function(results){ var result1 = results[0]; var result2 = results[1]; var result3 = results[2]; }); For more information about the underlying bluebird promise API, the API docs are here.\nDisclaimer Some people don\u0026rsquo;t like libraries that mix in to Object.prototype and Function.prototype. If that\u0026rsquo;s how you feel, then Songbird is not for you.\nContributing git clone git://github.com/duereg/songbird.git npm install npm test Songbird is written in CoffeeScript with source in src/ compiled to lib/.\nTests are written with mocha and chai in test/.\nRun tests with npm test which will also compile the CoffeeScript to lib/.\nPull requests are welcome. Please provide tests for your changes and features. Thanks!\n",
    "ref": "/blog/20140209-introducing-songbird/"
  },{
    "title": "About Me",
    "date": "",
    "description": "",
    "body": "My name is Matt Blair. Born in Virginia and now in the Bay Area. I write code during the day, play underwater hockey when I get a chance, and do other things occasionally.\nI\u0026rsquo;m the author of libraries such as songbird, js-algorithms, esvalidate, grunt-extract-sourcemap, and laboratory.\nI\u0026rsquo;m a mediocre presenter at meetups and conferences.\nYou can read about my management style here.\nI\u0026rsquo;ve contributed to projects such as emberjs, ember-data, browserify-middleware, fluentmigrator, amplify, and cassette. I help maintain write-good.\nI\u0026rsquo;ve also the author of the semi-decent sublime plugin sublime-jsvalidate and the partially worthwhile sublime-write-gooder.\nWhy a blog?\nI want to keep learning. I like to try new technologies. I am a imperfect individual. I make more than my share of mistakes. As I learn from them, I hope others out there can as well.\nI read that you learn more from a poor example than from a correct one. I don\u0026rsquo;t believe this but that means my site will be a success.\n\n",
    "ref": "/about/"
  },{
    "title": "Contact",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/contact/"
  }]
