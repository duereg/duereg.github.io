[{
    "title": "Refactoring a Legacy Codebase",
    "date": "",
    "description": "A Step-by-Step Approach - Immediate, Short, Medium, Long Term changes",
    "body": "Background In my current role, I inherited an older codebase where best practices were often overlooked. As I reviewed the code and the surrounding processes, I found numerous areas for improvement in both code quality and operational practices.\nWhere to Start? When tackling a project like this, I find it best to break down the necessary changes into four categories:\nImmediate Changes Short-Term Changes Medium-Term Changes Long-Term Changes Immediate Changes Stack Overflow used to offer a list of concrete practices that engineering companies should follow. These include specific technical and operational practices, such as:\nRepeatable Builds: Ensuring that builds can be reliably reproduced in any environment. Source Control: Using version control systems like Git for all code. One-Step Build: Implementing a one-step build process for simplicity and efficiency. Daily Deployments: Enabling and encouraging frequent code deployments to catch issues early. Bug Tracker: Utilizing a bug tracking system to manage and prioritize issues. Testing: Incorporating automated tests within the code to ensure reliability and quality. Monitoring: Setting up monitoring tools to track the performance and health of applications. Staging Environment: Maintaining a staging environment that mirrors production for testing changes. Code Reviews: Conducting code reviews to maintain quality and share knowledge. Documentation: Providing comprehensive documentation for code, processes, and systems. Some of these practices are more critical than others. For me, the following are deal breakers if they don\u0026rsquo;t exist:\nSource Control Repeatable Builds Code Reviews Monitoring Automated Tests When I started my current job, we lacked repeatable builds and automated tests. These became my top priorities, and I implemented them first.\nShort-Term Changes Once immediate priorities are addressed, focus on team-wide changes to improve code quality.\nIdentifying Problems Look at what your code reviews are highlighting. Are there issues with the current production code, such as slowness or memory leaks?\nIn my role, we had a long-standing memory leak due to a lack of development guidance and best practices. This required a detailed code review to identify problematic areas and practices, which we then addressed systematically in each pull request.\nTwo-Pronged Approach Systemic Changes: Implement automated systems to facilitate good practices. For example, use code linters and enforce code coverage standards for PRs. This allows code reviews to focus on holistic issues rather than basic formatting or style.\nProcess Changes: Establish and document the rules you want your code to follow. Create a Contributing guide and ensure code reviewers adhere to these practices.\nExamples from our Contributing guide include:\nUse Functional Components over Class Components Use invoke for events rather than send/receive where possible Use Named Functions over Anonymous functions when possible Use Custom Hooks for Repetitive UI Logic Medium-Term Changes These changes are straightforward but not easy. They often require dedicated project bandwidth to complete.\nFor us, medium-term changes included:\nMoving to shared components between systems (Internal Open Source) Transitioning to a different logging stack Creating a One-Step Build process Switching to a different compiler Developing a comprehensive integration test suite Long-Term Changes These changes are neither straightforward nor easy. They often involve structural modifications and should be approached with caution.\nIn our case, this meant restructuring a significant portion of our codebase. However, it\u0026rsquo;s crucial not to rush into these changes. Take the time to fully understand the issues at hand to avoid suboptimal solutions. The best time to make these decisions is at the last possible moment, when you have the most information.\nBy following this approach, you can systematically improve your codebase and development processes, ensuring a more robust and maintainable system for the future.\n",
    "ref": "/blog/20240305-refactoring-a-legacy-codebase/"
  },{
    "title": "Hiring for an Early-Stage Team",
    "date": "",
    "description": "How to build a foundational team",
    "body": "These are some notes I took from a hiring event I attended. I hope they help someone in the future (even if that someone is me).\nThe Impact of Your First Hires The first team members will shape the culture and set the operational norms for your company. Their influence is profound and lasting, making it essential to focus on two primary criteria when hiring:\nCompetence: Can they get the job done? Collaboration: Can they work well with others? Recruitment: A Time-Intensive, High-Stakes Process Recruiting for early-stage teams is time-consuming and requires a focus on quality over cost. Always recruit to specification, not to budget. This means hiring individuals who exhibit universally valuable traits:\nResourcefulness Self-awareness Hard-working and committed High integrity Good attitude High personal and professional standards Effective communication (context-dependent) Do not lower your standards due to workload pressures. A bad hire can create more work and disrupt team dynamics.\nUpholding High Standards It\u0026rsquo;s common to feel that your standards are too high during the hiring process. Maintain confidence in your criteria, and trust that the right candidate will come along. Being organized and in sync during the hiring process sends a strong signal about your company\u0026rsquo;s culture. Disorganization is a red flag to potential hires.\nClear Communication and Documentation Over-communicate and over-document every aspect of the hiring process. Assign a single point of contact for each role or candidate to ensure clear and consistent communication. Every candidate should always know their status in the process. Ghosting is unacceptable.\nWriting things down helps clarify and align the team on various aspects, such as: Role scope and job description Hiring process and decision-makers Ideal candidate profiles Motivational Red Flags Be cautious of candidates primarily motivated by: Getting rich Fancy titles Leading large teams Becoming public spokespersons Such motivations often lead to dissatisfaction.\nLeveraging Networks and Team Involvement Referrals from your network are the best way to find top candidates and yield the highest return on investment. Everyone on your early team should be involved in hiring decisions to foster trust and alignment.\nUse Slack channels to keep the team updated on hiring progress: Role-specific channel: Weekly updates about the candidate pipeline. Candidate-specific channel: Detailed updates and team impressions. Diversity and Inclusion Prioritize getting Under Represented Groups (URG) and Under Represented Minorities (URM) on your early team. Once you have a large team of white men, diversifying becomes significantly harder.\nPreparing the Team for Hiring Define what makes a candidate a good fit for your company. Consider how they will work within your specific context. Develop a clear perspective on essential qualities and ensure everyone agrees on what\u0026rsquo;s necessary versus nice-to-have.\nDefining the Hiring Process Clarify the decision-making process. Determine if everyone must agree or if there’s a tie-breaker. Identify potential candidates by sharing LinkedIn profiles of individuals who exemplify the ideal candidate. Define outcomes and role scope clearly.\nCreating a Job Description A well-crafted job description is crucial. It should include:\nA brief explanation of what the company does and its ambitions. Reasons to believe in the company\u0026rsquo;s potential. A title that captures attention. Day-to-day responsibilities framed as questions or problems to solve. A personal, engaging tone. Clear instructions on how to apply. Structured Interview Process Don’t just throw candidates into interviews. Each interview should assess specific competencies. Prepare an interview plan outlining:\nEvaluation criteria (hard and soft skills) Interview phases and owners Specific questions for each phase Keep the total candidate time to about 10-15 hours.\nEvaluating Candidates Use a structured evaluation process to avoid bias. Have everyone rate candidates decisively and make final decisions promptly. Attitude and cultural fit are critical, especially for small teams.\nMaking Offers Create clear standards and guidelines for offers. Ensure fairness in compensation and equity to maintain trust within the team. When extending an offer, be specific about why you chose the candidate to make them feel valued.\nClosing Candidates Closing requires a concerted effort:\nAssign an owner for the closing process. Engage the entire team in welcoming the candidate. Use personal touches like handwritten notes or celebratory meals. Parting Ways If someone isn’t performing, address it within three months. Delaying necessary terminations is detrimental to both the team and the individual.\nBy adhering to these guidelines, early-stage companies can build a resilient, high-performing team that sets the stage for future success.\n",
    "ref": "/blog/20231206-early-team-hiring/"
  },{
    "title": "Decoding the Origins of CAN Reports",
    "date": "",
    "description": "A SitRep in three parts",
    "body": "In the realm of incident management, accurate and swift communication is vital. Different organizations adopt various strategies to ensure efficient communication during emergencies. One such strategy that has been gaining traction is the utilization of CAN reports, a mnemonic that stands for “Conditions, Actions, Needs.” Let us delve deeper into the intricacies and origins of this unique reporting format.\nWhat is a CAN Report? A CAN report, fundamentally, serves as a structure to relay critical information succinctly during an incident. It breaks down the report into three primary segments:\nConditions: This part describes the current situation, giving a clear picture of what is happening. Actions: Here, the actions taken so far are detailed, offering an understanding of the steps undertaken in response to the conditions. Needs: This segment outlines what is required or needed next, paving the way for a structured request for resources or further actions. Origins of the CAN Report The origin of this format traces back to the U.S. fire departments where it was utilized as a standard mnemonic for radio reports. However, its practicality and effectiveness have seen it being adopted in various other sectors, including IT incident management.\nOne of the pioneers in bringing this format to the IT sector has been the consulting firm, Blackrock 3 Partners, which specializes in IT incident management training based on best practices derived from the emergency services sector. They not only offer a certification program for IT incident responders but have also extensively discussed the utility of CAN reports in a podcast.\nThe Debate: CAN Report or SitRep? While the CAN report has established its foothold in incident reporting, there is a conversation to be had about its nomenclature. Some industry experts believe that the term \u0026ldquo;CAN report\u0026rdquo; might be a misnomer and that it could more appropriately be called a \u0026ldquo;Situation Report\u0026rdquo; or \u0026ldquo;SitRep.\u0026rdquo;\nThe reasoning behind this alternative terminology is that the CAN structure can effectively be employed in various reporting contexts, not limited to just incident reports. The term \u0026ldquo;SitRep\u0026rdquo; would, therefore, highlight the format\u0026rsquo;s flexibility and wide-ranging applicability, making it a mnemonic tool useful in a variety of situations, and not restricting it to a specific kind of report.\nEducational Resources For those keen on exploring the historical background and usage of CAN reports in depth, a resourceful PowerPoint presentation that hails from a fire department training deck is available. It offers a detailed history and utilization of CAN reports, elucidating how this tool has evolved over time.\nConclusion Whether you prefer calling it a CAN report or a SitRep, what remains undeniable is the format\u0026rsquo;s efficiency in structuring communications during emergencies and critical incidents. Its origin from the U.S. fire departments to its contemporary application in IT incident management is a testimony to its practicality and adaptability in high-pressure situations.\nAs we wrap up, we invite you to reflect on the potential of adopting the CAN report format or the broader SitRep structure in your organization’s incident management strategies, to foster clarity and structured communication in critical moments.\nSpecial Thanks I would like to extend a heartfelt thank you to Brent Chapman and Tricia Bogen for their contributions to my understanding of CAN reports. Brent\u0026rsquo;s detailed explanations and historical insight, coupled with Tricia\u0026rsquo;s engaged and thoughtful questions, were incredibly helpful. Their expertise has not only shed light on the nuances of CAN reporting but also opened up a rich discussion on its functionality and application.\n",
    "ref": "/blog/20230907-can-reports/"
  },{
    "title": "Strategic Approaches for Technical Improvement",
    "date": "",
    "description": "",
    "body": "Introduction Technical debt is a common challenge faced by engineering teams, requiring deliberate efforts to manage and pay it down. In this blog post, we will explore different approaches to tackling technical debt and building a long-term technical strategy. We will also highlight the importance of involving senior individual contributors (ICs) and engineering managers (EMs) in shaping the strategy, while considering the alignment with business and product goals.\nEngaging Senior ICs and EMs in Technical Strategy To ensure a comprehensive technical strategy, it is essential to involve experienced ICs and EMs in the decision-making process. This engagement helps leverage their expertise and insights while creating a collective vision for the engineering function. The strategy-setting process can involve quarterly planning sessions, where EMs and tech leads define the engineering priorities, with input from ICs. This approach enables a bottom-up approach, empowering the team to contribute their perspectives.\nLong-Term Strategy vs. Short-Term Roadmaps While quarterly planning sessions address immediate engineering goals, a long-term strategy focuses on broader aspects such as language choices, technological advancements, and developer experience (DevX). It considers the growth trajectory of the engineering function as a whole. In contrast, short-term roadmaps tend to be more reactive, addressing immediate challenges and technical debt. Balancing both long-term strategy and short-term roadmaps is crucial for sustainable technical development.\nConducting Technical Audits A technical audit is a valuable exercise to gain a clear understanding of the existing technical state and identify areas of improvement. ICs can drive this process, examining code quality, system scalability, and infrastructure bottlenecks. The audit results inform the roadmap for addressing technical debt and identifying priorities for future development. By involving ICs directly in this process, you tap into their technical expertise and ensure a bottom-up perspective.\nMeasuring the Technical State of the Team To track progress and maintain visibility on technical improvements, it is crucial to establish measurable metrics. Metrics such as code coverage, system performance, and reduction in technical debt can provide a quantifiable view of the team\u0026rsquo;s progress. Regularly reviewing these metrics enables better decision-making and helps prioritize efforts effectively. This blog provides some guidance on measuring the technical state of the team and tracking progress.\nEmbracing Proactive Technical Improvements Shifting the mindset from \u0026ldquo;technical debt\u0026rdquo; to \u0026ldquo;technical improvements\u0026rdquo; helps foster a proactive approach to engineering challenges. While technical debt refers to systems that require attention due to accumulated compromises, technical improvements encompass a broader scope. This includes scaling systems beyond current limitations, anticipating future growth, and modernizing outdated components. Recognizing the need for both reactive and proactive improvements is key to maintaining a healthy technical ecosystem.\nConclusion Developing a strategic approach to tackle technical debt is crucial for long-term engineering success. By engaging senior ICs and EMs, conducting technical audits, and measuring progress, teams can create a roadmap that addresses immediate challenges while considering long-term growth. Embracing proactive technical improvements helps foster a forward-thinking mindset, ensuring systems are resilient and adaptable. By aligning the technical strategy with business and product goals, organizations can establish a solid foundation for sustainable technical development.\n",
    "ref": "/blog/20230508-tech-improvement-roadmap/"
  },{
    "title": "Crunch Time",
    "date": "",
    "description": "Approaches for Formalized Recovery Time",
    "body": "Crunch periods are a reality in many industries, and sometimes they are necessary to meet an immovable deadline. However, working under high-pressure situations for an extended period can lead to burnout, and it\u0026rsquo;s essential to provide support for the team after the crunch is over. In this blog post, we will discuss different approaches for formalized recovery time after a crunch period.\nAsk team members what would make them feel valued One approach is to ask team members what would make them feel valued after the crunch period. It could be anything from time off to a dinner paid for by the company for them and their family. By listening to their needs and responding accordingly, you show that you care about their well-being and appreciate their hard work.\nRecord extra work time as PTO Another approach is to use a formal policy for recovery time. For example, for every day worked that you wouldn\u0026rsquo;t usually work, such as a weekend, record it, and then once the project ships, immediately use that time off as \u0026ldquo;free\u0026rdquo; PTO. This gives people time to recover and reset.\nSet cultural expectations for team recovery time In a company with unlimited PTO, it might be more challenging to provide formalized recovery time. In this case, setting cultural expectations for team recovery time is crucial. Encourage team members to take time off and make it clear that the company values their well-being. Creating an environment where people feel comfortable taking time off after a crunch period can go a long way towards reducing burnout.\nSchedule group recovery time When giving people time off, it\u0026rsquo;s essential to consider the timing. One tactic to consider is having everyone go on PTO or work half-time at the same time. This approach can be more restful for individuals as they know that everyone else is also away, and they don\u0026rsquo;t have work that they\u0026rsquo;re missing out on or have to catch up on. Scheduling group recovery time can also be an excellent opportunity for team building and creating a shared sense of recovery.\nSchedule a recovery project These are typically inspiring or \u0026ldquo;fun\u0026rdquo; exploratory engineering projects that have no real stakeholders. For these, the person might end up doing non-shippable work and it is fine because no one was really counting on it anyway. This could be some technical improvements that the person was looking to make or shipping an internal feature that would make their life easier. These type of projects can be a nice active recovery that gets them inspired again.\nConclusion Crunch periods can be necessary to meet immovable deadlines, but they can take a toll on the team\u0026rsquo;s mental and physical well-being. Providing formalized recovery time can help support the team and reduce the risk of burnout. By using one or more of the approaches discussed above, you can show that you care about your team\u0026rsquo;s well-being and value their hard work. It\u0026rsquo;s crucial to create an environment where recovery time is normalized, so people don\u0026rsquo;t feel guilty about taking time off after a crunch period.\nHowever, note that even if you institute all of these policies, you may still suffer attrition from people who are burnt out. Depending on the length of crunch, there\u0026rsquo;s no amount of time that can fully heal a burnt out person.\n",
    "ref": "/blog/20230404-crunch-time/"
  },{
    "title": "Improving Software Quality",
    "date": "",
    "description": "Leading Metrics to Measure and Strategies to Implement",
    "body": "As a manager, you\u0026rsquo;re responsible for ensuring that the software your team creates is of the highest quality possible. This means reducing the number of bugs and improving code quality. But how do you measure these improvements? And what strategies can you implement to achieve them?\nMeasuring Quality One traditional way of measuring quality is by the number of bugs that are found and fixed. However, this is a lagging metric, meaning that you can only measure it after the damage has been done. Instead, leading metrics can be used to predict the quality of the software before any bugs are found. Two examples of leading metrics are code quality and test coverage.\nCode Quality Code quality can be measured by using tools such as Codeclimate. These tools analyze your codebase and provide a report on the quality of your code. This includes metrics such as code complexity, duplication, and style consistency. By continuously monitoring and improving code quality, you can prevent bugs from occurring in the first place.\nTest Coverage Test coverage is another leading metric that measures the amount of code that is covered by automated tests. By implementing a code coverage floor, you can ensure that your team cannot release code that falls below a certain level of test coverage. As new code is added, the code coverage will naturally decrease, but by breaking the build when this happens, you can ensure that your team adds tests to maintain the required level of coverage. This strategy has been proven to rapidly increase code coverage and decrease the number of bugs.\nStrategies to Implement In addition to measuring quality, there are several strategies that you can implement to improve it.\nTest-Driven Development One effective strategy is to implement Test-Driven Development (TDD). With TDD, you write tests before you write code. This ensures that your code meets the requirements and prevents regression bugs from occurring. Every bug fix that is put into place should have a corresponding test that would have caught the regression. This approach can be especially effective when working on legacy code, as it provides a safety net when making changes.\nPeer Verification Another strategy is to implement peer verification. For every completed ticket, another developer on the team has to verify that it works as expected. This means that the person who wrote the code has to figure out how to test the change, document that, and then explain it to someone else, who then tests it. This strategy can be useful for teams that have bad habits, and if you don\u0026rsquo;t have good automated tests, it can catch a lot of small issues before they\u0026rsquo;re merged.\nEnd-to-End Test Coverage Finally, you can think about your end-to-end test coverage per page, endpoint, or flow. For example, if your app has 5 distinct UI flows, you should have a corresponding number of headless, automated browser tests for each of those flows. Similarly, if you have 10 API endpoints you support, you should have a corresponding number of automated integration tests for each of those endpoints. By measuring end-to-end test coverage, you can ensure that all critical paths are covered and prevent bugs from occurring.\nConclusion Improving software quality requires a combination of measuring and implementing strategies. By using leading metrics such as code quality and test coverage, you can predict and prevent bugs from occurring. Strategies such as TDD, peer verification, and end-to-end test coverage can be implemented to improve code quality and reduce the number of bugs. By continuously monitoring and improving software quality, you can ensure that your team delivers high-quality software that meets the needs of your customers.\n",
    "ref": "/blog/20230327-code-quality/"
  },{
    "title": "Moving Between Tech Stacks",
    "date": "",
    "description": "How difficult is it?",
    "body": "When it comes to software engineering roles, experience in the tech stack you\u0026rsquo;re going to be working in is valuable but not specifically required. A good engineer can ramp up and learn new stacks. However, someone experienced in the tech stack can contribute quickly to key development initiatives, while also bringing outside experience using the stack.\nBut which tech stacks are easier to move between, and which ones are the hardest? In my experience, when I’ve transitioned from one stack to another, it took a little while to get my footing. But if you already have experience, you can share that experience to up-level the team.\nStacks can be grouped around concepts. For example, a Java stack and a .NET stack have similar OOP concepts, so the typical migration is pretty easy. Similarly, languages like Python, Ruby, and JavaScript are by default weakly typed, so the concepts are the same and it should be easy to port over. However, if the developers on that stack have only used it in one way (e.g., Ruby on Rails, Python/Django, Node/Express), it might be difficult to master the concepts of what the other stack is doing.\nAdditionally, some shops roll their own software and only use native libraries, while others use a lot of third-party libraries and open-source software (OSS). Moving from a closed-source shop using .NET to an OOS shop using Java (think Java Spring Boot) might actually be really difficult if you\u0026rsquo;ve never seen that paradigm.\nThere are also other factors to consider. For example, in Ruby, extensions are \u0026ldquo;baked\u0026rdquo; into the language, and the order you import the packages actually changes how the language behaves. The use of middleware as a concept in your stack vs. a stack that doesn\u0026rsquo;t use middleware can also be a challenge. And a JavaScript stack that heavily uses promises vs. something that uses async/await (or a stack that doesn\u0026rsquo;t use these concepts at all) can require a different mindset.\nAdd in type hints in Python, or TypeScript in JS, and you have another ball of wax.\nSo, which tech stacks are easiest to move between? I like to think that the more OSS-friendly, weakly-typed languages are easier to move between. If you get any good at one of these stacks, you typically have to learn a bunch of other concepts (how OSS works, SemVer, modules, duck-typing, etc.).\nThe ramp-up time for engineers changing stacks is also mitigated a bit by the stack they\u0026rsquo;re coming from. Someone moving from Java to .NET is going to have a shorter ramp up than someone moving from Java to Python (strongly-typed OOP to weakly-typed scripting language) or vice versa. Someone moving from JavaScript (weakly-typed scripting) to Haskell (strongly-typed functional) or vice versa would take even longer.\nHowever, it really depends on your company\u0026rsquo;s mentorship abilities and your ability to be patient as their manager. I think it\u0026rsquo;s hardest to make the migration from a closed-source shop that uses a strongly-typed language to almost anything else. For example, if you\u0026rsquo;re used to working at a bank or for the government on a .NET platform where you\u0026rsquo;re only allowed to use the baked-in MS libraries, then moving to a startup using Python and Django and 100+ other OSS modules might be very challenging.\nWhat they\u0026rsquo;re doing in the stack might impact how quickly they ramp up as well. For example, a person coming from a web dev background in Ruby might find moving to web dev in Python/JS pretty easy. A data engineer moving from Python to Python web dev might really struggle outside of the language\n",
    "ref": "/blog/20230302-changing-stacks/"
  },{
    "title": "Promoting Technical Excellence in your Organization",
    "date": "",
    "description": "",
    "body": "I was speaking to a friend who works at a startup with a team of around 14 engineers. 80% of them are mid level engineers with 3-4 years of experience. They all work in product squads covering specific areas.\nThese have lost momentum in the development and they are seeing 2 key problems:\nThe teams lacks direction on where to focus their energy and prefer tackling small issues as they don\u0026rsquo;t have a vision as to what impactful engineering initiatives to do. They are struggling to find time to work on technical debt. There is a perception that they should be working on Product work all the time. She had originally proposed two solutions, but wanted to hear my thoughts:\nAllocating a percentage of time per week to work on tech debt. Getting the Tech Lead and EMs to set the technical direction of what to work on. In our view solution 1 sounds like it might help relieve some of problem 2 but not really address problem 1.\nSolution 2 would solve the issues, but she was worried that would take the autonomy/empowerment from engineers to really own those initiatives.\nI\u0026rsquo;ve seen both of these approaches tried in other organizations. We ended up steering the conversation towards engineering planning on product initiatives.\nEngineering planning on product initiatives is not exactly her 2nd solution - where tech leads pick the tech debt to work on. It\u0026rsquo;s more a strategy along the lines of establishing a technical culture for your org.\nAn example: Product wants to add a button a screen. You could leave it at that and an engineer could code up a solution. In high-functioning engineering organizations, the leadership has set up a set of principles that allow you to bake in engineering excellence work along the way. So for this example, a couple principles that might apply:\nThe page has to load in under 1 second All new code has to have corresponding unit tests All new UI features have to corresponding headless browser tests The APIs that support the page have to respond in under 200ms. etc etc etc So as the developer is doing the work, they\u0026rsquo;re baking in engineering excellence. If adding the button slows down the page dramatically, they have to figure out a way to get the page load time down.\nThe person reviewing their code has to check for the presence of the right kind of tests. Someone has to verify the new data being used by the button doesn\u0026rsquo;t slow down the system.\nAll of these are cultural things that slow down development slightly, but they leave with a durable foundation that accelerates your development later on.\nWhile your engineering leadership should provide the standards you want to operate on, it gives the engineers working on the project the freedom to solve as they see fit. By promoting a set of engineering standards you\u0026rsquo;ve removed the need of your technical leaders to push forwards engineering excellence on every project. It is still your engineering leadership\u0026rsquo;s responsibility to make sure the principals are enforced.\nTechnical leadership can also contribute to the effort by tracking down all the bugs/issues/feature requests related to the new project at the beginning of the project planning, and making sure the most important of these are prioritized.\nThis allows developers to drive the technical excellence of their products, by baking in their principals into their projects and their everyday practices.\nIt removes the idea of needing 20% time to pay down technical debt. You pay down your debt on every project. If you\u0026rsquo;re touching code that needs improvement, it\u0026rsquo;s part of the project itself. The larger the project, the larger the amount of debt you can pay down\n",
    "ref": "/blog/20230221-technical-excellence/"
  },{
    "title": "Interesting Articles for Engineering Managers",
    "date": "",
    "description": "",
    "body": "Engineering Leadership Principles The article \u0026ldquo;Engineering Leadership Principles\u0026rdquo; by Hugo Dias outlines six principles that he believes are crucial for effective engineering leadership:\nBuild trust through transparency and communication Foster a culture of learning and growth Prioritize quality and reliability Lead with empathy and emotional intelligence Build strong, diverse teams Empower your team to take ownership and make decisions Dias provides examples and anecdotes to illustrate each principle and explains why they are important. He also notes that while these principles are essential for engineering leadership, they can also be applied to leadership in other industries.\nHow to Onboard into a New Job The article titled \u0026ldquo;How to Onboard into a New Job\u0026rdquo; provides tips and recommendations for professionals who have started a new job and want to make the most of their onboarding process. The author suggests that new employees should take advantage of the opportunity to learn about the company\u0026rsquo;s culture, processes, and expectations, as well as build relationships with their colleagues and stakeholders.\nThe article provides several practical suggestions for new hires, such as scheduling one-on-one meetings with key stakeholders, asking questions, taking notes, and setting goals for their first few months. The author emphasizes the importance of being proactive and taking ownership of one\u0026rsquo;s own onboarding process, rather than expecting the company to provide all the necessary guidance and resources.\nThe article also recommends that new employees take the time to understand their team\u0026rsquo;s priorities and goals, as well as familiarize themselves with the tools and technologies used by the company. The author suggests that new hires should seek feedback and communicate openly with their manager and team members, and take advantage of any training or development opportunities offered by the company.\nOverall, the article encourages new hires to approach their onboarding process with a positive attitude, curiosity, and a willingness to learn and adapt to their new environment. By taking an active role in their onboarding process, new employees can set themselves up for success and integrate more effectively into their new role and organization.\nSix Coding Interview Formats The article proposes six alternative coding interview formats that can be used to replace LeetCode-style interviews. The author argues that while LeetCode-style interviews are effective in measuring algorithmic problem-solving skills, they do not reflect the realities of day-to-day coding work. The proposed alternative interview formats are:\nPair Programming: The candidate pairs up with an interviewer to solve a coding problem together, allowing the interviewer to observe the candidate\u0026rsquo;s coding skills in real-time.\nCode Review: The candidate is asked to review and provide feedback on a codebase, demonstrating their ability to identify bugs, improve code quality, and communicate effectively.\nDesign Discussion: The candidate is asked to design a system or feature, showcasing their ability to understand requirements, identify trade-offs, and communicate technical concepts clearly.\nDebugging: The candidate is given a codebase with bugs and is asked to identify and fix them, demonstrating their ability to navigate complex codebases and debug effectively.\nExisting Project: The candidate is asked to work on a real project from the company\u0026rsquo;s codebase, allowing them to see the kind of work they would be doing if they joined the company.\nTake-Home Assignment: The candidate is given a realistic coding assignment to complete on their own time, allowing them to work at their own pace and showcase their ability to write code independently.\nThe author argues that using alternative interview formats can provide a more accurate assessment of a candidate\u0026rsquo;s coding skills and fit for the company, while also creating a more inclusive and equitable hiring process.\nAI Generated Performance Reviews https://review.gobudapest.io/\nWrite Performance reviews with the help of ChatGPT Writing an effective performance review with AI Are you looking for guidance on how to write better performance reviews for your team members? ",
    "ref": "/blog/20230201-link-dump/"
  },{
    "title": "Mentorship Proposal",
    "date": "",
    "description": "",
    "body": "Note: This is a proposal I put together with one of the engineers in my organization for a peer-directed mentorship program. I\u0026rsquo;ve removed names and fudged numbers but I hope it will serve as a valuable template. All other numbers quoted here are from outside studies, with links to the studies provided.\nPeer Mentorship Proposal The most valuable asset of a company are its employees.\nAmong top reasons for millennials wanting to quit their jobs are \u0026lsquo;Not enough opportunities to advance\u0026rsquo; at 35% and \u0026lsquo;Lack of learning and development opportunities\u0026rsquo; at 28%.\nThis ought to be a top priority for companies, considering millennials will comprise more than 75% of the workforce by 2025.\nSo what is a high impact, low cost program we can put into place that will help employees grow in their careers, collaborate cross functionally while leading them to feel appreciated for their hard work and successes?\nMentorship Workplace mentoring programs help employees do the right thing by exposing them to senior employees that know how to do the right thing. This helps the employee perform more effectively and gives the employee more satisfaction.\nMentorship has positive aspects in many areas of a company:\nMentees Mentors The Business Positive Impact on Mentees 94% of employees said they would stay at a company longer if they were offered opportunities to learn and grow. 71% of people with a mentor say their company provides them with good opportunities to advance in their career, compared with 47% of those without a mentor. 87% of mentors and mentees feel empowered by their mentoring relationships 79% of millennials see mentoring as crucial to their career success 89% of those who have been mentored will also go on to mentor others, and so contribute to this cycle of learning and development within an organization.\nPositive Impact on Mentors\nThe company has identified coaching as one of the most important aspects of our tech leads here.\nThe most important part of a Tech Lead’s role, coaching means sharing expertise with others.\nHaving a mentorship program will allow our leads to spread their expertise throughout the organization.\nHarvard Business Review conducted a study researching the positive effects mentoring can have on the mentors themselves, and found that people who served as mentors experienced lower levels of anxiety, and described their job as more meaningful, than those who did not mentor.\nWe’ve already called out that 87% of mentors and mentees feel empowered by their mentoring relationships.\nAnother positive aspect for mentors is that mentorship provides career advancement opportunities to employees aspiring for promotion. Being able to teach and guide others, and having cross-functional impact across the organization is called out in our career development matrix as a key requisite of any staff level position.\nBusiness Impact\n67% of businesses reported an increase in productivity due to mentoring. 55% of businesses felt that mentoring had a positive impact on their profits. This will have a positive impact on recruiting and retaining talent. 79% of millennials see mentoring as crucial to their career success, and 94% of employees said they would stay at a company longer if they were offered opportunities to learn and grow. Being able to call out a formal mentorship program as part of our recruiting pitch should help us differentiate from our competitors, and help us retain talent once they join our company.\nNext Steps\nIf this has tacit endorsement from leadership, we need to devote some time to put together a full proposal and begin the work on getting the program started, answering the following strategic questions:\nWhat type of mentorship will this program foster? How do we communicate the benefits for mentors and mentees? What is the commitment expected from participants? How do we remove as many barriers to entry as possible? How will we monitor progress and report success? At a high level, here are our initial thoughts on these questions.\nWhat type of mentorship will this program foster?\nWe are envisioning a one-on-one, peer mentorship program. Mentors will be roughly three to five years ahead of their mentees in their career, and will help them navigate their current career challenges and growth.\nIn order to facilitate career growth, mentors and mentees should be open and honest with each other. To promote that honesty, there should be a reasonable expectation of privacy. Mentors should not gossip about their mentees’ challenges to others. Mentors are not secondary managers, and are not evaluating or judging the mentees.\nWhile the mentoring pairs should get to know each other, the goal of this relationship is the career development of the mentee. The problems being addressed should be career related.\nHow do we communicate the benefits for mentors and mentees?\nOur proposal is to advertise many of the benefits of mentorship mentioned in this document in Slack and an email to the org, and ask folks to sign up if interested for a beta program. We’ll create a semi-automated registration process that will allow us to pre-screen interested parties to make sure we select the best candidates for our initial program.\nFor both mentors and mentees, we’ll look for participants who:\nAre enthusiastic about being in a mentoring relationship Have the time and commitment to meaningfully engage in the pilot program In mentors, we’ll look for the following additional qualities:\nEmpathy Have been in a successful mentoring relationship before, preferably as mentors but as a mentee works as well Has intermediate stage career experience (Staff Engineer or above) Are willing to connect on a human level and be vulnerable, as well as share their knowledge and expertise Are willing to listen and meet their mentee where they are Mentee qualities:\nWilling to be honest with where they could use help in their career Willing to articulate and share their career goals Have a growth mindset and are willing to listen to and action feedback Ready to drive the relationship and conversation Know what they want, just need help getting there For the initial beta program, we’ll target mentors who have previous mentorship experience, and for mentees we’ll look to prioritize developers from under-represented groups, as these groups typically suffer the largest gaps in mentorship.\nWhat is the commitment expected from participants?\nThis first program will have a limited timeframe (around 3-6 months) and the meeting schedule will be set between mentees and mentors, to best match the availability of the mentors and the needs of the mentee.\nThe mentee is responsible to set up meetings with their mentors and figure out a schedule that works for both of them. The cadence of meetings is set by the mentor \u0026amp; mentee. Regular meetings will work for some, on-demand, ad hoc scheduling will work for others.\nThis program will be mentee driven; the goal of this is not to have another person for people to answer to, but to have a sounding board for problems they may be facing in their career.\nBoth mentors and mentees will be responsible to fill out pre and post program questionnaires.\nHow do we remove as many barriers to entry as possible?\nWe’ll cap the initial group for this at 20-30 so it’s easy to spin up and manage, so we can iterate and learn from a small group.\nWe\u0026rsquo;ll reach out multiple times, through various channels to the organization if we do not have an exciting first round of applicants.\nFor each mentee, we will choose a few (2-3) potential mentors. The mentoring candidates should be at or above the level where the mentee is trying to get to. The candidates should also have experience with achieving the mentee’s goals or overcoming the mentee’s hurdles. The mentor and mentee won’t work together closely on a daily basis, as some clinical distance allows for honest conversations. We will then let the mentee choose the mentor.\nThese pairs are not set in stone; if they decide after a meeting that it isn’t a good fit, they can let us know and we’ll pair them with another participant. However, since the pool will be limited for the first group, this might mean waiting until a wider release.\nWe’ll spin up a FAQ page with details of the program and what we’re planning on offering to the organization. That page will link to training materials and other media which will help educate the folks interested in the program in its benefits and how to proceed. \u0026ldquo;Being a good mentor\u0026rdquo; and æBeing a good mentor and mentee\u0026quot; are two example videos found on LinkedIn learning. We will come up with written guidelines on how to be a good mentor and a good mentee.\nEach relationship will be unique and structured by the participants, but we will give each pair a default relationship plan to get them started and unstuck if necessary. The plan will include suggestions for the meeting cadence, a first meeting blueprint, and tips on how to move forward when things start to get in a rut.\nWe’ll also make the program easy to join and organize.\nHow will we monitor progress and report success?\nDuring the registration process we’ll also ask a few survey questions to gauge how the potential mentors/mentees feel about the company. This will help us later track progress with the program and see if it\u0026rsquo;s working effectively. The results we have from the before/after survey results will be reported up to leadership.\nMajor KPI to measure Employees feel appreciated for their hard work and successes Minor KPI to observe Employees feel we have effective cross-functional collaboration ",
    "ref": "/blog/20230131-mentorship-proposal/"
  },{
    "title": "Technical State of the Team - Expanded",
    "date": "",
    "description": "",
    "body": "Note: This is a compliment to the previous article I wrote about the Technical state of a Team, and explains the concepts in depth.\nTechnical State of the Team There’s a saying that people don’t leave companies, they leave managers. Management is a key part of any organization, yet the discipline is often self-taught and unstructured. Getting to the good solutions for complex management challenges can make the difference between fulfillment and frustration for teams, and, ultimately, between the success and failure of companies.\nIn Will Larson’s excellent book An Elegant Puzzle focuses on the particular challenges of engineering management—from sizing teams to handling technical debt to performing succession planning—and provides a path to the good solutions.\nOne of the early concepts in An Elegant Puzzle centers around the Four States of a Team:\nThe framework starts with vocabulary for describing teams, their performance within their surrounding context. Teams are slotted into a continuum of four states:\nA team is falling behind if each week their backlog is longer than the week before. Typically folks are working extremely hard but not making much progress, morale is low, and your users are vocally dissatisfied. A team is treading water if they’re able to get their critical work done, but are not able to start paying down technical debt or start major new projects. Morale is a bit higher, but folks are still working hard and your users may seem happier because they’ve learned that asking for help won’t go anywhere. A team is repaying debt when they’re able to start paying down technical debt, and are beginning to benefit from the debt repayment snowball: each piece of debt you repay leads to more time to repay more debt. A team is innovating when their technical debt is sustainably low, morale is high, and the majority of work is satisfying new user needs. Teams want to climb from falling behind to innovation, while entropy drags you backwards. Each state transition requires a different tact.\nLarson speaks in his blog and his book on strategies for teams transitioning between each state. However, some managers might have problems identifying which state their team is in. Other managers might believe it is better to hide the facts of their team’s failures or shortcomings from their peers or leadership. Other teams might hide the nature of their team’s failures by the excellent always-on work of some key engineers.\nSo what is the best way to audit the technical state of an engineering team? When I worked at Slack, I worked with a talented engineer, and together we came up with a set of questions we thought could help evaluate the technical state of a team.\nThe way this works; you record a row in a spreadsheet for every API/Site/System that you own. Get as granular as you would like. Then go through the list of questions for each owned system.\nNot all questions apply to all architectures or all system types. Remove the questions that do not apply to the systems that you own.\nOnce you’re pruned the list of questions, go through and evaluate each system for each question. Each question is evaluated on a binary basis; a question is given a value of 1 if you have the most positive outcome of the questions, and a 0 if you’re unsure or can’t answer the question positivity.\nOnce you’ve calculated your scores, do some simple math to figure out where your team should be focusing and how it compares to other teams in your organization. Ideally the scores you generate roughly align to the four stages of team progress, so you use some of the guidance there to figure out how to fix the problems your org is facing.\n0%-25%: falling behind\n25%-50%: treading water\n50%-75%: repaying debt\n75%+: innovating\nOnce you gathered your data, there are a couple ways to process it:\nSum across everything Add up all your yes answers. Divide by the total number of questions asked. This should give you a percent score of your organization’s technical health.\nExample: Say you have 50 total questions and 10 services you’re evaluating. That means you have a possible score of 50*10 = 500 questions for your organization to answer.\nLet’s say you add up all of your positive answers, and you get a score of 240. (240 / 500) * 100 = 48%.\nYour team is treading water.\nSum across subject areas Add up the possible questions and scores for each section you’re focusing on.\nExample: Let’s say you have 10 questions around Metrics and 10 questions around Build \u0026amp; Deploy for your 10 services. You scored a 20 on Metrics and a 60 on Build and Deploy.\nFor Metrics, you scored (20 / 100) * 100 = 20%. Your services are failing behind in regard to Metrics\nFor Build \u0026amp; Deploy, you scored (60 / 100) * 100 = 60%. Your services are repaying debt in regards to Build \u0026amp; Deploy.\nSum across services Add up the possible questions and scores for each API/Site/System you’re focusing on.\nLet’s say you have 50 total questions, and you’ve scored a 40 for your “Alpha Service”.\nFor the Alpha Service, you scored (40 / 50) * 100 = 80%. Your Alpha Service is innovating.\n",
    "ref": "/blog/20221212-technical-state-of-team-expanded/"
  },{
    "title": "Project Planning Checklist",
    "date": "",
    "description": "",
    "body": "All the previous project planning articles summarized into a checklist.\nProject Planning Checklist Pre-Planning Identity your stakeholders Identity the goal you’re trying to accomplish Get familiar with the code Set up a local environment to try things out Beginning to Plan Identify the rough scope of the work Identify the milestones of the project Project Kickoff High-Level Timelines Call out timelines you haven’t figured out yet, and when you will figure them out Identify Roles and Responsibilities of people involved with the project Identify Dependencies on other teams Lay out the requirements for what you need from others to be successful Identify Goals and Outcomes for the project Identify how you want people to work together on the project Identify next steps after the kickoff is complete Overall Technical Design An overview of the problem A breakdown of the individual milestones and how they’re related High-level process / workflow diagrams / designs / etc Any other notes that might be relevant to folks who will be working on the project Breaking Down the Project into Milestones Are the milestones clear on what they’re delivering? Do you have a plan for communicating updates and setbacks? Do you have time for writing/reviewing milestone specific tech specs? Do you have time devoted to metrics / data / monitoring what you built? Do you have time devoted to testing? Do you have time devoted to paying down tech debt in the area you’re working on? Do you have a sign-off process? Did you add time for fast-follow work? Does your milestone fit into your overall timeline? ",
    "ref": "/blog/20221110-project-planning-checklist/"
  },{
    "title": "Running Your Projects",
    "date": "",
    "description": "",
    "body": "Note: This is a series of project planning talks I gave my team.\nRunning your project Writing A Technical Design Document At this point, you’re ready to start designing your system.\nA good technical design document should contain:\nAn overview of the problem A breakdown of the individual milestones and how they’re related High-level process / workflow diagrams / designs / etc Any other notes that might be relevant to folks who will be working on the project You should also consider if certain steps can be done in parallel, and what steps block other aspects of the work. Make sure to prioritize blocking steps, and possibly assign parallel work out simultaneously (if staffing permits).\nAttempting to breakdown work or introduce parallelism for projects that were not initially designed that way can cause problems later on. So it’s best to figure out in the design phase what work that can be done in parallel (planning for multiple developers).\nOnce your technical design is complete, you should review it with the engineering team before starting on your milestones.\nSetting up goals / milestones / tickets The planning phase is key to successful projects and focuses on developing a roadmap for the team to follow. During the planning phase, you should plan to organize your team, set up resources, and set goals.\nAfter your design doc is complete and vetted, you should deconstruct each milestone into smaller chunks (tickets) so one person can be assigned responsibility for each facet.\nIn breaking down the work, consider many factors such as the strengths and weaknesses of project team members, the interdependencies among tasks, available resources, and the overall project deadline.\nHow do you know your milestones were successful? Should be clear what you’re delivering What is the smallest thing we can deliver to our customers/partners so they can validate our approach? Example: If you’re building a complex webpage, could you ship a read-only, not interactive version of the page, to test that the data displayed is what they want? How can you split up the work into the smallest pieces possible that can be shown to your stakeholders? After you ship a milestone, you should get sign-off from your stakeholders This can be as small as a demo at the sprint meeting Stakeholders should sign off on what you did If something is wrong, better to find out earlier than later You need time for fast-follow work after each milestone If the customer requests changes based of the sign-off session, you want to have time in your schedule for that If you find small pieces of tech debt/bugs while working on the milestone, fix it directly afterwards while it’s fresh in your mind. Does your milestone fit your overall timeline? If the project has a two month deadline, but the work you’ve laid out for the 1st milestone will take three months, you need to figure out how to get on track fast Can you cut scope? Can you increase velocity by adding more developers? Can you deliver a proof of concept by the deadline and follow up with the rest of the work? What work should you include in your milestones? You need time devoted to design, review, write tech specs Each milestone should include a tech design doc and a review session This can be a paragraph or a multi-page document You should get a review and a sanity check for each tech design doc you create. You need time devoted to metrics / data / monitoring what you built Implement monitoring and error visibility to make it easier to debug problems down the road. Ideally you have a way to record usage whenever we can to illustrate impact. implement monitoring \u0026amp; debugging for every milestone, every deliverable You need time devoted to testing Unit tests for new work is a minimum Implement automated testing early in the process Write a Test Plan/Test Matrix up-front if you’re building a complex system with many interactions You need time devoted to tech debt Fix broken windows along the way Broker time for tech debt Broker time for related bugs in the backlog Build quality into every phase of the project How would you build this if you had to maintain it forever? Communicating Updates There should be constant, detailed, concise status updates in your project channel. This is particularly helpful when rolling new people on because you can say \u0026ldquo;please go back and read the content of the channel for the past week\u0026rdquo;.\nRelevant documents (such as your kickoff slidedeck and your technical roadmap) should be included in your project channel.\nYou should invite your stakeholders to your project channel to have a central place to vet ideas and invite feedback.\nWhen setbacks occur, you should highlight the risks early and often in the channel. Surprises are worse than setbacks.\nInvolve the whole team along the way Include more people in code reviews even if they\u0026rsquo;re not actively picking up development tasks this shares out knowledge of the changes and gets another set of eyes that can ask good questions Break team silos where possible and share knowledge Do Team PR\u0026rsquo;s for big PR\u0026rsquo;s Ideally break work into small pieces though Demo your work early and often Try to avoid having single developers on projects ",
    "ref": "/blog/20221008-running-your-project/"
  },{
    "title": "Kickoff Doc Expanded",
    "date": "",
    "description": "",
    "body": "Note: this is an expansion on a previous article I wrote around kickoff docs.\nProject Kickoff! At this point, you should have a good idea of what your overall goal is. You should have a rough sketch of what your milestones are for the project and what you want to include in each one. You should not have the specific details of the projects worked out yet.\nIt’s time for a project kickoff.\nWhat is a Project Kickoff? A project kick-off meeting is the first meeting with the project team and the client of the project where applicable. This meeting is the time to establish common goals and the purpose of the project.\nTaken from the Atlassian Project Kickoff reference.\nThe kickoff meeting is a\nchance to bring all stakeholders together, cast a vision for the project that everyone can get behind, and an opportunity to make introductions and establish good working relationships. At this stage, the specific details of the project haven’t been determined, so you should include a discussion on the project scope, timeline, and goals in your meeting agenda. This is also when roles are announced and a communication plan is explained. The kickoff meeting sets the tone for the working relationship among stakeholders for the duration of the project.\nWhy a Project Kickoff? A project kickoff sets a clear outline of project goals and milestones.\nIt\u0026rsquo;s a celebration of where you\u0026rsquo;re going as a group. You get your chance to outline what you want to build as a team and why you\u0026rsquo;re doing it. The how isn\u0026rsquo;t important at this step - either from a management or engineering side. You\u0026rsquo;re just trying to let everyone know where you want to end up once the project is complete.\nA kickoff generally will be a forcing function to think about timelines.\nHave you planned for:\nDesign Testing Customer Sign-off Quality Assurance If not, you can always call that out - we\u0026rsquo;ll deliver a finalized timeline and design by XXX date, instead of trying to figure out when you\u0026rsquo;ll deliver before you\u0026rsquo;ve started. If you\u0026rsquo;re not being pushed to deliver by a certain date but instead to deliver certain functionality this can be a great way to go.\nIf you\u0026rsquo;ve already committed to a delivery date, the kickoff can be a great way to acknowledge that we have to find a way to meet the goal in a certain amount of time. It can act as an immediate forcing function to cut functionality you can\u0026rsquo;t afford or won\u0026rsquo;t need.\nFinally, a project kickoff can help your team have something to fall back on when things get unorganized. If someone is unsure what to do at any point, the project kickoff docs can be a great reference to refocus everyone.\nRoles and Responsibilities In a project kickoff, you should lay out who\u0026rsquo;s responsible for various aspects of the project. This is a great opportunity for a manager to provide growth opportunities to folks. You can break up the responsibilities of the project into many small pieces that you dole out to your entire team or have one person be responsible for everything.\nSome ways I\u0026rsquo;ve broken up responsibilities in the past:\nProduct Design Feature Delivery Standups Leadership Team Updates Internal/External Comms Development Code Reviews Tech Specs, Architectural diagrams Tech Spec reviews Backlog maintenance, review Testing (automation, manual) Driving Resolution on technical issues (aka making sure bugs get fixed) Remember that a role is not the same as a person.\nIn some cases, one person can fill multiple roles, such as having a designated emergency contact, a role that adds few additional work hours to a person’s schedule. In other cases, multiple people may hold identical roles, as when your project requires multiple software engineers. Goals and Outcomes When setting out the goals of your project, you should tie the project into any company wide OKR\u0026rsquo;s you might have. Most likely the project is tied to a key result or results - those should be stated for the team. There shouldn\u0026rsquo;t be any surprises about what the deliverables are.\nAny deadline driven deliverables should also be called out. If you have hard customer commitments those should be highlighted.\nIf you\u0026rsquo;re lucky enough to work on a project with no deadline, you should at least endeavor to provide a rough timeline to give the team your expectations around delivery.\nA rough timeline like this has worked for me:\nDesign, Research done by Late June Development Done by Late July Load Testing by End of July Medium Confidence in shipping by End of Quarter The progress you make over the first 2-4 weeks of a project will have a compounding effect on the overall project timeline and risk. Make the most of it.\nWorking Together It\u0026rsquo;s good to highlight how everyone is going to work together, and what to do when you\u0026rsquo;re not working together as effectively as you could be.\nHow often do you plan on meeting? Where are you documenting your decisions? How much process do you want to put into place? How will you review if things are going well outside of the deliverables? Where is your backlog of work stored? A high level example:\nStaying in Sync\nWhen in doubt, jump on a Zoom Bring everything back to the development channel Daily standups Start with minimal process Periodic Retros Executing\nIterations (2 weeks) One planning session per iteration Jira is the source of truth, everything should be in there Next Steps Once you\u0026rsquo;ve kicked off the project, what are your next steps? What are the actions you need to take now? Finish the kickoff making sure everyone is empowered to act the moment the meeting ends.\nCommon next steps:\nCreating a project slack channel for folks to follow along Writing \u0026amp; Reviewing a Technical Design document for the 1st milestone by XXX Date ",
    "ref": "/blog/20220907-kickoff-docs-expanded/"
  },{
    "title": "So you’ve got yourself a project",
    "date": "",
    "description": "",
    "body": "Note: This is a series of project planning talks I gave my team.\nSo you’ve got yourself a project A project (and a ticket) is a placeholder for a conversation. No matter if a ticket is super detailed or vague on what it wants, the best way to do good work is to figure out a few things about the work you’ve been given.\nGet Comfortable Pre-planning for any project should begin FAR before the actual work.\nIf you’re working on maintaining/updating an unfamiliar code base, take some time to get familiar Set up a local environment to test and try things out You won’t be effective if you don’t understand the current system Identity your stakeholders You’ll most likely need to talk to your stakeholders to figure out the true nature of the work you’ve been assigned.\nYour stakeholder could be someone on the team. Your project could have several stakeholders, and not all of them will be involved in every detail of the project. Project stakeholders include\nthe end-users of the product the company and its leaders the team working directly on the project What’s the goal you’re trying to accomplish? If your project or goal is clear, great! Sometimes though, a big project is hidden inside of a small task.\nSometimes tickets don’t describe the problem they’re trying to solve or the feature they want, instead they describe a series of steps to accomplish something.\nWhen you have a ticket that is prescriptive in how to solve something but the problem is vague, it is smart to ask your stakeholders what they’re trying to accomplish. Sometimes what the ticket describes and what should be built are two entirely different things, and only a conversation will figure that out.\nOnce you figure out what the real problem is, look to solve that. Don’t just follow a list of prescriptive steps that don’t make sense.\nWhat’s the scope of the project? Once you know the project goals, you should define ​the scope. By defining the scope, you can begin to show what the project\u0026rsquo;s goal or finished product will look like at the end. If the scope isn\u0026rsquo;t defined, it can get expanded throughout the project and lead to overruns, missed deadlines, and frustrated stakeholders.\nIt’s important as requirements come in to figure out what you’re going to tackle and what is not part of the project scope. Defining the scope can get the entire team on the same page at the onset.\nWhat are the milestones for the project? The key achievements for a project are called milestones. They represent the big components of work on a project.\nOnce you understand who your stakeholders are and what the scope of the project is, you should start dividing your project into small deliverable milestones.\nHaving a clear roadmap of your milestones can be a great help when things get unorganized or new requests / features / changes come in.\n",
    "ref": "/blog/20220806-so-you-have-project/"
  },{
    "title": "When to plan a project",
    "date": "",
    "description": "",
    "body": "Note: This is a series of project planning talks I gave my team.\nWhen to plan a project What is a project plan? Project planning is the process of defining your objectives and scope, your goals and milestones (deliverables), and assigning tasks and resources for each step. A good plan is easily shareable with everyone involved, and it’s most useful when it’s revisited regularly. Simply outlining a plan and never discussing it with your team again is a good recipe for wasted time and effort.\nA project plan outlines the objectives and scope of the project and serves as an official point of reference for the project team, larger company, and stakeholders.\nA project plan is more than just a schedule or a task list, though it does include those things. The project management plan is formally approved at the beginning of the project and then progressively updated throughout the course of the project.\nWhy is project planning important? Project planning is a crucial stage. Through proper planning, you streamline the entire project into a series of steps and ensure the availability of all the resources on time.\nWhen do I need a project plan? If you grab a ticket or look into some work (in the form of a spike ticket or project request), you can ask yourself a couple of questions that can point towards whether or not you’ll want or need a project plan:\nCan I finish the ticket by myself in this sprint without any outside help? If this is the case, you don’t need a project plan\nIs the amount of work the ticket describes bigger than a sprint, but is well defined, easily handled by one person, and not much bigger than one sprint? I would share your findings around the scope of the work with the team, but you most likely don’t need a project plan.\nIs the amount of work the ticket describes a multiple-sprint effort, has some ambiguity, or could involve multiple people and/or teams? You should probably put together a project plan.\n",
    "ref": "/blog/20220705-project-planning-overview/"
  },{
    "title": "Define your team's stragetic intent",
    "date": "",
    "description": "",
    "body": "Note: This was a series of talks I gave to leadership in my organization, so some of the comments here might not make sense in the context of a blog post.\nThis is not original work: I pulled heavilty from these four books to put together these talks:\nReferences:\nHigh Output Management The First 90 Days An Elegant Puzzle A Manager’s Path If I did not site some of these works here, or pulled quotes directly from them, forgive me.\nDefine Strategic Intent Develop and communicate a compelling vision for what the organization will become. Outline a strategy for achieving that vision.\nHaving a well-defined strategic intent helps your team focus their efforts, make better decisions, and stay ahead of their needs.\nStrategic intent is not the same as a mission statement or a set of goals. Instead, it should be a bold and inspiring statement of what the team aspires to achieve in the long term. The strategic intent should be broad enough to encompass multiple goals and strategies, but specific enough to provide guidance and direction.\nI suggest starting by asking questions such as \u0026ldquo;What do we want to be known for?\u0026rdquo; and \u0026ldquo;What do we want to accomplish in the next 6-12 months?\u0026rdquo;. Once your strategic intent is defined, the team should be able to communicate it clearly to all employees and stakeholders.\nFinally, regularly revisit and update your team\u0026rsquo;s strategic intent as circumstances change. The strategic intent should be a living document that guides the team\u0026rsquo;s decision-making and helps it stay on track towards its long-term goals.\nWriting your Strategic Intent Use SCQA to lay out:\nThe situation with the team The conflict the team is facing The question that naturally rises from the conflict The answer to solve the conflict/question facing your team Your solution to get the team back on track or producing effectively These are your A-list goals for the team Your answers here should be:\nSpecific We’re going to fix XXX We\u0026rsquo;re going to build XXX Measurable Fixing XXX means we’ll see a YYY success rate You want measurements to be paired A 99% success rate means you’re measuring both success and failure Response time is not a good metric if every response returns an error aka Pair your measurement with a quality measurement Any measurement is better than none, but the best measurements cover the output of the work, not the activity involved Time-bound This will take ZZZZZ months/sprints/whatever with VVVV engineers Realistic If your engineers say it will take ZZZ sprints, double that Add in time for planning and testing How to plan a project State what you could do with more resources If we increase the numbers of engineers by WWWW, we can reduce the time it takes to fix by UUUUU sprints Also let folks know if increasing staffing won’t help the issue Take into account holidays/vacations/on-call shifts when planning timelines Build some slack into your scheduling! Planning \u0026amp; Pitching You need to plan like the fire department plans. You cannot anticipate where the next fire will be, but you can shape an energetic and efficient team that is capable of responding to the unanticipated as well as ordinary events.\nPitch your plan to your management. Get buy-in.\nYou have to negotiate timelines for diagnosis and action planning. You have to be firm when you’re asked to change your plans - you must mention what this will cost your team to take on the additional work. Clarify expectations for what you can achieve early and often. Tell management what will happen if you do something vs if you don’t do something. Don’t ever let bad news be a surprise if something happens. Get in front of problems.\nClarify what you’re doing over and over again. Repeat yourself. Let folks know what you\u0026rsquo;re doing in every medium possible. Assume no one will remember anything you say. Repeat yourself.\nNow that you’ve outlined your vision? You have two options to meet your goals, especially if you’re struggling to deliver.\nHire more people Speaks for itself. In six months you’ll be able to do much more if you have more people Reduce Work in Progress Start swarming on single tasks instead of having as many tasks in flight as you have people. Reduce concurrent work until you’re able to repay your technical debt. Tactically, the focus here is to help people transition from a personal view of productivity to a team view. Announce that you’re stopping any and all non-essential activities until you meet one of your goals. Either of these will narrow the focus of the team and allow you to produce on the tasks you’re selected more quickly. These changes to your process or organization structure, no matter what you choose, take time to enact. You’re fighting months or years of inaction. Conversely, the same thing that makes these changes slow to enact makes them extremely durable once they’re in effect.\n",
    "ref": "/blog/20220628-strategic-intent/"
  },{
    "title": "Getting Started with your Team: Organize to Learn",
    "date": "",
    "description": "",
    "body": "Note: This was a series of talks I gave to leadership in my organization, so some of the comments here might not make sense in the context of a blog post.\nThis is not original work: I pulled heavilty from these four books to put together these talks:\nReferences:\nHigh Output Management The First 90 Days An Elegant Puzzle A Manager’s Path If I did not site some of these works here, or pulled quotes directly from them, forgive me.\nGetting Started with your Team Organize to Learn What is the purpose of a team?\n“They build \u0026amp; deliver products in response to the demands of their customers at a scheduled delivery time, at an acceptable quality level, and at the lowest possible cost.”\n-Andy Grove, High Output Management\nYour team charter cannot be to deliver whatever your customer wants whenever they want it, that would require infinite engineering capacity.\nHow do you figure out your charter? The starting point is focused learning. Figure out what you most need to learn, from whom, and how you can best learn it.\nIf you don’t know where to start? Ask the team.\nAsk the team:\nWhat are the biggest challenges the team is facing (or will face in the near future)? Why is the team facing (or going to face) these challenges? What are the most promising opportunities for growth/success? What would we need to happen for the team to take advantage of those opportunities? If you were me, what would you focus your attention on? Points of Focus; Organize your Findings Technical Learnings Focus on technical learnings (strategies, technologies, practices, etc). Think about what changes you can make quickly. A better trained team can handle more situations in less time.\nWasteful Practices Look at wasteful practices. Do you have lots of long running meetings? Figure out how to eliminate/remove them. What can you take on, to free up your team to do work?\nExisting Data Look over whatever data you already have. Do you track the type of #ask requests you get? How often are you paged? Technical state of the team? The nature of the failures/errors your team encounters? These are all useful measurements that you’ll need to put together your vision for your team.\nClassifying Problems \u0026amp; Opportunities Once you have everything documented, start to classify the problems/opportunities:\nHow long will each thing take? Days? Sprints? Months? Years? How many people will need to do it? 1 dev? 1 team? 3 teams? How important is it to get done? Anything that slows the team down and makes you less productive is of critical importance to kill Whatever wasteful tasks you eliminate immediately pay you back in increased productivity A common rule for prioritization: Detect and fix problems at the earliest state possible. If you catch a problem right as it happens, it’s infinitely cheaper than letting your customer find your problem for you. Create a matrix. You want to tackle the high importance / low effort tasks first. After that, you can figure it out. Your task here is to find the most cost-effective way to deploy your resources - the key to optimizing all types of productive work.\nRemember while doing this exercise:\n“Many managers, upon recognizing today’s gap, try very hard to determine what decision has to be made to close it. But today’s gap represents a failure of planning sometime in the past”.\n-Andy Grove, High Output Management\nYou must understand the energy you put in early to your team and process pays off 10x, while the energy you put in at the end of the process pays off -10x.\n",
    "ref": "/blog/20220325-organize-to-learn/"
  },{
    "title": "Managerial Meddling",
    "date": "",
    "description": "The Negative Leverage Activity",
    "body": "Note: This was a series of talks I gave to leadership in my organization, so some of the comments here might not make sense in the context of a blog post.\nThis is not original work: I pulled heavilty from these four books to put together these talks:\nReferences:\nHigh Output Management The First 90 Days An Elegant Puzzle A Manager’s Path If I did not site some of these works here, or pulled quotes directly from them, forgive me.\nManagerial Meddling: The Negative Leverage Activity In a corporate environment, a manager\u0026rsquo;s role is critical, and the success of the team or the entire organization depends on how effectively they manage their employees. However, sometimes, even with the best intentions, a manager may engage in negative leverage activities that can have adverse effects on the team\u0026rsquo;s output.\nOne example of such negative leverage activity is Managerial Meddling, where a supervisor uses their superior knowledge and experience (real or imagined) to assume command of a situation, rather than letting the subordinate work things through themselves. This behavior creates negative leverage as the subordinate, after being exposed to many such instances, will begin to take a much more restricted view of what is expected of them. They will show less initiative to solve their problems and will refer their problems to their supervisor, resulting in reduced output in the long run.\nSituational Leadership: High Managerial Productivity To increase the output of their teams, managers must engage in high-leverage tasks. One such task is training and mentoring employees. It allows managers to uplevel the skills of their team and build redundancy. If an employee is immature in a task, hands-on training is essential. If the employee is more mature, then the manager can delegate.\nHowever, managers must remember that they are still responsible for the outcome of the task. Monitoring the task\u0026rsquo;s progress is not meddling. If a manager has multiple tasks they could delegate, they should choose the one they\u0026rsquo;re most familiar with. This might go against their emotional grain, but it\u0026rsquo;s easier to monitor a task that a manager is familiar with than one that they\u0026rsquo;re not.\nManagers must not define their roles too narrowly. Effective managers are the glue in their team, filling any gaps. Sometimes that means doing things they don\u0026rsquo;t want to do to set a good example.\nManaging Up vs. Down: Power Comes from Healthy Teams Managers have two directions to manage: down and up. When managing down, it\u0026rsquo;s essential not to build things that the team wants to build but the company or customers aren\u0026rsquo;t interested in. Managers must ensure that their team is aligned with the company\u0026rsquo;s goals and objectives.\nWhen managing up, managers must share their success with management to show the value their team brings to the organization. Sometimes managers focus so much on following their management\u0026rsquo;s wishes that their team evaporates beneath them. However, sharing the success of the team can lead to increased recognition and support from higher management.\nConclusion In conclusion, managers must engage in high-leverage tasks, avoid negative leverage activities, and manage both down and up to increase the output of their teams. By focusing on building healthy teams, aligning their team\u0026rsquo;s goals with the organization\u0026rsquo;s objectives, and sharing their success with management, managers can ensure the success of their teams and the entire organization.\n",
    "ref": "/blog/20211222-managerial-meddling/"
  },{
    "title": "What is a manager?",
    "date": "",
    "description": "",
    "body": "Note: This was a series of talks I gave to leadership in my organization, so some of the comments here might not make sense in the context of a blog post.\nThis is not original work: I pulled heavilty from these four books to put together these talks:\nReferences:\nHigh Output Management The First 90 Days An Elegant Puzzle A Manager’s Path If I did not site some of these works here, or pulled quotes directly from them, forgive me.\nWhat is a manager? “The output of a manager is the output of the organizational units under their supervision or influence”.\nAndy Grove, High Output Management How do you, as a manager, add value to your organization?\nBy continually looking for ways to make things truly better for your team. Every hour of every day should be spent increasing the output or the value of the output of the people you’re responsible for well.\nA team will only perform well if peak performance is elicited from individuals. Your expectation and goal setting can help motivate your team to perform better. No one shows up for work thinking to themselves, “I really want to do a bad job today.”\nSetting Goals \u0026amp; Expectations If you do not tell your reports, “I want you do XXX as part of your (job/project/task)”. Then they won’t do it. If you tell them what to do, but they don’t have the skills/training to do it, you’ve supplied them with an impossible task.\nExample: If you have a project coming up, and one of the requirements is using some technology (Bash/Gitlab/ElasticSearch/Terraform/Redis/Whatever), you should tell your team what they\u0026rsquo;re going to be doing. Then, given who’s going to be working on the project, you need to find out their comfort level with the tech they’ll be using. If they’re going to be working on the project and not comfortable, it’s your job to find training for them.\nThis doesn’t just apply to technology. If you want your team to follow a certain practice, follow process in a certain way, communicate a certain way, you should train them on what you want. Asking them without showing them how to do what you want is ineffective.\nYou don’t have to train folks yourself. Look at what I’m doing. I’m speaking to you because our management identified a gap and wants us to work on it. They think I have knowledge of the topic that can help. You can do the same with your team.\nIf your manageer came to you and said, “Go buy a book and some courses on any topic, and give a presentation to the team in two weeks. This is 50% of your job for the next sprint.” Would you be upset? Or would you be excited to learn something new? You can leverage this with your team! You don’t need experts on a topic to create knowledge and get the ball rolling.\nWhen someone isn\u0026rsquo;t performing When a person is not doing their job, there can only be two reasons for it. The person either can’t do it (they need training) or won’t do it (they need motivation). Either they are not capable or not motivated. All you can do to improve the output of your employees is motivate and train. There is nothing else.\nAs a manager, the only way you can increase the output of your team is through motivation and training. If you are not training your team, then you are neglecting half your job.\n",
    "ref": "/blog/20210919-what-is-a-manager/"
  },{
    "title": "SMART vs CLEAR goals",
    "date": "",
    "description": "",
    "body": "Setting Goals Two of the more popular methods for setting goals are SMART and CLEAR:\nSMART Goals This method helps ensure that the goals have been thoroughly vetted. It also provides a way to clearly understand the implications of the goal-setting process.\nSpecific – To set specific goals, answer the following questions: who, what, where, when, which, and why.\nMeasurable – Create criteria that you can use to measure the success of a goal.\nAttainable – Identify the most important goals and what it will take to achieve them.\nRealistic – You should be willing and able to work toward a particular goal.\nTimely – Create a timeframe to achieve the goal.\nFor more information about S.M.A.R.T. goals, read \u0026ldquo;The Essential Guide to Writing S.M.A.R.T. Goals.\u0026rdquo;\nCLEAR Goals A newer method for setting goals that takes into consideration the environment of today’s fast-paced businesses.\nCollaborative – The goal should encourage employees to work together.\nLimited – They should be limited in scope and time to keep it manageable.\nEmotional – Goals should tap into the passion of employees and be something they can form an emotional connection to. This can optimize the quality of work.\nAppreciable – Break larger goals into smaller tasks that can be quickly achieved.\nRefinable – As new situations arise, be flexible and refine goals as needed.\nDuring this phase, the scope of the project is defined and a project plan is developed. It involves identifying the quality of the work, available resources, and a realistic timetable. The project plans also includes establishing baselines or performance measures. These are generated using the scope and schedule of a project. A baseline is essential to determine if a project is on track.\nAt this time, roles and responsibilities are clearly defined, so everyone involved knows what they are accountable for.\n",
    "ref": "/blog/20210627-smart-vs-clear/"
  },{
    "title": "The schedule of an engineering manager",
    "date": "",
    "description": "",
    "body": "Overview In re-reading High Output Management recently, I was particularly interested in reading over Andy Grove\u0026rsquo;s schedule and seeing how he spent his time. I thought it might be interesting to post something similar to how I allocate my time throughout the year.\nRegular Occurring Events: Weekly 1:1’s with all direct reports Weekly 1:1’s with PM, Design, etc Weekly 1:1\u0026rsquo;s with my manager Weekly leadership meeting with pillar leadership Bi-weekly 1:1’s with peers Monthly Career Conversations with direct reports\nQuarterly Meetings Beginning/End of Quarter Review Previous Quarter \u0026amp; how we did on our Goals Kickoff new Quarter, talk through new Goals\nHalfway through Quarter Review Goal Progress with Team Start planning next quarter w/ team\nBiweekly (Assuming 2 week sprints): Plan for New Sprint Complete Sprint Start New Sprint Retrospect on Previous Sprint Follow up on Retro Action Items\nA typical weekly schedule Monday Run Standup, take notes Look for tickets due and explain state of any tickets due Go over open tickets with QA\nTriage over tickets in JIRA:\nOverall Ticket Dashboard Ungroomed Tickets Missing Start Date for Epics Query Tickets Due Tuesday: Bug Triage with PM Meet with Pillar Leadership Post daily standup updates\nWednesday: Review Healthscores for Team Review team escalations Review Open, Useful Bugs Post daily standup updates\nThursday: Post daily standup updates\nFriday: Run Standup, take notes SLA Analysis\nHow are our services doing? Go over Leadership Dashboards Are we on track towards our pillar\u0026rsquo;s goals? Go over Quality Dashboard Are we collecting debt in a certain area? Did our recent project rollouts go well? Update Project Statuses ",
    "ref": "/blog/20210516-weekly-tasks/"
  },{
    "title": "Breakdown; post-mortem of a process failure",
    "date": "",
    "description": "",
    "body": "I was reviewing an old incident review doc where I wrote up some of the high level learnings from the incident. Thought it was worth sharing, with the details omitted to protect the innocent.\nSome backstory; we were trying to load test a component and ended up getting the load testing done at the last minute right before customer launch. The team had to work into the weekend to meet the customer deadline.\nSo while this wasn\u0026rsquo;t an \u0026ldquo;incident\u0026rdquo; as most people would define it, the fact that our process failed us in a way that we missed several deliverables led me to run a review of our process, much like in a typical post-mortem. Here were the team\u0026rsquo;s findings.\nWhen lacking knowledge, use historical data. We got stuck early in the process trying to get the customer\u0026rsquo;s release plan, where we could have looked at what we had done other customers had done for their release plans. Using that data, we could have suggested a plan, and moved forward under those assumptions. The fact that we didn’t have comprehensive data until almost a week into the project shouldn’t have slowed us down as much as it did.\nWhen looking for direction, write up a plan and look for feedback Our original plan for this project consisted of an Epic and a write up of tickets. For these type of projects, it is expected that a load test plan would be written up and vetted with folks outside of the team. This was a known requirement of the project that wasn’t completed until very late in the process, and we didn’t have sign-off until the day of our load testing. Had we done this early in the process, we would have gotten valuable feedback about our approach early, and most likely met our deadline.\nMake “unreasonable” asks Early in the process, we booked a late load testing time (the day of the deadline at 1pm). The reason we did this wasn’t that we wanted to test this late, but that by the time we signed up, this was the only timeslot left available. This would have been a good time to make an “unreasonable” ask of the loadtest team, and see if they could accommodate us at another time, either before or after their normal slots.\nThe worst thing that could happen is they say no, and at least then it’s known that you’d like to test earlier, in case someone else cancelled or can’t make their slot.\nAsk for help early and often We hit some snags with our load testing, but the request for help didn’t come up until late in the process, and the biggest push for assistance came days before our load testing deadline. Had we front-loaded some of these questions, we probably wouldn’t have missed our deadline.\nAdditionally, some of the updates from the team indicated we were on track when we were not. Had those updates been more transparent, we would have had the right folks working on the right set of problems.\nOne of the problems we hit was testing multiple users vs a single user. This was never highlighted in channel until it was uncovered during load testing on the day of the deadline. Had this been highlighted earlier, we might have swarmed on the problem then.\nSwarm on problems early Going into the deadline, we did not have a working load test script that met our requirements. By early Saturday morning (after our deadline) we did. The key here was that 4 people jumped on a call and walked through the problems, live debugged, and kept folks focused on the problem. After a few hours we had a working proof of concept.\nWhile we needed much of the early context and research to allow for this to happen, if we had swarmed earlier in the week we might have come up with a solution at our deadline.\n",
    "ref": "/blog/20210217-incident-remediation/"
  },{
    "title": "Measure the Technical State of your Team",
    "date": "",
    "description": "",
    "body": "Some thoughts on how you could evaluate the state of the systems your team owns.\nOne way to use this:\nPut some of these criteria on the Y axis Put the name of the components you own on the X. Give everything a score from 1 to 0. Either average the scores or sum them to figure out which components need the most love. If all of these are the same for everything you own, it might make sense to skip that section. For example, if you own 10 services, but they all use a common build pipeline that you don\u0026rsquo;t maintain, it might make sense to skip that criteria.\nBuilds: Consistent Build from Dev -\u0026gt; Prod\nThe same image/code used in each step, not built at each step Blocking tests at each phase\nUnit is a good start, acceptance is better Canary and/or staged releases to production\nHaving an \u0026ldquo;alpha\u0026rdquo; or \u0026ldquo;canary\u0026rdquo; production environment can save you a good deal of heartache Easy, well understood deployment process\nCan you deploy and roll back in 1 step? Is it fast? Both the overall process and each individual step? Code Ownership \u0026amp; Quality What is the level of comfort your team has with the code?\nHas your team built the codebase? Have they maintained it in any meaningful way? Do they own it without knowing it? Well Factored Code\nIf an ax weilding maniac who knew where you lived was the next person to maintain the code you\u0026rsquo;re working on, would you be worried? Health Quality Score\nDoes your company have a way to measure code health? If not, could you use something off the shelf? How many bugs per component exist? Is that number increasing or decreasing? Fully Owned Code\nAre you in a codebase where you share dependencies or entire sections of your code? Well Documented Code\nNot commenting per se, but diagrams/drawings/something to help folks understand and dive in Degrading Gracefully\nCircuit Breakers Rate Limiting Retry-After on 429/503\u0026rsquo;s Can the services you rely on fail and would still return a useful response? On-Call / Triage Everyone on the team is on-call\nDo you have a process for handling bugs / requests / questions?\nIs there someone who reliably triages questions and concerns? Is it one person, or a rotation of people? \u0026ldquo;Good\u0026rdquo; Runbooks\nCan you actually fix problems from them? Do they cover most of the common errors your systems experience? \u0026ldquo;Good\u0026rdquo; Alerting\nDo the alerts identity the issue and point towards resolution, or the tools to resolve? When your alerts fire, does that cause an action, or do they frequently get ignored/silenced? Non-Noisy Alerts\nAre your on-calls dreading their shifts because of pages day \u0026amp; night? Do you have a formal incident policy?\nWhen do you work into the night vs work 9-5 until its over? Do you have a formal incident review process once the incident is over? Do you have a process to make sure incident remediation gets completed? Low Incident Rate\nService License Agreement (SLO) for Services\nWhat is the expected response time? What\u0026rsquo;s your TP50? TP95? TP99? 200 rate? is 4 nines enough? Do you alert when you service doesn\u0026rsquo;t perform as expected? Code is easy to debug\nEasy to plug in debugger? Error messages that make sense? Can you trace calls from start to finish through your systems? Can you time calls from start to finish through your system? Testing / Tooling Load Testing Tooling in Place\nCan you determine the maximum # of callers while maintaining your SLO\u0026rsquo;s? Acceptance Tests\nCan you test end to end your services? Integration Tests\nDo you have tests that bridge layers of your codebase? High Test Coverage\nWhat percentage of your code has unit tests? Non-Noisy Tests\nDo you have tests that inconsistently fail? You should fix or delete them Metrics/Monitoring Non-Noisy Logging\nUseful Metrics\nDo you track the big metrics? Response/Run time 200\u0026rsquo;s or successful operations 500\u0026rsquo;s or failed operations \u0026ldquo;Good\u0026rdquo; Dashboards\nCan you not only track performance, but the rate at which events happen/don\u0026rsquo;t happen that are relevant? Useful Logging\nDo you use all the information you\u0026rsquo;re logging? Roadmaps Is there a technical roadmap for each component?\nIs there a product roadmap for each component?\n",
    "ref": "/blog/20210110-measurable-technical-state-of-the-team/"
  },{
    "title": "Understanding Velocity in Development Teams",
    "date": "",
    "description": "Best Practices and Cautionary Tales",
    "body": "Velocity is a commonly used metric in development teams to measure how much work they can fit into a sprint. However, using velocity for any other purpose can be problematic as it might not reflect the real progress of the project and can be a flawed planning mechanism.\nIt\u0026rsquo;s crucial to understand that each team defines what a point means for them, making velocity not useful for comparing teams with each other. Each team can track their own velocity to have a better gauge of their progress and how much they can fit into a sprint. Teams should be self-organizing, and how they want to track velocity is up to them.\nOne use case where velocity can be used as a proxy metric is for cross-cutting concerns, such as investing time in infrastructure to reduce future costs in a certain area. A flat velocity line over a few sprints can indicate that the team is investing time in non-feature work, such as refactoring or technical debt reduction. This can signal that the team is taking a long-term view of the project and focusing on improving the codebase, even if it means that they\u0026rsquo;re not delivering new features at the same rate.\nHowever, it\u0026rsquo;s important to note that using velocity as a proxy metric for cross-cutting concerns should be resolved within the team rather than the organization. This means that the team should decide when to invest in non-feature work and how much time to allocate to it. As a manager, it\u0026rsquo;s your responsibility to ensure that the team has the necessary resources and support to make these decisions.\nCycle time can be a better metric for measuring progress towards cross-cutting concerns. Cycle time is the time it takes for a ticket to move from the \u0026ldquo;in progress\u0026rdquo; stage to \u0026ldquo;done.\u0026rdquo; This metric can be used to measure the time it takes to complete non-feature work, such as refactoring or technical debt reduction. Normalizing the data for days worked, tracking moving averages over 1, 3, and 5 sprints, and using deeper retrospectives to understand trends in the data can help teams make more informed decisions.\nIn conclusion, velocity is a helpful tool for development teams to plan their work, but it should be used cautiously and only for its intended purpose. A flat velocity line can be used as a proxy metric for cross-cutting concerns, but it should be resolved within the team rather than the organization. Cycle time can be a better metric for measuring progress towards non-feature work, and each team should define their own points to avoid comparing teams with each other. As a manager, your role is to support the team in making informed decisions and provide them with the necessary resources to succeed.\n",
    "ref": "/blog/20201102-understanding-velocity-in-development-teams/"
  },{
    "title": "The importance of clear communication",
    "date": "",
    "description": "",
    "body": "This is based off a talk I gave on improving communications.\nThere is a lot of communication right now With everyone working remotely, the importance of communication has increased. We\u0026rsquo;re communicating more often without meeting, and making your message clear when everyone is deluged with correspondance is the only way to have impact in your organization.\nTo succeed in any organization, you need to be able to tell your story. Whether it’s a status update, an RFC, or an escal question, you need to be able to quickly tell people the state of the world. It’s how you’re going to convince other people to take action or to answer their questions.\nPeople need structure to their stories. In order to follow a story, either written or spoken, people need to understand how all the given information is related. When you present your story, your audience will look for connections between things you\u0026rsquo;re saying, such as: there must be a reason for that statement; or, this is probably an example of the previous point.\nThis structuring can be a conscious or unconscious process by your audience. People automatically look for structure.\nWithout structure to your communication, your message can get lost Communicating information, whether on a Zoom call or in Slack, well it’s hard. If you don’t present a clearly structured story, your audience will look for their own structure, which can lead to problems.\nYour audience could misunderstand your structure and be unable to understand your story. Because of that, they might lose attention, or they may draw false conclusions. Even if your audience understands your story, without structure they’ll have to work hard to do so.\nIf they’re working hard early, they’ll have less attention later on, or stop reading and listening to you all together.\nTo have your audience fully grasp what you are telling them, you need to structure your story as clearly as possible. This requires you to have a clear view on your own story structure.\nWhat’s an effective way to structure communication? Start your storytelling with a simple structure that works. If you need to convince a analytical audience such as your fellow engineers, turn to Barbara Minto and her Pyramid principle.\nShe has spent decades teaching her pyramid principle. Her framework makes your arguments easy to understand and much more convincing.\nI’ll introduce each element and then we will discuss some examples to make it more concrete.\nStart by outlining the S - the situation. The Situation is the starting point of your story. It is important that your audience can easily understand your story and recognize what you are telling them. This introduces them to your topic and how it relates to their world.\nThe Situation is made up of recognizable and mostly agreed-on points. They describe the state of the world and the topic of your work.\nOf course, this is not a story yet. If you only describe a situation as it is, there’s no reason to act.\nFor example, let’s say you get an alert that an API is taking 500ms to respond. if I tell any of you, “An API is taking 500ms to respond”, without any context, there is no motivation to act. 500ms could be good or bad.\nNext outline the C - the Complication. This is the reason that you’re asking people\u0026rsquo;s attention for your story.\nWhat has changed that’s making things harder? What threats do we face if the Situation carries on as it is now? What opportunities do we miss?\nExplaining this in your Complication will give your story its urgency. Also part of the Complication is: what practical hurdles do we need to overcome to prevent those threats or to realize those opportunities?\nWith the previous example with the API alert, adding the complication might sound like, “An API is taking 500ms to respond, it normally responds in 50ms.”\nIf you sharply define the Complication, the Question follows naturally. It asks how the issues of your Complication can be overcome, so that we can either stop the negative effects or seize an opportunity.\nWhen communicating your story, a commonly agreed on SCQ makes sure that the audience understands what you want to do in your Answer, and also why this is relevant.\nThe question also allows your user to take a breath. Many times the Situation and Complication can be quite long. Phrasing out the question simply reminds the user, after all of the explanation, why they are here.\nUsing our previous example, we might add a question such, “An API is taking 500ms to respond, it normally responds in 50ms. Why is the API so much slower?”\nThe A provides the Answer. It explains what we should do and how we can do it. Your Answer should be explicit in how it will solve the Complication that has been raised.\nA simple SCQA for our alert situation:\nAn API is taking 500ms to respond It normally responds in 50ms. Why is the API so much slower? We are under 10x the normal load. We should scale up the cluster to compensate.\nBreaking down the Answer So that’s the basic structure. Now we’re going to focus on the A - the Answer. It seems to me that most folks have a good grasp on the S \u0026amp; C in their writings. The Q naturally falls out of that. But the A sometimes needs more structure to be effective.\nArguments \u0026amp; Evidence Once you have an answer, you can spend your time offering arguments and evidence for your answer.\nAnd it’s going to make your arguments better. The pyramid makes your answer the focal point of the conversation. This is appealing to analytical folks who have a solutions mindset.\nThe pyramid creates a logical structure. Each level of the pyramid supports the level above it. Evidence supports each argument, and the arguments come together to support the answer. If they don’t, you’ll need to find better arguments.\nFor our alert example, you could provide evidence of the response time over the past 30 days, the db load being normal, no long-running tasks in flight, and the traffic from a certain customer being elevated.\nParing down your Answer The Pyramid requires you to pare out all the unnecessary information. Many presentations, status updates, and RFCs contain a lot of information to show that you did a lot of work. In the Pyramid, if your evidence or arguments don’t directly support your answer, take it out.\nFor our alert adventure, let’s say you did hours of work researching technologies such as Consul, Envoy, and Docker. Some people might put what they learned about these systems in their story to show they did a lot of research, but it doesn’t serve your answer, so take it out.\nThink of your Audience If your audience loves analysis, logic, and reason, tell stories this way.\nHow much do I like SCQA? I structured this post using it.\n",
    "ref": "/blog/20200909-pyramid-principle-inaction/"
  },{
    "title": "1:1's aren't enough in a SIP world",
    "date": "",
    "description": "",
    "body": "Back when we were all the office together, it was pretty easy as a manager to get a feel for how the team was doing. Are folks getting along? Are folks stressed? Does everyone have the right balance of work? With folks all around you, it was pretty easy to drop in on a conversation, take someone to lunch, or grab a coffee and talk.\nThese small encounters gave you a chance to make sure your team was running efficiency, it also gave your team a chance to speak to you as a human being outside of formal settings. Usually that level of shared vunerability led to better, more fulfilling conversations in the following 1:1\u0026rsquo;s.\nWith the traditional office gone, all of the luxurious interactions managers had when we shared physical space are gone. Given we have none of the in-person tools for building trust with our teams that we\u0026rsquo;ve had developed over the years, what could we do?\nI started a new job 9 days before shelther in place, so I didn\u0026rsquo;t have much time to meet my team or get to know them. I noticed quickly that the level of trust and sharing wasn\u0026rsquo;t where I expected it to be. So what did I do?\nOvershare (a bit) I\u0026rsquo;m a relatively private person. I don\u0026rsquo;t like to talk about my personal life in group settings. However, to build trust with a group, many studies have shown that showing trust in someone helps them to trust you.\nOne way you can do this is by confiding small details about your life with them.\nWould you tell your teams that you and your partner had a fight? No. You don\u0026rsquo;t want to overshare or make them uncomfortable.\nHowever, details of your life you normally wouldn\u0026rsquo;t broadcast, you could share those in an attempt to be a bit vunerable and build closeness with your team. Things like:\nWhether you\u0026rsquo;vee been sleeping well or not How your pets are doing Projects you\u0026rsquo;ve accomplished or failed to accomplish How you\u0026rsquo;re dealing with being remote (or not dealing with it) Some moments of vunerability allow your teams to get to know you, and hopefully feel comfortable enough to be themselves around you as well.\nBe more prescriptive in getting to know them I found with my move to remote working that 1:1\u0026rsquo;s, even once a week, wasn\u0026rsquo;t enough to get to know my team on any appreciable level.\nSo I had to be very prescriptive in my approach. Not only breaking up 1:1\u0026rsquo;s into a format where I could \u0026ldquo;force\u0026rdquo; organic conversation.\nA normal format I\u0026rsquo;ve been following that has worked for me, in a 30 minute 1/1:\n10 min: Personal chit-chat 10 min: Whatever is on their agenda 10 min: Whatever is on my agenda/requesting feedback/etc If you\u0026rsquo;re looking for questions to ask, my co-worker Cyriel Dikoume created this great site with 1:1 prompts if you ever get stuck with nothing to say or ask.\nMake more time for them If you\u0026rsquo;re being prescriptive with your 1:1\u0026rsquo;s, you might find that you still don\u0026rsquo;t have enough time to cover everything you want, such as career development. If you find this is the case, schedule recurring time to talk about the specific issues that you find are getting short-changed. For me, I have a dedicated time slot for career development outside of my regular 1:1 time as I felt that wasn\u0026rsquo;t getting the time and attention it deserved.\nSet reminders to yourself One last thing I\u0026rsquo;ve found useful: setting regular reminders to be human with your team. Whether that\u0026rsquo;s thanking them for their work, checking in on their family and friends, or writing birthday cards or celebrating work anniversaries, it\u0026rsquo;s nice to take the worry out of remembering to appreciate your team for the great work they\u0026rsquo;re doing.\n",
    "ref": "/blog/20200606-remote-management-lessons-learned/"
  },{
    "title": "Kickoff Docs",
    "date": "",
    "description": "",
    "body": "What is a Project Kickoff? What is a project kick-off? A project kick-off meeting is the first meeting with the project team and the client of the project where applicable. This meeting is the time to establish common goals and the purpose of the project.\nTaken from the Atlassian Project Kickoff reference.\nWhy a Project Kickoff? A project kickoff sets a clear outline of project goals and milestones.\nIt\u0026rsquo;s a celebration of where you\u0026rsquo;re going as a group. You get your chance to outline what you want to build as a team and why you\u0026rsquo;re doing it. The how isn\u0026rsquo;t important at this step - either from a management or engineering side. You\u0026rsquo;re just trying to let everyone know where you want to end up once the project is complete.\nA kickoff generally will be a forcing function to think about timelines. Have you planned for design? Testing? Customer Sign-off? Quality Assurance? If not, you can always call that out - we\u0026rsquo;ll deliver a finalized timeline and design by XXX date, instead of trying to figure out when you\u0026rsquo;ll deliver before you\u0026rsquo;ve started. If you\u0026rsquo;re not being pushed to deliver by a certain date but instead to deliver certain functionality this can be a great way to go.\nIf you\u0026rsquo;ve already committed to a delivery date, the kickoff can be a great way to acknowledge that we have to find a way to meet the goal in a certain amount of time. It can act as an immediate forcing function to cut functionality you can\u0026rsquo;t afford or won\u0026rsquo;t need.\nFinally, a project kickoff can help your team have something to fall back on when things get unorganized. If someone is unsure what to do at any point, the project kickoff docs can be a greate reference to refocus everyone.\nRoles and Responsibilities In a project kickoff, you should lay who\u0026rsquo;s responsible for various aspects of the project. This is a great opportunity for a manager to try out assigning leadership to folks who haven\u0026rsquo;t been in those positions before. You can break up the responsibilities of the project into many small pieces that you dole out to your entire team so one person is responsible for everything. Some ways I\u0026rsquo;ve broken up responsibilities in the past:\nProduct Design Feature Delivery Standups Leadership Team Updates Internal/External Comms Development Code Reviews Tech Specs, Architectural diagrams Tech Spec reviews Backlog maintenance, review Testing (automation, manual) Driving Resolution on technical issues (aka making sure bugs get fixed) Goals and Outcomes When setting out the goals of your project, you should tie the project into any company wide OKR\u0026rsquo;s you might have. Most likely the project is tied to a key result or results - those should be stated for the team. There shouldn\u0026rsquo;t be any surprises about what the deliverables are.\nAny deadline driven deliverables should also be called out. If you have hard customer commitments those should be highlighted.\nIf you\u0026rsquo;re lucky enough to work on a project with no deadline, you should at least endeavor to provide a rough timeline to give the team your expectations around delivery.\nA rough timeline like this has worked for me:\nDesign, Research done by Late June Development Done by Late July Load Testing by End of July Medium Confidence in shipping by End of Quarter The progress you make over the first 2-4 weeks of an unplanned project will have a compounding effect on the overall project timeline and risk. Make the most of it.\nWorking Together It\u0026rsquo;s good to highlight how everyone is going to work together, and what to do when you\u0026rsquo;re not working together as effectively as you could be. How often do you plan on meeting? Where are you documenting your decisions? How much process do you want to put into place? How will you review if things are going well outside of the deliverables? Where is your backlog of work stored?\nA high level example:\nStaying in Sync * When in doubt, jump on a Zoom * Bring everything back to the development channel * Daily standups * Start with minimal process * Periodic Retros Executing * Iterations (2 weeks) * One planning session per iteration * Jira is the source of truth, everything should be in there Next Steps Once you\u0026rsquo;ve kicked off the project, what are you next steps? What are the actions you need to take now? Finish the kickoff making sure everyone is empowered to act the moment the meeting ends.\n",
    "ref": "/blog/20200404-kickoff-docs/"
  },{
    "title": "Measuring Backlog Health",
    "date": "",
    "description": "",
    "body": "Backlog Grooming Some thoughts on how you could evaluate the state of your backlog.\nSmall, well groomed backlog\nAre the tickets in the backlog going to be actioned in the near term? If you deleted the tickets that aren\u0026rsquo;t in your near-term roadmap, how long would it take you to recreate it? Is the Backlog consistently growing or shrinking? Are the tickets all in a state to be actioned immediately, or do they need additional work? Ticket \u0026amp; Project Health\nIs the average age of your tickets staying constant? Increasing? Is the average time your tickets staying open consistent? Increasing? How many projects are in progress? Is it less than 1 / person? How many tickets are in progress? Is it less than 1 / person? ",
    "ref": "/blog/20200101-measuring-backlog-health/"
  },{
    "title": "Pyramid Principle Examples",
    "date": "",
    "description": "",
    "body": "I use SCQA all the time in my communications both up to leadership and down to my teams.\nThis TED talk from Derek Sivers is a great example of someone using SCQA to communicating a problem and a suggested solution in a short amount of time. Worth watching if you\u0026rsquo;re looking to use SCQA in your own communications.\nAnother example of an SCQA structured communication is something I received at work:\nPhishers and scammers are actively targeting employees on LinkedIn and email (work and personal) in hopes of accessing valuable information. Every employee, whether you realize it or not, has insider knowledge - it may be access to financial data, technical resources, customer contacts, intellectual property, customer data, or other resources – and there are people who will try to exploit that. What can you do? Do not click the link, open the attachment, or respond to the sender Forward a copy to phishing@company-corp.com Use the Spam button in GMail If it’s a LinkedIn message, text message, or other non-Company-Corp message that feels suspicious, please report it to security ...Additional Evidence... ",
    "ref": "/blog/20191111-pyramid-principle-examples/"
  },{
    "title": "Further Engineering Management Classes",
    "date": "",
    "description": "Further Engineering Management Classes",
    "body": "Some further classes I recommend for potential new engineering managers.\nhttps://www.harrisonmetal.com/library/objectives-key-results\nSo many companies want to set up goals in the OKR (Objective-Key Result) format. This shows some great examples how to format yours.\nhttps://www.harrisonmetal.com/library/storytelling-amp-presenting-1-thank-you-barbara-minto\nI use SCQA all the time in my communications both up to leadership and down to my teams. Highly recommend taking this class or reading The Pyramid Principle.\nhttps://www.harrisonmetal.com/classes/gm2-setting-goals-measuring-performance\nIf you\u0026rsquo;re a manager, you\u0026rsquo;re going to have to figure out a way to set goals for your teams and measure the performance of those goals. This will help.\nhttps://www.harrisonmetal.com/classes/business-leadership\nA three-day class on how to be a better leader for your group.\nhttps://www.harrisonmetal.com/classes/performance-review-lab\nHow to give great performance reviews (and how you shouldn\u0026rsquo;t be talking about performance once a year).\nhttps://www.eventbrite.com/e/influence-without-authority-online-workshop-registration-125979033681?aff=ebdsoporgprofile\nI had a former colleague say the true measure of someone\u0026rsquo;s effectiveness is not how they manage their direct reports, but how they manage to get their agenda done in the larger organization, and motivate people who don\u0026rsquo;t report to them to work on tasks that are important to them. This class helps with those skills.\n",
    "ref": "/blog/20190607-further-engineering-management-classes/"
  },{
    "title": "Project Planning Notes",
    "date": "",
    "description": "",
    "body": "More Shared Knowledge on Projects Include more people in code reviews even if they\u0026rsquo;re not actively picking up development tasks \u0026ndash; this shares out knowledge of the changes and gets another set of eyes that can ask good questions Break team silos, share knowledge Do Team PR\u0026rsquo;s for big PR\u0026rsquo;s Ideally break work into small pieces though Do team share of projects for tech projects, share knowledge Team Collab! Metrics/Monitoring/Data Implement monitoring and error visibility to make it easier to debug problems down the road. Data driven approach whenever we can to illustrate impact. This can be something we start collection at the beginning and continue through out the project. implement monitoring \u0026amp; debugging for every milestone, every deliverable Testing \u0026amp; Tech Debt Automated testing early in the process Test Plan/Test Matrix up-front Fix broken windows along the way broker time for tech debt broker time for related bugs in the backlog Status Update/Communication Constant, detailed, concise status updates in channel \u0026ndash; this is particularly helpful when rolling new people on because you can say \u0026ldquo;please go back and read the content of the channel for the past week\u0026rdquo; Frequent check-ins/deliverables Customers/Users to consult with along the way highlight risks early and often Clear Communication of Risks, Early \u0026amp; Often Roll out plans Disorganization from not knowing what work streams are in progress and who is working on what tasks Clear Status Updates in Channel Nice for on-boarding new folks clear comms, high vis Kickoff \u0026amp; Milestones Clear Milestones What is the smallest thing we can deliver to our customers/partners so they can validate our approach? Clear outline of project goals and milestones, this helps us fall back on the main objective when things get unorganized Kick Off! Celebration, where we\u0026rsquo;re going Outline what we want to build Why we\u0026rsquo;re doing it Is how that important? What you\u0026rsquo;re going to do is not that important 🎉 Continue celebrating small wins! You need time devoted to design, review, write tech specs You need time for fast-follow work that you uncover along the way Clear Project Goals \u0026amp; Milestones when things get disorganized, what to do Project Task Tracking Doc Keeping a separate project doc that tracks tasks and stories. It can be a bit of a pain to manage and sometimes is a couple days out of date, but I\u0026rsquo;ve found it very helpful in keeping alignment on the work left to do for a project Take into accounts bugs and broken windows you can fix along the way Don’t be too fine grained on certain tasks Things can be rough if clear. You don’t need a page long ticket for a one line change Tech Specs / RFCs Pre-planning for any project should begin much before the actual work Getting familiar with code base Setting up environment etc etc Tech specs or brain storming sessions that involve the entire team in the design process. Create a detailed design doc to iron out the implementation details no matter how small the feature/project is take them through the appropriate design reviews RFCs Full RFC overview right before the official kick-off. could be an engineering focused project where we comb through assumptions and highlight any risks. This might also help with setting original expectations on delivery date Swarming Full Team Swarming has value Reduce having single developers on projects Attempting to breakdown work or introduce parallelism for projects that were not initially designed that way can cause problems. Figure out in the design phase what work that can be done in parallel (planning for multiple developers) ",
    "ref": "/blog/20190202-project-planning-notes/"
  },{
    "title": "Manager Conference Links",
    "date": "",
    "description": "Manager Manager Conference Links",
    "body": "A couple of EM conferences folks might find useful:\nSFELC Summit\nAn annual celebration for engineering leaders.\nA wide range of topics. One day, multiple tracks. Great speaker lineup. A refresher on management fundamentals. Workshops and Breakouts.\nCalibrate\nYou’re a great engineer. Become a great leader. Calibrate is aimed at practicing engineering managers, responsible for the people on their team.\nYou can find videos of previous years here.\nTEMSCON\nResearch-focused engineering management conference.\n",
    "ref": "/blog/20180115-manager-conference-links/"
  },{
    "title": "ElasticSearch Perf - Highlighter Edition",
    "date": "",
    "description": "Examine sharding and highlighting strategy with ES",
    "body": "Wanted to share the results of the work we\u0026rsquo;ve been doing to improve performance and stabilize our ES cluster.\nShort Version: Changing sharding and \u0026ldquo;highlighting\u0026rdquo; strategies when doing FreeText searches dramatically impacts performance.\nLong Version: We\u0026rsquo;ve been load testing various aspects of search to pinpoint features we use that create large amounts of load on the system. Our initial research pointed at normal searches and freetext searches as being problematic.\nOne of the tests we ran examined \u0026ldquo;highlighting\u0026rdquo; in freetext search. \u0026ldquo;Highlighting\u0026rdquo; is the selection of relevant criteria when you search for words or phrases in a document.\nThe graph below is an illustration of some load testing we did around highlighting. The red squares represent, in order of appearance:\n5 shards, highlighting freetext results 1 shard, highlighting freetext results 5 shares, no highlighting, freetext results 1 shard, no highlighting, freetext results Our conclusions from these graphs:\n5 shards w/ highlighting takes a long time and a lot of resources 1 shard w/o highlighting is fast and doesn\u0026rsquo;t use many resources In researching highlighting, we found there are different ways to highlight results. We were using the default highlighter - the \u0026ldquo;plain\u0026rdquo; highlighter. There are other highlighters - the \u0026ldquo;unified\u0026rdquo; highlighter, for some example - that along with some index changes, promised significant performance improvements.\nIn this graph, the dots on the left represent the performance of the \u0026ldquo;plain\u0026rdquo; highlighter, while the dots on the right represent the \u0026ldquo;unified\u0026rdquo; highlighter.\nIt appears that a \u0026ldquo;unified\u0026rdquo; highlighter strategy is more performant than our original \u0026ldquo;plain\u0026rdquo; highlighter.\nLate today, we launched a new experiment with three indices:\nControl (5 Shards, \u0026ldquo;plain\u0026rdquo; highlighter) Variant 1 (1 Shard, \u0026ldquo;plain\u0026rdquo; highlighter) Variant 2 (1 Shard, \u0026ldquo;unified\u0026rdquo; highlighter) Here is a graph of the overall performance of the experiment so far:\nRed line (top): Variant 1. TP95: 1.7 seconds A single sharded strategy with the \u0026ldquo;plain\u0026rdquo; highlighter is much slower, though it consumes less ES resources than the 5 shard strategy.\nOrange line (middle): Control. TP95: 600 ms 5 shards with the \u0026ldquo;plain\u0026rdquo; highlighter responds must faster than a single shard, but it consumes more ES resources to run than the 1 shard strategy.\nBlue line (bottom): Variant 2. TP95: 150 ms A single shard, using the \u0026ldquo;unified\u0026rdquo; highlighter, is much more performant, and uses less system resources, than the other two variants.\n",
    "ref": "/blog/20181121-elasticsearch-perf-work/"
  },{
    "title": "Moment.js alternatives",
    "date": "",
    "description": "Moment.js alternatives",
    "body": "If you\u0026rsquo;re looking for moment.js alternatives, I\u0026rsquo;d recommend reading this article about smaller, lighter-weight moment.js alternatives.\n",
    "ref": "/blog/20180908-moment-js-alternatives/"
  },{
    "title": "Manager READMEs",
    "date": "",
    "description": "Manager READMEs",
    "body": "A friend recently introduced me to the ideas of creating a Manager README.\nThe idea is that for coworkers and new team members, you give a rundown of how you like to work and what they can expect.\nSome of the canonical READMEs that are frequently used as templates can be found here.\nA list of the current READMEs out in the wild (including mine), as well as some links to guides to help write them, can be found here.\nYou can read about my management style here.\n",
    "ref": "/blog/20180601-manager-readme/"
  },{
    "title": "ElasticSearch sharding work",
    "date": "",
    "description": "ElasticSearch sharding work",
    "body": "Wanted to share some insights my team has found with changing sharding strategies for ElasticSearch (ES).\nToday we moved 100% of my work\u0026rsquo;s search and autocomplete queries from a mutli-sharded index to a single-sharded index.\nShort version: Reducing shard count reduces system load, CPU usage, mostly positive results on performance.\nMedium version: In moving 100% of our searches and autocomplete queries from a mutli-sharded index to a single-sharded index, we saw drops in cluster load, queries generated by ES, and overall ES CPU usage.\nWe saw improvements in response time for retrieval and ranking from search.\nAlong with response time drops, we saw a smoothing of response times from search in general.\nAverage query \u0026amp; fetch times increased. While we reduced the total number of queries ES generated, each of those queries and fetches was doing more work.\nWe managed to reduce response from search but autocomplete (which uses the same indice) saw its average response time increase. The response time is now much more stable, and the service performs better under high load. In the graph below, the red line is autocomplete with a single shard, the yellow line is the 5-shard autocomplete response time. As our load increased during the day today, you can see the 5-shard performance steadily decrease while the single shard response remained steady.\n",
    "ref": "/blog/20180305-elasticsearch-sharding-work/"
  },{
    "title": "Engineering Management Classes",
    "date": "",
    "description": "Engineering Management Classes",
    "body": "Two classes I recommend for potential new engineering managers.\nhttps://www.harrisonmetal.com/classes/foundations-general-management\nThe course is designed to help new managers develop foundational skills in management and leadership.\nThe course covers several key topics, including:\nUnderstanding the role of a manager and developing a management philosophy Building effective teams and managing team dynamics Developing and executing strategy Managing operations and projects Building and managing relationships with stakeholders Leading change and managing transitions The course is divided into several modules, with each module covering a specific topic. The modules include video lectures, readings, case studies, and exercises to help learners apply the concepts in real-world situations. The course also includes discussion forums and opportunities to connect with other learners to facilitate collaboration and learning. The course covers 3 days, has great teachers, and teaches you basic skills needed to run a small business or team.\nOverall, the course aims to provide a comprehensive introduction to management and leadership, with a focus on practical skills and tools that new managers can apply in their day-to-day work.\nhttps://bradfieldcs.com/courses/leadership/\nThe course is designed to help software engineers develop the leadership skills necessary to advance in their careers and make an impact in their organizations. The course covers several key topics, including:\nBuilding effective teams and managing team dynamics Developing and executing strategy Communicating effectively and managing conflict Managing performance and providing feedback Building and managing relationships with stakeholders Leading change and managing transitions Developing a personal leadership style The course is divided into several modules, with each module covering a specific topic. The modules include video lectures, readings, case studies, and exercises to help learners apply the concepts in real-world situations. The course also includes discussion forums and opportunities to connect with other learners to facilitate collaboration and learning. This class meets twice a week for a month, providing great tactical skills for first time engineering managers.\nOverall, the course aims to provide a comprehensive introduction to leadership for software engineers, with a focus on practical skills and tools that learners can apply in their day-to-day work. The course is designed to be flexible and accessible, allowing learners to work at their own pace and on their own schedule.\n",
    "ref": "/blog/20171229-engineering-management-classes/"
  },{
    "title": "ElasticSearch Garbage Collection issues?",
    "date": "",
    "description": "Seeing high garbage collection with ElasticSearch?",
    "body": "Seeing high garbage collection with ElasticSearch? My team was seeing periodic 300ms+ garbage collection pauses. We found out that we had misconfigured our ES instances.\nIf you\u0026rsquo;re encountering this, make sure you\u0026rsquo;ve disabled memory swapping:\nhttps://www.elastic.co/guide/en/elasticsearch/reference/5.0/setup-configuration-memory.html\n",
    "ref": "/blog/20170813-elasticsearch-garbage-collection/"
  },{
    "title": "Moment.js instantiation slowness",
    "date": "",
    "description": "Moment.js instantiation slowness",
    "body": "Was doing some test speedup/performance improvement work recently on the search API and found out something; the moment.js library takes around 100 microseconds (or .1 milliseconds) to create a new instance.\nWhy is 100 microseconds a big deal?\nIf you\u0026rsquo;re processing:\n100 records Where each record has 7 date fields Then you\u0026rsquo;ve created 70,000 microseconds of work Or 70 milliseconds of processing delay. By doing some memoization of date formatting in our API, we\u0026rsquo;ve seen these performance improvements:\nResponse Times Before After Fastest 211ms 194ms Max 651ms 597ms Average 309ms 268ms Without making any significant changes, we\u0026rsquo;ve managed to shave 41ms off of our response time on average!\nHope this helps someone else.\n",
    "ref": "/blog/20170504-moment-js-instantiation-slowness/"
  },{
    "title": "Performance Improvement via node 4 to node 6",
    "date": "",
    "description": "Performance improvement via babel tranpilation removal",
    "body": "My team at work recently upgraded our codebase to use to node 6.9, as node 6 has recently gone to LTS.\nIn the picture below, the 1st line is the upgrade from node 4 to node 6, and the corresponding flattening of memory usage vs. load.\nThe 2nd line is our removal of redis connection queueing in the application.\nAll of all, the memory consumption of our application is now averaging around 150MB, down from a high of 1GB!\nHope this information helps all those teams considering upgrading their node projects.\n",
    "ref": "/blog/20161109-performance-improvement-via-babel-tranpilation-removal/"
  },{
    "title": "Superagent/Request Memory Leaks",
    "date": "",
    "description": "Superagent/Request Memory Leaks",
    "body": "Superagent/Request Memory Leaks The last several weeks Thomas Hunter and myself have spent some of our nights and weekends trying to track down memory leaks in an API we both work on.\nWe were seeing a distinct pattern, that when the API was put under a certain amount of load, that we would start slowly bleeding memory.\nWe\u0026rsquo;ve found three results:\nSuperagent, when put under a certain threshold of load and then connections timeout, can leak memory.\nThe PR to fix this issue has been merged: https://github.com/visionmedia/superagent/pull/1084 Request, when put under a certain threshold of load and then connections timeout, can leak memory.\nThe PR to fix this issue has been merged: https://github.com/request/request/pull/2420 Superagent, when not explicitly assigned a timeout parameter, can hold connections open and therefore leak memory\nThe fix for this is to call req.timeout(YOUR_TIMEOUT_VALUE) to resolve. The fixes for these issues are all in the latest versions of the libraries\n",
    "ref": "/blog/20161017-superagent-request-memory-leaks/"
  },{
    "title": "Node 4 and Babel 6 in Harmony",
    "date": "",
    "description": "A note for the upgrade from Node 4 and Babel 6",
    "body": "Pun in title intentional I upgraded a heap of projects I was working on to node 4.2.3 and babel 6.\nAs I did a quick and dirty upgrade, I kept thinking to myself: doesn\u0026rsquo;t node 4/5 have pretty good support for es6/2015?\nAs I was looking around the internet for Hello Kitty Formalwear babel 6 upgrade tips, I came across this package which read my mind.\nSo if you\u0026rsquo;re a node 4/5 user, by doing this:\nnpm install --save-dev babel-preset-es2015-node4 Then changing your .babelrc to look something like this:\n{ \u0026#34;presets\u0026#34;: [\u0026#34;es2015-node4\u0026#34;] } you\u0026rsquo;ll get the minimal tranpilation needed to use the latest ES6 features with node 4/5.\n",
    "ref": "/blog/20160116-node-4-and-babel-6/"
  },{
    "title": "Guide to upgrading from Babel 5 => 6",
    "date": "",
    "description": "Guide to upgrading from Babel 5 => 6",
    "body": "Because it\u0026rsquo;s changed since October There have been a bunch of guides on upgrading to babel 5.\nEven those written in the last two months are already out of date. Babel moves annoyingly fast.\nPlease note: this is up to date as of 6.3.13. As I write this, it might also be obsolete.\nSkip babel-core and babel-loader. User babel-register. Due to some complaints about the various ways you could bootstrap babel into an app, there is now babel-register.\nIf you\u0026rsquo;ve held onto using babel 5 until now, porting over couldn\u0026rsquo;t be easier:\nReplace require('babel/register') with require('babel-register').\nAssuming you\u0026rsquo;ve installed the babel-register package.\n.babelrc You\u0026rsquo;ll want to create a .babelrc file to store your babel settings. For most folks, the easiest port from 5 =\u0026gt; 6 looks like this:\n{ \u0026#34;presets\u0026#34;: [\u0026#34;es2015\u0026#34;] } This also assumes you\u0026rsquo;ve installed the babel-preset-es2015 package. This will give you most of the es2015 behavior you had. With caveats.\nExporting and Destructing Objects? Whoops Apparently in ES6 you can\u0026rsquo;t export and then destructure objects.\nWhich means if you have any code that looks like this:\nexport default { a: 1, b: 2, c: 3 } with an import like this:\nimport {a,b,c} from \u0026#39;./terrible-json-object\u0026#39;; you\u0026rsquo;re in a bit of a pickle. You could upgrade your code to ES6 standards, OR you can install babel-plugin-add-module-exports in your codebase, and add the plugin to your .babelrc:\n{ \u0026#34;presets\u0026#34;: [\u0026#34;es2015\u0026#34;], \u0026#34;plugins\u0026#34;: [\u0026#34;add-module-exports\u0026#34;] } This restores the behavior of Babel 5 in this case, which while not strictly ES6 compliant, will at least allow you to upgrade without having to change a ton of code.\nCrisis adverted.\nPLEASE NOTE: Some Babel 5 features are missing from Babel 6 One method I\u0026rsquo;ve found missing is Object.values.\nObject.values is an ES7 stage 3 proposal and is part of Babel 5 but there is no support for this functionality in Babel 6. Yet. Again, this might be out of date as of the writing of this article.\nAs of today this has not appeared in the official Stage 3 plugin from Babel.\n",
    "ref": "/blog/20151231-for-real-upgrade-babel-5-to-6/"
  },{
    "title": "Move your Open Source work to Node 4",
    "date": "",
    "description": "Move your Open Source work to Node 4",
    "body": "Now that Node 4 has been released, isn\u0026rsquo;t it time you upgraded your OS (Open Source) projects to use it?\nStep 1 - package.json If you\u0026rsquo;re not already using it, the engines field in your package.json allows you to specify what version of node you designed your package to run on. The engines field is not strict - you can\u0026rsquo;t force your consumers to use a preferred engine, but you can warn them if your package uses features that aren\u0026rsquo;t available in all version of node.\nMost people won\u0026rsquo;t need to upgrade this to use Node 4, but it\u0026rsquo;s good to be aware of.\n.travis.yml I use travis to build and test my open source projects. To get my OS work running on thew new version of node, I needed to update my .travis.yml files to specify the new version of node.\nThe first part was easy:\nnode_js: - \u0026#34;4\u0026#34; I pushed my travis change, and I was hoping for a big fat green build message. Not so fast. Errors.\nLong story short - to compile native modules in Node 4, you need a C++ compiler. Luckily you can configure travis to use one.\nAdd the following to your .travis.yml files\nenv: - CXX=g++-4.8 addons: apt: sources: - ubuntu-toolchain-r-test packages: - g++-4.8 BOOM!!! Big green build. Hope this helps folks out there.\n",
    "ref": "/blog/20150910-upgrade-travis-and-os-for-node-4/"
  },{
    "title": "The (0, func) operation in transpiled code",
    "date": "",
    "description": "Figuring out JS quirks",
    "body": "Was looking at some decompiled code from ES6 the other day, when I saw a line that looked like this:\nvar x = (0, anObject.aFunc)(params); WTF? I had never seen syntax like this before in JavaScript. Time to dig into the docs.\nParaphrasing from Mozilla and StackOverflow:\nWhen you write expressions separated by a comma (,) JavaScript evaluates all the expressions in order and returns the value of the last expression.\nMeaning the expression (x=1, y=2, anObject.aFunc) would set the variables x and y, and return anObject.aFunc to the caller.\nNow that we know what is going on, why?\nHere is the explanation I cobbled together from the Interwebs:\nWhen you call anObject.aFunc(), this is equal to anObject because aFunc is coupled to anObject.\nWhen you call (0, anObject.aFunc)(), you have decoupled aFunc from anObject, so this is no longer equal to anObject in aFunc.\nIn this case, this would be equal to the global object - window in the browser, or global in node.\nSo in the example given above:\nvar x = (0, anObject.aFunc)(params); Code that would have the same output (in the browser):\nvar x = anObject.aFunc.call(window, params); Or, even more trivially:\nvar boundToWindow = anObject.aFunc; var x = boundToWindow(params); ",
    "ref": "/blog/20150420-0-func-operator-and-decoupling/"
  },{
    "title": "Replaying changes from one git branch onto another",
    "date": "",
    "description": "Replaying changes from one git branch onto another",
    "body": "Or rebasing without rebasing Where I work, we use git (like everyone else), and we follow this common pattern for development:\nCreate a feature branch off of master Work on your feature in the branch When getting ready to submit a Pull Request, squash your commits Rebase master against your branch Open PR Get feedback After feedback corrected (if present), merge branch into master Pretty standard practice. 99% of the time, this is a frictionless process.\nThe other day I picked up a story which, while small in scope, touched a ton of files.\nThe path to failure I created a branch, did the work, but never squashed my commits - I basically skipped step 3 - and tried to rebase master against my branch. I got the common enemy of every PR - merge conflicts.\nCompounding failure I had 5+ commits in the branch. The idea of wading through multiple failing rebase steps left me queasy, so I abandoned the rebase and went to merge master.\nSo to add to my failure at step 3, now I had skipped step 4 as well.\nAfter getting the code working I pushed my PR. I received some minor feedback, updated my code, and went to merge master again. More merge conflicts.\nI fixed those conflicts, but now I had a convoluted history of un-squashed commits and two merges. This was both out of practice and felt sloppy.\nFinding a solution When you have a messed up git history, you normally do a git rebase --interactive, fix your commit history, and move on.\nBut with the merges scattered between commits, an interactive rebase would be difficult.\nIt also won\u0026rsquo;t give you what you want - a single commit.\nThe solution Enter git symbolic-ref.\nThis command, while well documented, doesn\u0026rsquo;t give away the true beauty of this command.\nHiding on this line is the heart of the command:\nGiven two arguments, creates or updates a symbolic ref \u0026lt;name\u0026gt; to point at the given branch .\nWhat does this do? Let\u0026rsquo;s say you\u0026rsquo;re working on a sloppy branch. You want to carry over those changes onto another branch (like master), without changing the history of the that branch.\ngit symbolic-ref HEAD refs/heads/master sets the state of the current branch onto master. You haven\u0026rsquo;t changed the history - git modifies the files on master to match the state of your branch. The commit history doesn\u0026rsquo;t change. What this means is that doing something like this:\ngit checkout super-sloppy-work-branch //this causes you to \u0026#39;checkout\u0026#39; master, but with your current file changes from the sloppy branch git symbolic-ref HEAD refs/heads/master git checkout -b new-branch-that-is-great git add -A git commit -m \u0026#39;I totally did this work in one pass\u0026#39; Will give you a one-commit branch with all the work you did in the sloppy branch, but against the latest version of master. Pretty cool!\n",
    "ref": "/blog/20150216-git-rebasing-without-rebasing/"
  },{
    "title": "Code coverage for CoffeeScript and JavaScript without pre-compiling",
    "date": "",
    "description": "Code coverage for CoffeeScript and JavaScript using gulp and istanbul without pre-compiling",
    "body": "If you\u0026rsquo;re not aware of your code coverage when building a serious application, you\u0026rsquo;re not building a serious app.\nSo I love istanbul and gulp-istanbul.\nOne problem - you have to compile your CoffeeScript, then point you tests at the compiled assets to get coverage metrics.\nNot anymore. Introducing gulp-coffee-istanbul. This allows in place CoffeeScript test coverage.\nHave tests in coffee? Great. Have tests in JS? Great too. Same with your dependencies - it\u0026rsquo;ll take both, in place, and run coverage.\nA quick and dirty example:\nistanbul = require(\u0026#39;gulp-coffee-istanbul\u0026#39;) # We\u0026#39;ll use mocha here, but any test framework will work mocha = require(\u0026#39;gulp-mocha\u0026#39;) jsFiles = [\u0026#39;config/**/*.js\u0026#39;, \u0026#39;controllers/**/*.js\u0026#39;, \u0026#39;models/**/*.js\u0026#39;, \u0026#39;app.js\u0026#39;] specFiles = [\u0026#39;spec/**/*.coffee\u0026#39;] coffeeFiles = [\u0026#39;src/**/*.coffee\u0026#39;] gulp.task \u0026#39;test\u0026#39;, -\u0026gt; gulp.src jsFiles.concat(coffeeFiles) .pipe istanbul({includeUntested: true}) # Covering files .pipe istanbul.hookRequire() .on \u0026#39;finish\u0026#39;, -\u0026gt; gulp.src specFiles .pipe mocha reporter: \u0026#39;spec\u0026#39; .pipe istanbul.writeReports() # Creating the reports after tests run Which will give you\nNotice that both coffee and js files are shown in the output.\n",
    "ref": "/blog/20141204-gulp-coffee-istanbul/"
  },{
    "title": "It took pivotal 3 years to close a pull request",
    "date": "",
    "description": "jasmine-node, beforeAll & afterAll",
    "body": "On Feb 9, 2011, Fat (Jacob Thornton, one of the creators on Bootstrap) opened a pull request to add beforeAll and afterAll statements to the jasmine library.\nPivotal, at the time, thought that they were just about to implement:\nThat tweet was from December 2010.\nSince then, a couple people have come up with workarounds.\nAnd now, over three years later, pivotal is about to release beforeAll/afterAll.\nYou can check out the work here.\n",
    "ref": "/blog/20141013-jasmine-node-before-all-after-all/"
  },{
    "title": "express-coffee-react-views",
    "date": "",
    "description": "Express View Engine for Rendering JSX Components written in CoffeeScript",
    "body": "This is an Express view engine which renders React components written in CoffeeScript on the server. It renders static markup and does not support mounting those views on the client.\nThis was derived from express-react-views\nThis is intended to be used as a replacement for existing server-side view solutions, like jade, ejs, or handlebars.\nUsage npm install express-coffee-react-views react Note: You must explicitly install react as a dependency. react is a peer dependency here. This is to avoid issues that may come when using incompatible versions.\nAdd it to your app. # app.coffee app = express() app.set \u0026#39;view engine\u0026#39;, \u0026#39;cjsx\u0026#39; app.engine \u0026#39;cjsx\u0026#39;, require(\u0026#39;express-coffee-react-views\u0026#39;).createEngine() Options You can pass options in when creating your engine.\noption values default extension any file extension with leading . \u0026quot;.cjsx\u0026quot; doctype any string that can be used as a doctype, this will be prepended to your document \u0026quot;\u0026lt;!DOCTYPE html\u0026gt;\u0026quot; beautify true: beautify markup before outputting (note, this can affect rendering due to additional whitespace) false The defaults are sane, but just in case you want to change something, here\u0026rsquo;s how it would look:\noptions = extension: \u0026#39;.csx\u0026#39; app.engine \u0026#39;cjsx\u0026#39;, require(\u0026#39;express-coffee-react-views\u0026#39;).createEngine options Views Your views should be node modules that export a React component. Let\u0026rsquo;s assume you have this file in views/index.cjsx:\n/** @cjsx React.DOM */ HelloMessage = React.createClass render: -\u0026gt; \u0026lt;div\u0026gt;Hello {this.props.name}\u0026lt;/div\u0026gt; module.exports = HelloMessage Routes Your routes would look identical to the default routes Express gives you out of the box.\n# app.coffee app.get \u0026#39;/\u0026#39;, require(\u0026#39;./routes\u0026#39;).index # routes/index.coffee exports.index = (req, res) -\u0026gt; res.render \u0026#39;index\u0026#39;, { name: \u0026#39;John\u0026#39; } That\u0026rsquo;s it! Layouts follow really naturally from the idea of composition.\nLayouts Simply pass the relevant props to a layout component.\nviews/layouts/default.cjsx:\n/** @cjsx React.DOM */ DefaultLayout = React.createClass render: -\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;{this.props.title}\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt;{this.props.children}\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; module.exports = DefaultLayout views/index.cjsx:\n/** @cjsx React.DOM */ DefaultLayout = require \u0026#39;./layouts/default\u0026#39; HelloMessage = React.createClass render: -\u0026gt; \u0026lt;DefaultLayout title={this.props.title}\u0026gt; \u0026lt;div\u0026gt;Hello {this.props.name}\u0026lt;/div\u0026gt; \u0026lt;/DefaultLayout\u0026gt; module.exports = HelloMessage Questions What about partials \u0026amp; includes? These ideas don\u0026rsquo;t really apply. But since they are familiar ideas to people coming from more traditional \u0026ldquo;templating\u0026rdquo; solutions, let\u0026rsquo;s address it. Most of these can be solved by packaging up another component that encapsulates that piece of functionality.\nWhat about view helpers? I know you\u0026rsquo;re used to registering helpers with your view helper (hbs.registerHelper('something', ...))) and operating on strings. But you don\u0026rsquo;t need to do that here.\nMany helpers can be turned into components. Then you can just require and use them in your view. You have access to everything else in CoffeeScript. If you want to do some date formatting, you can require('moment') and use directly in your view. You can bundle up other helpers as you please. Where does my data come from? All \u0026ldquo;locals\u0026rdquo; are exposed to your view in this.props. These should work identically to other view engines.\nUsing this.props follows the pattern of passing data into a React component, which is why we do it that way.\nRemember, as with other engines, rendering is synchronous. If you have database access or other async operations, they should be done in your routes.\nCaveats I\u0026rsquo;m saying it again to avoid confusion: this does not do anything with React in the browser. This is only a solution for server-side rendering. This uses require to access your views. This means that the plugin caches the contents for the lifetime of the server process. You need to restart your server when making changes to your views. In development, we clear your view files from the cache so you can refresh your browser to see changes. React \u0026amp; JSX have their own rendering caveats. For example, inline \u0026lt;script\u0026gt;s and \u0026lt;style\u0026gt;s will need to use dangerouslySetInnerHTML={{__html: 'script content'}}. \u0026lt;script dangerouslySetInnerHTML={{__html: \u0026#34;\u0026#34;\u0026#34; # google analtyics # is a common use \u0026#34;\u0026#34;\u0026#34;}} /\u0026gt; It\u0026rsquo;s not possible to specify a doctype in JSX. You can override the default HTML5 doctype in the options. ",
    "ref": "/blog/20141008-express-coffee-react-views/"
  },{
    "title": "React and the annoyances of JSX",
    "date": "",
    "description": "React and JSX. class vs className, for vs htmlFor",
    "body": "I\u0026rsquo;ve been writing a bunch of React code and a heap of JSX at work.\nReact (coupled with Flux) has been a joy to work with. The uni-directional data flow makes understanding the state of your application at any point easy to understand. The gradual componentization of our UI codebase is a beautiful thing to witness. That, coupled with a component based CSS system (using BEM guidelines for naming classes) has removed the messy bleed over we were having with some of our old css code.\nOne thing that has consistently annoyed my team has been JSX. Basically, we wish we had something like handlebars that React could use on top of its virtual DOM.\n(And yes, we know about Ractive.js. If there was better community support for it, we\u0026rsquo;d probably be using it).\nWhat is annoying us?\nYou can write template code ANYWHERE. We found some places where we had five different methods in one component that contained JSX. Maybe that\u0026rsquo;s just development, but because JSX is just JavaScript, and you can use JavaScript in your JSX, the reverse is also true. You can hide markup anywhere in your components you feel like it.\nIt\u0026rsquo;s just close enough to HTML to annoy you. This should be a minor annoyance. But when you\u0026rsquo;re copying between HTML and React on a massive rewrite of a legacy system, it becomes painful.\nHow is this a problem? I take the markup for an existing component. I copy the markup into React, convert over some fields, get everything working, and then I open up my browser console to get waylaid with tons of React warnings. About what? About my using \u0026ldquo;for\u0026rdquo; or \u0026ldquo;class\u0026rdquo; attributes in my markup.\nThese are valid HTML attributes, but in React, you have to use \u0026ldquo;htmlFor\u0026rdquo; and \u0026ldquo;className\u0026rdquo; respectively.\nWhy? Because Facebook hates you and decides against logical arguments.\nApparently at some point, you could at least use \u0026ldquo;class\u0026rdquo; in your JSX. But at some point the executive decision was made that because JSX is JavaScript, you shouldn\u0026rsquo;t be able to use reserved words in JSX (like \u0026ldquo;class\u0026rdquo; and \u0026ldquo;for\u0026rdquo;). Even though JSX gets interpolated into JavaScript. And it\u0026rsquo;s got angle brackets. And it almost identically resembles HTML.\n",
    "ref": "/blog/20140909-react-jsx-class-classname-for-htmlfor/"
  },{
    "title": "Ember.Data Model Issues",
    "date": "",
    "description": "Ember.Data Model Issues",
    "body": "I was working with some older Ember.Data code, and I came across a model like this:\nApp.MyFancyModel = DS.Model.extend({ isSelected: false, isSomethingElse: DS.attr(\u0026#39;boolean\u0026#39;, {defaultValue: false}) }); I thought this code was a bit strange, and then went and played with it a bit:\naFancyModel.get(\u0026#39;isSelected\u0026#39;); //returns false aFancyModel.set(\u0026#39;isSelected\u0026#39;, true); aFancyModel.get(\u0026#39;isSelected\u0026#39;); //returns true aFancyModel.get(\u0026#39;isSomethingElse\u0026#39;); //returns false aFancyModel.set(\u0026#39;isSomethingElse\u0026#39;, true); aFancyModel.get(\u0026#39;isSomethingElse\u0026#39;); //returns true I got identical behavior from the two properties. Then, I tried this:\naFancyModel.set(\u0026#39;isSelected\u0026#39;, true); aFancyModel.get(\u0026#39;isDirty\u0026#39;); //RETURNS FALSE aFancyModel.set(\u0026#39;isSomethingElse\u0026#39;, true); aFancyModel.get(\u0026#39;isDirty\u0026#39;); //RETURNS TRUE!!! My question was this: was this the expected behavior? I can\u0026rsquo;t find any documentation on setting boolean values directly on the model like this anywhere in the Ember.Data docs.\nAfter asking around on discuss.emberjs.com, I got an answer.\nThis behavior is by design. Fields designated with just a variable (e.g. isSelected) are local attributes. You can use them just like an other attribute.\nThe difference with fields declared this way is they won\u0026rsquo;t dirty the model and they aren\u0026rsquo;t sent across the wire on save or update.\n",
    "ref": "/blog/20140708-ember-data-model-issue-boolean/"
  },{
    "title": "Ember.Data Promise-Aware Properties (Cheaters Edition)",
    "date": "",
    "description": "Ember.Data Promise-Aware Properties (Cheaters Edition)",
    "body": "I have models like this:\nModels App.Child = DS.Model.extend({ parent: DS.belongsTo(\u0026#39;parent\u0026#39;, {async: true}) }); App.Parent = DS.Model.extend({ children: DS.hasMany(\u0026#39;child\u0026#39;, {async: true}) }); App.Nursery = DS.Model.extend({ children: DS.hasMany(\u0026#39;child\u0026#39;) }); Then a controller like this:\n###Controller\nApp.NurseryController = Ember.Controller.extend({ uniqueParents = function() { return this.get(\u0026#39;children\u0026#39;).mapBy(\u0026#39;parent\u0026#39;).uniq(); }.property(\u0026#39;children\u0026#39;), somethingLikeReliesOnUniqueParents = function() { .... }.property(\u0026#39;uniqueParents\u0026#39;) } The Problem The property somethingLikeReliesOnUniqueParents was never getting unique values. I found two problems here:\nuniq() couldn\u0026rsquo;t figure out uniqueness - much like the problems with filter. The parents promises, once they resolved, weren\u0026rsquo;t updating properties that relied on them. The first problem I solved the same way I solved in the filter case - filter uniqueness by id, not by object.\nThe second problem I found a somewhat hacky workaround. All promises in the system have a isFulfilled flag. Setting the properties to observe that field allowed the properties to update.\nThe Solution My code ended up looking like this:\n###Controller\nApp.NurseryController = Ember.Controller.extend({ uniqueParents = function() { return this.get(\u0026#39;children\u0026#39;).mapBy(\u0026#39;parent\u0026#39;).uniq(function(parent) { return parent.get(\u0026#39;id\u0026#39;); }); }.property(\u0026#39;children\u0026#39;), somethingLikeReliesOnUniqueParents = function() { .... }.property(\u0026#39;uniqueParents.@each.isFulfilled\u0026#39;) } This solved the issue and still allowed the async behavior I was looking for.\n",
    "ref": "/blog/20140711-ember-data-promise-aware-properties/"
  },{
    "title": "Stuff to mind when writing ES6 code",
    "date": "",
    "description": "Stuff to mind when writing ES6 code",
    "body": "These are some good tips I picked up browsing the ember and ember.data commits. Nice if you\u0026rsquo;re looking for best practices in writing ES6 code.\nexample: diverging bindings\nthis is an issue when dealing with cycles.\nbad: (diverges bindings)\nimport { foo } from \u0026#39;bar\u0026#39;; var otherFoo = foo; foo: (if the rename is actually needed) good:\nimport { foo as otherFoo } from \u0026#39;bar\u0026#39;; example: closure compiler dead code remove friendly:\nbad: closure compile wont drop, bar if foo is used, or foo if bar is used\nexport default { foo: function() { }, bar: function() { } } good: closure compile will drop whats not used correctly.\nexport function foo() { } export function bar() { } Some other interesting tidbits (not sure of the validity of all of these, but this is what some of the Ember guys claim):\nre-using argument variables makes it quite hard to see the original value re-using argument variables has some negative performance side-effects. using the comma operator for long variable declarations makes it impossible to easily set breakpoints. ",
    "ref": "/blog/20140701-stuff-to-mind-es6/"
  },{
    "title": "Post about Songbird on npmawesome",
    "date": "",
    "description": "Post about Songbird on npmawesome",
    "body": "The folks at npmawesome wrote a blog post about the Songbird library I wrote.\nSongbird is a library that mixes in promise helpers in the Function and Object prototypes on JavaScript. This is a technique that not everybody loves, and I think the author made a great observation about Songbird (and this technique in general).\nWhile I think it\u0026rsquo;s a great idea to mix in the promise property to Object and Function, however with great power comes great responsibility. I strongly urge against using songbird in modules that you would distribute on npm because it would have a very big side effect on anyone who dares to install your code. However, when used on a project that isn\u0026rsquo;t made available publicly, songbird would be a great asset.\nCheck out the blog post here.\n",
    "ref": "/blog/20140626-post-about-songbird-on-npmawesome/"
  },{
    "title": "WriteGooder for Sublime Text",
    "date": "",
    "description": "WriteGooder for Sublime Text",
    "body": "Simple grammar checking for your documentation.\nPrerequisites: write-gooder and Sublime Package Control\nMac OS X: Installing node with homebrew or macports is assumed. The path to write-gooder is hardcoded in this plugin as /usr/local/share/npm/bin:/usr/local/bin:/opt/local/bin. You can change the path to the executable in settings.\nLinux: Make sure write-gooder is in your environment path.\nWindows: Installing node with the Windows Installer from nodejs.org is assumed.\n##Install write-gooder with npm\nnpm install -g duereg/write-gooder\n##Install WriteGooder with Package Control in Sublime Text\ncommand-shift-P or control-shift-P in Linux/Windows* type install p, select Package Control: Install Package type WriteGooder, select WriteGooder Note: Without Sublime Package Control, you could manually copy this project to your Packages directory as \u0026lsquo;WriteGooder\u0026rsquo;.\n##Run WriteGooder on an active Markdown file in Sublime Text\ncontrol-shift-W or Tools/Contextual menus or the Command Palette F4 jump to next error row/column shift-F4 jump to previous error row-column ",
    "ref": "/blog/20140622-sublime-text-write-gooder/"
  },{
    "title": "Ember Model.isDirty - or not",
    "date": "",
    "description": "Ember Model.isDirty - or not",
    "body": "In Ember, if you have models like this:\nvar Tag = DS.Model.extend({ name: DS.attr(\u0026#39;string\u0026#39;), person: DS.belongsTo(\u0026#39;person\u0026#39;) }); var Person = DS.Model.extend({ name: DS.attr(\u0026#39;string\u0026#39;), tags: DS.hasMany(\u0026#39;tag\u0026#39;) }); Then did something like this:\nvar tag1 = this.store.find(\u0026#39;tag\u0026#39;, 1); tag1.get(\u0026#39;isDirty\u0026#39;); //returns false tag1.get(\u0026#39;name\u0026#39;); //return null tag1.set(\u0026#39;name\u0026#39;, \u0026#39;foo\u0026#39;); tag1.get(\u0026#39;isDirty\u0026#39;); //returns true That would be the obvious outcome, right?\nHowever, if you do this:\nvar tag1 = this.store.find(\u0026#39;tag\u0026#39;, 1); var thatGuy = this.store.find(\u0026#39;person\u0026#39;, 1); tag1.get(\u0026#39;isDirty\u0026#39;); //returns false tag.get(\u0026#39;person\u0026#39;); //returns null tag1.set(\u0026#39;person\u0026#39;, thatGuy); //set person on tag tag1.get(\u0026#39;isDirty\u0026#39;); //returns false Because Ember does not check relationships when figuring out isDirty.\nHere is the issue on github\nHere is a solution proposed by someone else (that I do not think solves the problem)\n",
    "ref": "/blog/20140605-ember-model-isdirty-or-not/"
  },{
    "title": "Ember Data Contributions",
    "date": "",
    "description": "Ember Data Contributions",
    "body": "My contributions to Ember.Data!\nHad three pull requests accepted in the last couple of days.\nNow only if they\u0026rsquo;d release version 1.0 \u0026hellip;\n",
    "ref": "/blog/20140518-ember-data-contributor/"
  },{
    "title": "Ember Official Contributor!",
    "date": "",
    "description": "Ember Official Contributor!",
    "body": "Check Out My Contribution to Ember!\n(Not sexy but I\u0026rsquo;m happy to be helping out.)\n",
    "ref": "/blog/20140505-ember-official-contributor/"
  },{
    "title": "Ember FilterBy Fun",
    "date": "",
    "description": "Ember FilterBy Fun",
    "body": "If you happen to be writing filterBy statements in Ember against an object, you will want to use this syntax:\nskusForStyle: function(style) { return this.get(\u0026#39;mergedSkus\u0026#39;).filterBy(\u0026#39;style.id\u0026#39;, style.get(\u0026#39;id\u0026#39;)); } Instead of this similar looking but exceptionally evil and non-functioning cousin:\nskusForStyle: function(style) { return this.get(\u0026#39;mergedSkus\u0026#39;).filterBy(\u0026#39;style\u0026#39;, style); } ",
    "ref": "/blog/20140429-ember-filterby-fun/"
  },{
    "title": "Ember - Test Teardown Error",
    "date": "",
    "description": "Ember - Test Teardown Error",
    "body": "Cannot read property \u0026lsquo;addObject\u0026rsquo; of null If you see the following error in Ember.Data 1.0.0-beta.7:\nCannot read property \u0026#39;addObject\u0026#39; of null TypeError: Cannot read property \u0026#39;addObject\u0026#39; of null at Ember.ArrayProxy.extend.addRecord at Ember.Object.extend.updateRecordArray at null.\u0026lt;anonymous\u0026gt; I found this had to do with Test teardown. A monkey patch that solves the issue:\nDS.RecordArray.reopen({ addRecord: function(record) { var thing = Ember.get(this, \u0026#39;content\u0026#39;); if(thing) { this._super(record); } } }); ",
    "ref": "/blog/20140410-ember-test-teardown-errors/"
  },{
    "title": "Ember - The content property of DS.PromiseArray should be set before modifying it",
    "date": "",
    "description": "Ember - The content property of DS.PromiseArray should be set before modifying it",
    "body": "The content property of DS.PromiseArray should be set before modifying it If you see the following error in Ember.Data 1.0.0-beta.7:\nThe content property of DS.PromiseArray should be set before modifying it\nThe issue is with changing the contents of an async field.\n//program.js Program = DS.Model.extend({ styles: DS.hasMany(\u0026#39;style\u0026#39;, {async: true}), }); Style = DS.Model.extend({}); and then used like so:\nprogram.get(\u0026#39;styles\u0026#39;).pushObject(style); That code will throw the exception listed above. To work around this behavior, do the following:\nprogram.get(\u0026#39;styles\u0026#39;).then(function(styles){ styles.pushObject(style); }); A gist talking about the issue is here.\n",
    "ref": "/blog/20140408-ember-the-content-property-of-ds-promise-array/"
  },{
    "title": "Ember vs Knockout - Property Comparison",
    "date": "",
    "description": "Ember vs Knockout - Property Comparison",
    "body": "A small, appropriate comparison At ModCloth, I\u0026rsquo;ve been working on an internal application that uses Ember.js as its front end framework. In learning Ember I\u0026rsquo;ve noticed some interesting architectural decisions they\u0026rsquo;ve made.\nThis article will concentrate on their Observable Models in comparison with how Knockout built the same functionality.\nTANGENT\nEmber.js and Knockout are great contrasts in the library vs framework debate in JS development.\nEmber is\nA framework for creating ambitious web applications.\n(emphasis is mine).\nKnockout is a library whose goal is to\nSimplify dynamic JavaScript UIs with the Model-View-View Model (MVVM) pattern.\nEmber is outspoken and proud of its framework status. Knockout makes it clear that it is a small library for building dynamic JavaScript UIs.\nEmber, while a year younger than Knockout, has SIX TIMES as many commits as Knockout. It\u0026rsquo;s also 4 times the size (71kb vs 17kb, once minified and gzipped).\n/TANGENT\nRead-only computed properties Ember firstName: null, lastName: null, fullName: function() { return this.get(\u0026#39;firstName\u0026#39;) + \u0026#39; \u0026#39; + this.get(\u0026#39;lastName\u0026#39;); }.property(\u0026#39;firstName\u0026#39;, \u0026#39;lastName\u0026#39;) Knockout this.firstName = ko.observable(\u0026#39;Bob\u0026#39;); this.lastName = ko.observable(\u0026#39;Smith\u0026#39;); this.fullName = ko.computed(function() { return this.firstName() + \u0026#39; \u0026#39; + this.lastName(); }, this); The differences here are trivial. Ember doesn\u0026rsquo;t need you to tell it what properties to observe (all properties added to your models are observed). Ember uses getters and setters for each property.\nKnockout asks you to state which properties you want to observe. Knockout then uses a named observable function instead of getters and setter.\nRead/write computed properties Ember firstName: null, lastName: null, fullName: function(key, value) { // setter if (arguments.length \u0026gt; 1) { var nameParts = value.split(/\\s+/); this.set(\u0026#39;firstName\u0026#39;, nameParts[0]); this.set(\u0026#39;lastName\u0026#39;, nameParts[1]); } // getter return this.get(\u0026#39;firstName\u0026#39;) + \u0026#39; \u0026#39; + this.get(\u0026#39;lastName\u0026#39;); }.property(\u0026#39;firstName\u0026#39;, \u0026#39;lastName\u0026#39;) Knockout this.firstName = ko.observable(\u0026#39;Planet\u0026#39;); this.lastName = ko.observable(\u0026#39;Earth\u0026#39;); this.fullName = ko.computed({ read: function () { return this.firstName() + \u0026#34; \u0026#34; + this.lastName(); }, write: function (value) { var lastSpacePos = value.lastIndexOf(\u0026#34; \u0026#34;); if (lastSpacePos \u0026gt; 0) { // Ignore values with no space character this.firstName(value.substring(0, lastSpacePos)); // Update \u0026#34;firstName\u0026#34; this.lastName(value.substring(lastSpacePos + 1)); // Update \u0026#34;lastName\u0026#34; } }, owner: this }); I think this scenario shows where Knockout really shine. I find the Knockout code easily readable. The fact that the Ember code needs comments to explain what part of the code is the setter vs getter is damning.\nAlso, the fact that the Ember code has to explicitly call out what properties it is watching is frustrating as well.\nForcing a Property to Recompute Every Time its Called Knockout myViewModel.fullName = ko.computed(function() { return myViewModel.firstName() + \u0026#34; \u0026#34; + myViewModel.lastName(); }).extend({ notify: \u0026#39;always\u0026#39; }); Ember fullName: function() { return this.get(\u0026#39;firstName\u0026#39;) + \u0026#39; \u0026#39; + this.get(\u0026#39;lastName\u0026#39;); }.property(\u0026#39;firstName\u0026#39;, \u0026#39;lastName\u0026#39;).volatile() I think Ember gets the node here for the chainable extension method. Knockout\u0026rsquo;s choice of passing in a extended configuration, while readable, seems a bit clunky to me.\nConclusion The biggest difference I see in the two frameworks in regards to Observable Models is the need of Ember to register property dependencies. This seems like a huge drawback to me - what if you change your code and forget to update the dependencies? Or what if you have a typo in writing in the dependencies?\nSince Knockout existed before Ember, it makes me wonder why the Ember creators didn\u0026rsquo;t incorporate Knockout into their framework.\nSolving a problem again after it\u0026rsquo;s been solved by someone else reminds me of this famous XKCD cartoon:\n##Side Note - How does Knockout get away without explicitly defining dependencies?\nKnockout\u0026rsquo;s Algorithm for Dependency Tracking It’s actually very simple and rather lovely. The tracking algorithm goes like this:\nWhenever you declare a computed observable, KO immediately invokes its evaluator function to get its initial value. While your evaluator function is running, KO keeps a log of any observables (or computed observables) that your evaluator reads the value of. When your evaluator finishes, KO sets up subscriptions to each of the observables (or computed observables) that you\u0026rsquo;ve touched. The subscription callback is set to cause your evaluator to run again, looping the whole process back to step 1 (disposing of any old subscriptions that no longer apply). KO notifies any subscribers about the new value of your computed observable. ",
    "ref": "/blog/20140320-ember-vs-knockout-property-comparison/"
  },{
    "title": "New Blog!",
    "date": "",
    "description": "New Blog!",
    "body": "I\u0026rsquo;ve just ended a very long relationship that was hideously overdue for some closure. That\u0026rsquo;s right - I\u0026rsquo;ve left wordpress.\nIt\u0026rsquo;s a great platform if you can\u0026rsquo;t make a website or just don\u0026rsquo;t care about the details. But it\u0026rsquo;s a little less than I was looking for.\nSo I\u0026rsquo;ve decided to get minorly techy and build a nice static site to hold all my blog entries. A thousand thanks goes to @dreikanter for writing a simple converter of the wordpress XML format to markdown.\nThis site is so cool! It\u0026rsquo;s powered by a heap of great tech:\nDocpad to serve my posts CoffeeScript whenever I need to write code Twitter Bootstrap for easy styling and reactive handling Markdown for easy blog writing Eco for cool templating Less and Stylus for my css The only thing I couldn\u0026rsquo;t take with me - all the old comments. I\u0026rsquo;ve tried to go back and edit the old entries where the comments where useful.\n",
    "ref": "/blog/20140112-new-blog/"
  },{
    "title": "A/B Testing and Random Selection",
    "date": "",
    "description": "A/B Testing or Random Selection in the browser and on the server",
    "body": "Are you looking for an A/B framework? Something you can use in the browser to toggle a user experience - do they see marketing promotion #1, or a picture of a cat?\nOr are you interested in random selection - you want to send our 5000 emails of differing types, and see how users respond?\nEither way, enter laboratory. A simple framework that allows random selection or A/B testing. With the added bonus of being usable anywhere you can load JavaScript.\nAn example for random selection:\nlaboratory = new Laboratory() laboratory.addExperiment(\u0026#34;FuzzyBunnies\u0026#34;) .variant \u0026#34;variant0\u0026#34;, 50, name: \u0026#34;Peter Rabbit\u0026#34; type: \u0026#34;Wooly\u0026#34; .variant \u0026#34;variant1\u0026#34;, 50, subject: \u0026#34;Briar Rabbit\u0026#34; type: \u0026#34;Silky\u0026#34; experiment = laboratory.run(\u0026#34;FuzzyBunnies\u0026#34;) experiment.value # Either Peter or Briar Rabbit In this example, the user would get either Peter or Briar. If you ran the experiment again you\u0026rsquo;d get another set of random values irregardless of the user.\nTo use the A/B features you need to provide laboratory with some kind of storage mechanism to store the selected options for the user. On the client side, we usually use a thin wrapper over localStore.\nYour storage needs to implement two methods:\nclass Store # stores the experiment results (as the variant name selected) for this user addResult: (experimentName, variantName) -\u0026gt; {} # retrieves a variant result if the user has already seen this experiment get: (experimentName) -\u0026gt; {} If you want to give the user the same experiment every time they come to your site simply pass in your storage to the laboratory when you declare it.\nlaboratory = new Laboratory(new Store()) ",
    "ref": "/blog/20131211-a-b-testing-and-random-selection/"
  },{
    "title": "Instrumenting Backbone for better error handling",
    "date": "",
    "description": "Instrumenting Backbone for better error handling",
    "body": "At work we\u0026rsquo;ve been having some issues tracking down some nasty client side bugs. We know they\u0026rsquo;re happening in our Backbone views, but we\u0026rsquo;ve been unable to locate them with any accuracy due to the errors bubbling all the way to the window.onerror handler.\nEnter Stackbone. A simple bit of code to instrument Backbone’s event loops to better locate client side errors.\nTo use:\nStackbone.start({ Backbone: Backbone jQuery: jQuery onError: function (err) { // ... log the error ... } }); You can either Stackbone = require(‘stackbone’) or simply include the .js file in a script tag.\nEnjoy!\n",
    "ref": "/blog/20131127-instrumenting-backbone-for-better-error-handling/"
  },{
    "title": "Source maps in node.js",
    "date": "",
    "description": "Source maps in node.js",
    "body": "One of the projects I\u0026rsquo;m working on deals with source maps.\nIf you don\u0026rsquo;t know anything about source maps this link is a good introduction to what source maps are and why they\u0026rsquo;re useful.\nLooking at the article date (March 21st, 2012), it\u0026rsquo;s not like source maps are some new hot thing. But the tooling around them is still pretty raw as is their use.\nSo why would you want to use source maps?\nSource maps are great for client side development. You can minify/mangle your code, use it in dev, and still debug. Faster dev environments while still being able to debug. Source maps can give you decent stack traces in your production environment without hurting your site\u0026rsquo;s performance. And without exposing any of your unminified source code to the end user. Read that last point again. This is the killer feature we were looking for at work - being able to track down client side errors reliably on production.\nTo do this you have to jump through a few hoops. At least in a node.js environment.\nThe three ways to use source maps There are three ways you can include source maps in your project.\nYou can imbed the source map directly in a .js file. You can add a comment to the .js to that points to the appropraite source map. You can set a header in the response for the .js file that points the browser to a source map. If you use Browserify you can turn on option 1 just by setting debug: true in your configuration. You\u0026rsquo;ll probably notice the performance degradation almost immediately. That\u0026rsquo;s because browserify includes your source map (with includes all your source) along with the combined .js you\u0026rsquo;re given it. Which is a pretty huge payload compared to just .js.\nMaking source maps work in development If you strip out that source map from the .js file and move the code to an external .map file you still have the ability to debug your browserify-ied code without hurting your performance.\nBrowsers only download external source maps (source maps included via option 2 or 3) when they are needed. So even in development your app will load quickly if you have external source maps. Once you open your debugger in the browser then you\u0026rsquo;ll go and download the source maps you need to debug the current page.\nMaking source maps work in production However, the source maps you generate for development aren\u0026rsquo;t appropriate for production. Why? Two reasons.\nAll of your source code is available for download from the source map. The .js browserify generates in debug mode is unminified. Even if you want to use source maps in production you wouldn\u0026rsquo;t want to push unminified code up. You also don\u0026rsquo;t want to expose your source code to the public. Luckily there is a solution: UglifyJS.\nSo Uglify (or more correctly Uglify 2) can take your unminified code and minify for you. If given a source map as input it can rewrite the source map to now point at the minified file. Pretty good.\nThat would still leave us with the problem with the embedded source code in your source map. Except for one thing - they\u0026rsquo;re a bug in Uglify. It strips out the embedded source code when it does it second run on your source map to get it match to the newly minified code.\nWhich means an uglified, external source map can be pushed to production. You won\u0026rsquo;t be able to debug production - you won\u0026rsquo;t have any source to look at - but an error that occurs will at least give you a decent stack trace.\n",
    "ref": "/blog/20131019-source-maps-in-node-js/"
  },{
    "title": "My ongoing relation with CoffeeScript - and a gotcha",
    "date": "",
    "description": "",
    "body": "CoffeeScript, what can I tell ya - I didn\u0026rsquo;t want to love it.\nI have an unreasonable grudge against significant whitespace.\nI couldn\u0026rsquo;t figure out the value of a language that compiles to another reasonable language.\nAnd don\u0026rsquo;t even get me started on the for of/in thing. I still don\u0026rsquo;t understand that.\nBut the more I use CoffeeScript, the more I love it.\nThe lambdas are probably my biggest love - how can you not love them, in comparison to what JavaScript makes you do?\nHowever, I found something out the other day that seems slightly counter-intuitive to me.\nsupposedToBeArray = null if foo in supposedToBeArray # You will never reach this code, because the line above throws an exception. I guess my thought would be if foo in supposedToBeArray would return false. But nope, throws when the object is not an array (or is not array-like).\n",
    "ref": "/blog/20130502-coffeescript-gotcha/"
  },{
    "title": "Docco Fork - All JS, all the time",
    "date": "",
    "description": "",
    "body": " EDIT: My fork is no longer needed. The folks at docco saw the same thing and recently ported over the library to use highlight.js.\nI love documentation generators for code. You know what I\u0026rsquo;ve talking about to - something which gives you a split screen of the code and the comments, side by side, for easy reading and scrolling. Like jasmine uses for their documentation:\nSince I\u0026rsquo;ve mostly been working in JavaScript lately I\u0026rsquo;ve been looking for something to help document the packages I create easily. In comes docco.\nA CoffeeScript + Python library to help generate good-looking documentation from comments in your code. One thing bothered me about this project - the python part. Docco uses a python library to highlight the syntax. There are plenty of decent syntax highlighters out there - why not use one written in a JavaScript flavor? So I forked docco and plugged in a JS highlighter. Pretty happy with the results.\nYou can check out the fork here.\n",
    "ref": "/blog/20130303-docco-fork-all-js-all-the-time/"
  },{
    "title": "Esvalidate Library - Standalone Validation Library Using Esprima",
    "date": "",
    "description": "",
    "body": "I spent a good bit of time working on the Esvalidate code that comes with Esprima, trying to get it to work smoothly with my sublime plugin. After submitting a massive pull request to the author of Esprima and our reviewing my code we came to a conclusion - the new code was better served in its own library.\nIt\u0026rsquo;s still in its early stages but please check out the progress I\u0026rsquo;m making here: Esvalidate Library\n",
    "ref": "/blog/20130215-esvalidate-library-standalone-validation-library-using-esprima/"
  },{
    "title": ".Net Gotcha - Private Classes With Access To Containing Classes's Protected Variables (Or Not)",
    "date": "",
    "description": "",
    "body": "A friend and I were working on some code together when we found an interesting edge case in .Net that neither of us knew about. This is what we knew: if you have a class with a protected field in it, if you declare a private class inside of that class, the private class can access the protected variable. The example below shows what this looks like.\npublic class ParentClassWithProtectedField { protected readonly int protectedField; private class PrivateClassInParentClass { public void Method(ParentClassWithProtectedField parent) { Console.WriteLine(parent.protectedField); //Me Work Good! } } } And this is what we learned: If you create a child class that inherits from the parent class, and declare another Private class in the child class, you cannot access the parent\u0026rsquo;s protected field from the private class in the child class. I know that was a ton of Parent/Child/Private classes in a short sentence, so here\u0026rsquo;s an example, building on the previous one, of what won\u0026rsquo;t work in .NET.\npublic class ChildClassOfParentClass : ParentClassWithProtectedField { private class PrivateClassInChildClass { public void Method(ParentClassWithProtectedField parent) { Console.WriteLine(parent.protectedField); // NO WORK! } } } ",
    "ref": "/blog/20130115-net-gotcha-private-classes-with-access-to-containing-classess-protected-variables-or-not/"
  },{
    "title": "Portfolio Spotlight on Pathbrite = Cool?",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;ve recently created a portfolio on Pathbrite. If you haven\u0026rsquo;t heard of Pathbrite, they are a company aiming to:\nCollect, organize and share a lifetime of learning and achievement.\nI think this section of their mission statement sums up how they are relevant to working professionals.\n\u0026hellip; employers rely on our Pathbrite Portfolio Platform to get a holistic view of candidates, and to better evaluate their readiness for and organizational fit to the opportunity at hand.\nHow does it work? The sites allows you to import data (from LinkedIn and other sites) as well as other documents (such as images and PDFs) and lay them out in whatever manner you see fit. It can also import websites you\u0026rsquo;ve written as well. It\u0026rsquo;s a great tool for a web software developer to showcase what they\u0026rsquo;re about. The link to the article: http://www.pathbrite.com/2012/12/03/portfolio-spotlight-julie-marciel-rozzi-matt-blair/\n",
    "ref": "/blog/20121204-portfolio-spotlight-on-pathbrite-cool/"
  },{
    "title": "Esprima Plugin for Sublime Text",
    "date": "",
    "description": "",
    "body": "In relation to my previous posts confessing my love for sublime, and my enjoyment of Esprima, here is some code that showcases both: An Esprima plugin for Sublime Test!\nhttp://github.com/duereg/sublime-jsvalidate\nThis has been included in the official list of Sublime Plugins. So you can install this from Sublime using Packages Control.\n",
    "ref": "/blog/20121201-esprima-plugin-for-sublime-text/"
  },{
    "title": "Added JavaScript syntax checking via Esprima and a Git pre-commit hook",
    "date": "",
    "description": "",
    "body": "I came across a brilliant project the other day - Esprima from Ariya Hidayat, the author of PhantomJS. What is Esprima? Esprima is a JavaScript Parser written in JavaScript Syntax Validator. It forms the basis of several different tools - a minifier, a code coverage tool, a syntax validator - just to name a few. I was immediately interested in the syntax validation tool. It\u0026rsquo;s not a linter - it just checks that the JavaScript written is syntactically correct. Why would you want this if you already have JsHint and JsLint?\nIt is extremely fast. Validating three.js (800 KB source) takes less than a second on a modern machine. It looks only for syntax errors, it does not care about coding style at all. It handles generated files as the result of minification or compilation (CoffeeScript, Dart, TypeScript, etc). It tries to be tolerant and not give up immediately on the first error, especially for strict mode violations. Esprima is available as an npm package, so installing it only takes a second: sudo npm install -g esprima Using Esprima from the command line is simple: esvalidate file.js\nThe only thing to note about running from the command line: if the validation succeeds, you won\u0026rsquo;t get much in the way of confirmation. Which can be painful if you are processing a whole directory. You only get useful feedback in the default mode on error. If you don\u0026rsquo;t mind reading a little XML: esvalidate lib/*.js --format=junit\nPrints junit XML which at least you can visually parse to see which files were validated. Where would I use this where I might not use JsHint? As a pre-commit hook to screen my checkins. Instead of going through a check-in, building everything, then running JSHint just to hear that something is not up to spec, I can add a little script that will do a quick sanity check of my JS before I go to commit anything to git.\nIf you\u0026rsquo;ve never created a pre-commit hook before, it\u0026rsquo;s pretty easy. Two lines in bash will give you a pre-commit file: touch .git/hooks/pre-commit chmod +x .git/hooks/pre-commit\nThis is windows version of the code for the pre-commit hook: #!/bin/sh files=$(git diff-index --name-only HEAD | grep -l '\\\\.js$') for file in $files; do esvalidate $file if [ $? -eq 1 ]; then echo \u0026quot;Syntax error: $file\u0026quot; exit 1 fi done\nTo make this work on Linux, just remove the remove the #!/bin/sh line. For more information about Esprima, check out this article by the author.\n",
    "ref": "/blog/20121120-added-javascript-syntax-checking-via-esprima-and-a-git-pre-commit-hook/"
  },{
    "title": ".Net SQL Parsing - Using the TSqlParser library",
    "date": "",
    "description": "",
    "body": "A preface to this post: it is hard to find a free SQL Parser for .NET. There is a company that has a terrible library that they charge $150 bucks for. There are a couple of incomplete implementations done for school projects or for narrowly focused tasks. So if you want a no-strings attached free parser for SQL, you\u0026rsquo;re out of luck. However, since most people who want a .NET parser are writing code on a Windows machine, and use Visual Studio, there is (lightly documented) hope: the TSqlParser library that ships with Visual Studio.\nThis is a fully featured parsing library for SQL Server SQL syntax. I\u0026rsquo;m not sure about the support of other DB\u0026rsquo;s SQL syntax, but I would imagine it\u0026rsquo;s poor. On an x64 Windows machine, using Visual Studio 2010, the dll\u0026rsquo;s which contain the TSqlParser library are located at: C:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\VSTSDB The class TSql100Parser in Microsoft.Data.Schema.ScriptDom.Sql gets you the parser for Sql Server 2008. To instantiate an instance of the TSql100Parser class, you have to supply the constructor with one parameter:\npublic TSql100Parser(bool initialQuotedIdentifiers ) The docs for this are better than trying to figure out what initialQuotedIdentifiers means:\nSpecifies whether quoted identifier handling is on.\nI\u0026rsquo;m guessing this has to do with declaring aliases for columns like this:\nselect bar as \u0026#39;This is the alias for foo.bar\u0026#39; from tblFoo \\--instead of like this: select bar as [This is the alias for foo.bar] from tblFoo Using the parser is relatively simple. Once you reference the correct dll\u0026rsquo;s in your project:\nvar parser = new TSql100Parser(true); var script = parser.Parse(reader, out errors) as TSqlScript; foreach (TSqlBatch batch in script.Batches) { foreach (TSqlStatement statement in batch.Statements) { //At this point, you have a collection of SQL Statements... //that can contain collections of SQL Statements... } } My comment in the code above is to help you understand something about parsing SQL - almost every relationship is expressed as a tree, where something contains more of the same thing, and that thing may contain more of the same thing, or maybe not. Which means the easiest way to navigate the data is recursively. In other words, the Rules for using TSqlParser:\nLEARN TO LOVE THE RECURSION. Refer to the Rules for using TSqlParser I\u0026rsquo;ll give you an example scenario to show you what you\u0026rsquo;re up against. One common scenario is searching your code for SELECT statements. Select statements can be contained in:\nStored Procedures If Statements While Statements BEGIN statements Try/Catch Blocks I\u0026rsquo;m sure I\u0026rsquo;m missing some cases. So it\u0026rsquo;s not as simple as saying \u0026ldquo;give me all the statements that are select statements\u0026rdquo;. Instead, you have to write something like:\nfunction ProcessStatements(statements) foreach(statement in statements) if statement is a Stored Procedure ProcessStatements(statement.MyStatements) if statement is an If Statement ProcessStatements(statement.MyStatements) if statement is a While Statement ProcessStatements(statement.MyStatements) if statement is a Select Statement ProcessSelect( statement) So once you get your select statement (or your collection of select statements), how do you process them? Well unfortunately it\u0026rsquo;s not straightforward. The SelectStatement class contains a field called QueryExpression - this field contains what kind of Select we\u0026rsquo;re dealing with. As far as I can determine, there are three types of QueryExpressions:\nQuerySpecification This is an actual SELECT statement\nBinaryQueryExpression This is a UNION or similar expression between two SELECT statements\nQueryParenthesis This is a SELECT surrounded by parenthesis. In other words, a sub-select\nSo again, if you only want SELECT statements, you have to weed through the three types of QueryExpressions until you get to the underlying SELECT statements. So eventually you\u0026rsquo;ll get to a list of QuerySpecifications (which represent the SELECT statements from your original query). Now here comes the good stuff: you can now weed through the SELECT fields programmatically and get out whatever information you want. Here are some of the fields on QuerySpecification:\n|FromClauses| Gets a list of FROM clauses.| |GroupByClause| Gets or sets a GROUP BY clause.| |HavingClause| Gets or sets a HAVING clause.| |Into| Gets or sets the into table name.| |SelectElements| Gets a list of the selected columns or set variables.| |TopRowFilter| Gets or sets the usage of the top row filter.| |UniqueRowFilter| Gets or sets the unique row filter value.| |WhereClause| Gets or sets a WHERE clause.| Just tons of SELECT goodness. However, be warned: each of these fields contains lists with multiple subclasses. So more recursive diving if you want to get something very specific out of this select data. To get farther you might have to dive into the docs. Link to MSDN Namespace Docs\n",
    "ref": "/blog/20121101-net-sql-parsing-using-the-tsqlparser-library/"
  },{
    "title": "Free Collection of Microsoft E-Books",
    "date": "",
    "description": "",
    "body": "If you\u0026rsquo;re a Microsoft Dev, want to learn a bit more about the following products:\nSharePoint 2010 Sql Server 2012 Visual Studio 2010 Windows 8 Windows Phone 7 Office 365 Office 2010 ASP.NET 4.5 Web Forms ASP.NET MVC 4 Microsoft Dynamics CRM 2011 (God Rest Your Soul) Microsoft has released a bunch of free e-books about these technologies (and more).\nThe links to the e-books:\nMicrosoft Free E-Books - Page 1 Microsoft Free E-Books - Page 2 ",
    "ref": "/blog/20121030-free-collection-of-microsoft-e-books/"
  },{
    "title": "Derby.js - The Ready() Function, and Adding Client-Side Scripts to your App",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;ve found a neat feature of derby dealing with the ready() function. I\u0026rsquo;ve been creating a derby app, and in my application I need to load up a client-side calendar. With a standard HTML web page this is straightforward thing to do. On the page you wanted the calendar, you would include the client js for the calendar, some code to load it, and that would be that. Derby introduced some complexity to this relatively simple task. On my first attempt, I put my scripts in the section of the page that I needed the calendar on. I added a script to load the calendar as well. When I went to the url of the page, it loaded immediately. Success! (I thought).\nThen I clicked a link away from my calendar, and then clicked back. No calendar. What happened? When I loaded the link originally, the page was rendered from the server. The second time, the page was rendered client side. Something wasn\u0026rsquo;t working with loading the calendar on the client-side render. You need a place to put your code that guarantees that it will load on the client-side. The app.ready() function is designed to handle this scenario. What is the purpose of the app.ready() function? From the derby documentation:\nCode that responds to user events and model events should be placed within the app.ready() callback. This provides the model object for the client and makes sure that the code is only executed on the client. This function is called as soon as the Derby app is loaded on the client. Note that any code within this callback is only executed on the client and not on the server.\nI\u0026rsquo;ve bolded the part I think is particularly important. This code is run as soon as the client is loaded. Which means if you have more than a single-page app, using app.ready() to load a feature might not work out. So what to do? An undocumented feature of Derby - app.on(). What does it do? It allows you to load code AFTER a specific page has loaded. Which is exactly what I\u0026rsquo;m looking for. So here\u0026rsquo;s what I ended up writing in my app.ready():\napp.on(\u0026#39;render:calendar\u0026#39;, function(ctx) { logger.log(\u0026#34;rendering calendar client-side...\u0026#34;); new Timeline(\u0026#34;timeline\u0026#34;, new Date()); }); In this example this code will run after rendering the calendar view. On the Calendar page, there is a script block which loads the Timeline function. After writing this code, I tried my page again. Still no luck. I wasn\u0026rsquo;t getting the calendar to load on both the client and server load. On a lark, I moved the block containing my Timeline javascript to my index view, and tried again. Success. Which makes sense. If you are rendering pages via the client side load, additional resources aren\u0026rsquo;t going to be loaded. So by putting my script into the index view, it\u0026rsquo;s unfortunately loaded for all my pages, but at least it\u0026rsquo;s available for both the client and server side rendering of my cool control.\n",
    "ref": "/blog/20121017-derby-js-the-ready-function-and-client-side-scripts/"
  },{
    "title": "Cracking the Coding Interview - The Tower of Hanoi and Poor Editing",
    "date": "",
    "description": "",
    "body": "I just finished the Stack section of Cracking the Coding Interview and came across an old puzzle - The Tower of Hanoi. I struggled with solving this problem. I wrote this elaborate, strange algorithm to try to solve it (which should have been a dead give-away that I had it wrong). Ironically enough, hidden in the 20-30 lines of code I wrote were the three lines of code I needed to solve the problem. Anyways, after beating my head in trying to solve this, I ended up going to the back of the book and looking up the solution. And found this pile of shit psuedocode. I\u0026rsquo;ve shortened the comments, but the content is the same.\nmoveDisks(int n, Tower origin, Tower destination, Tower buffer) { if (n \u0026lt;= 0) return; //Move top n - 1 disks from 1 to 2 moveDisks(n-1, tower 1, tower 2, tower 3); //Move top from 1 to 3 moveTop(tower 1, tower 3); //Move top n - 1 disks from 2 to 3 moveDisks(n-1, tower 2, tower 3, tower 1); } In this tiny amount of code, in over five revisions to her book, the author has managed to miss two errors.\nIn the first line, Variables origin, destination, and buffer are declared, but then tower 1, tower 2, and tower 3 are used. Which is which? In line 5, the comment says \u0026ldquo;Move top n-1 disks\u0026rdquo;. Then, in lines 8-9, the author indicates that you move the top. Since you\u0026rsquo;ve already moved all the items in the stack but one, the bottom element, that line should read \u0026ldquo;move bottom\u0026rdquo;. Maybe these aren\u0026rsquo;t huge issues, but since I was pretty frustrated with this problem, having to correct the solution didn\u0026rsquo;t help my frustration. The correct code:\nmoveDisks(int n, Tower origin, Tower destination, Tower buffer) { if (n \u0026lt;= 0) return; //Move top n - 1 disks from origin to buffer moveDisks(n-1, origin, buffer, destination); //Move nth disk (the bottom disk) from origin to destination moveBottom(origin , destination); //Move top n - 1 disks from buffer to destination moveDisks(n-1, buffer, destination, origin); } I hope this helps somebody else who\u0026rsquo;s working on this problem.\n",
    "ref": "/blog/20120915-cracking-the-coding-interview-the-tower-of-hanoi-and-poor-editing/"
  },{
    "title": "Cracking the Coding Interview - Linked Lists - The Runner Technique",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;ve been going over the Linked List section of Cracking the Coding Interview and most times I get stumped with a problem the solution is the Runner Technique (or slow/fast pointers).\nThe idea behind the runner technique is simple; use two pointers that either move at different speeds or are a set distance apart and iterate through a list.\nWhy is this so useful? In some linked list problems you need to know the position of a certain element or the length of the list. Given that you don\u0026rsquo;t always have the length of the list you are working on, the runner technique is an elegant way to solve these type of problems (and in some cases it is the only solution). Here are some examples of linked list problems where the runner technique provides an optimal solution:\nGiven two lists of different lengths that merge at a point, determine the merge point Determine if a linked list contains a loop Determine if a linked list is a palindrome Determine the kth element of a linked list Where do you use it? If you get handed a linked list question, and you find yourself asking these questions:\nHow do I figure out where these two things meet? How do I figure out the midpoint? How do I figure out the length? You\u0026rsquo;re likely dealing with a problem where you need to use the runner technique.\nHow does it work? I\u0026rsquo;ll illustrate one of the examples above. Given two lists of different lengths that merge at a point, determine the merge point\nStart a node at the beginning of each list on the left. Count how many nodes each pointer encounters. (The top list should be 5, the bottom list 4.) The difference between the two numbers is the difference in length of the two lists before the merge point (the difference is 1) Move your nodes to the beginning of each list, but the longer list should get a headstart equal to the amount of difference. (so the top list would start on its 2nd element, while the bottom list would start on its 1st). Move each node forward at the same speed until they meet. Where they meet is the collision point. Each of the links above contains code and solutions to each of the problems. I hope this example and the ones above show the usefulness of this approach. There are also some examples located here of linked list algorithms problems and solutions written in JavaScript.\n",
    "ref": "/blog/20120913-cracking-the-coding-interview-linked-list-the-runner-technique/"
  },{
    "title": "How to install Sublime Text 2 on Ubuntu 12.04 (Unity)",
    "date": "",
    "description": "",
    "body": "Sublime Text has rapidly become my favorite text editor. Cross platform, easy to use, great feature set. The Command Palette feature, where you can search for a feature without having to know where it is in the application, is an piece of usability brilliance. Somebody cobbled together a great step-by-step set of directions on how to install sublime on ubuntu. I wanted to give a shout-out to them and their work.\nHow to install Sublime Text 2 on Ubuntu 12.04 (Unity) | Technoreply.\n",
    "ref": "/blog/20120911-how-to-install-sublime-text-2-on-ubuntu-12-04-unity/"
  },{
    "title": "Setting up MongoDB to work with Derby.js",
    "date": "",
    "description": "",
    "body": "This post is going to cover installing and configuring MongoDB to use with Derby. If you\u0026rsquo;re reading this post looking to add model persistence to your Derby application but don\u0026rsquo;t know much about MongoDB, understanding MongoDB will help you understand Derby and the model system it uses.\nWhat\u0026rsquo;s MongoDB? From their website:\nMongoDB (from \u0026ldquo;humongous\u0026rdquo;) is a scalable, high-performance, open source NoSQL database.\nIf you\u0026rsquo;ve never used MongoDB before, you should immediately go here. This is the easiest, fastest way to learn the basics of what mongo is and how it works. And it only takes about fifteen minutes. It\u0026rsquo;s even interactive to keep you from getting bored. Go give it a play.\nDerby and MongoDB Now that you have an idea about how MongoDB works, many of the conventions Derby uses for models should make sense. If you scan through the Derby Query Readme now, hopefully is makes a bit more sense (like where the term \u0026ldquo;gte\u0026rdquo; came from).\nInstalling MongoDB If you still need to install MongoDB go here for downloads and installation directions.\nConfiguring Derby to use MongoDB Now that you know about MongoDB, let\u0026rsquo;s get MongoDB set up to work with Derby. This is straightforward and takes about two minutes. To add MongoDB to your Derby application, you\u0026rsquo;ll need to include the racer-db-mongo package in your project. Update your package.json file to look something like this:\n{ \u0026#34;name\u0026#34;: \u0026#34;potluck\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;./server.js\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;derby\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;derby-ui-boot\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;express\u0026#34;: \u0026#34;3.0.0beta4\u0026#34;, \u0026#34;gzippo\u0026#34;: \u0026#34;\u0026gt;=0.1.7\u0026#34;, \u0026#34;racer-db-mongo\u0026#34;: \u0026#34;*\u0026#34; //this is the line. Glory in its beauty. }, \u0026#34;private\u0026#34;: true } Then, at the command prompt, update your project (and download the recently added racer-db-mongo dependency) using the following command:\nnpm update You\u0026rsquo;ll have to update your server configuration (by default in /lib/server/index.js) to use the new dependency. This requires TWO new lines of code\nderby.use(require(\u0026#39;racer-db-mongo\u0026#39;)); // This line is new app.createStore({ listen: server , db: {type: \u0026#39;Mongo\u0026#39;, uri: \u0026#39;mongodb://localhost/database\u0026#39;} /* This line is new */ }); That\u0026rsquo;s all the changes you need to make to add MongoDB to your project. So why I\u0026rsquo;d bother with a blog post?\nWhat About Troubleshooting? Now, if you go and start your Derby application, you might see the following error:\nError: failed to connect to [localhost:27017] Which means:\nYou\u0026rsquo;ve installed the racer-db-mongo dependency correctly! You now need to: * Install MongoDB * Turn on MongoDB * OR Fix MongoDB If you\u0026rsquo;ve forgotten to install Mongo, if you look around, you\u0026rsquo;ll probably find a link somewhere which will help you out. Starting/Stopping/Statusing MongoDB If you\u0026rsquo;ve installed Mongo, you have to start the service before Derby can use it. On Ubuntu, you start Mongo using the following command:\nsudo start mongodb Remember to stop Mongo later with:\nsudo stop mongodb If you\u0026rsquo;ve started Mongo, then loaded your Derby application, and you\u0026rsquo;re still getting an error, it\u0026rsquo;s possible that Mongo did not start correctly. Typing:\nsudo status mongodb will let you know if Mongo is running or not. If you\u0026rsquo;ve run the Mongo Start command, yet the status command is telling you that Mongo is stopped, the most likely cause is Mongo did not shut down gracefully last time it was run. You\u0026rsquo;ll have to go and repair your installation (luckily, this is pretty easy).\nRepairing MongoDB To repair your installation, run the following commands:\n$ sudo rm /var/lib/mongodb/mongod.lock $ sudo -u mongodb mongod -f /etc/mongodb.conf --repair The code above was taken from this great article At this point, you should have a working copy on MongoDB along with a working integration with Derby. Congrats!\nMongoDB is working great - now Derby hates me If your application loads, but you\u0026rsquo;re getting a strange error whenever you add to a collection that looks something like this:\nError: No persistence handler for push(FIRST_WORD.SECOND_WORD, [object Object], 18) It means that you are pushing to the wrong portion on an model path. You can only use push to arrays, and arrays are not objects, and you can only use objects for the first and second words of your model path. In the case shown above, a push is attempting to be made to\nFIRST_WORD.SECOND_WORD which equates to\nFIRST_WORD.SECOND_WORD.push(object) which means SECOND_WORD is an array (which isn\u0026rsquo;t allowed). If this last bit of explanation might have well been in Latin, check out this post. It\u0026rsquo;ll explain a little bit about how to declare models and what Derby is expecting you to do. Unfortunately, you CAN use the second word of a model path as an array without persistence support. So this kind of bug will only surface once you\u0026rsquo;ve got MongoDB integrated with Derby.\n",
    "ref": "/blog/20120906-setting-up-mongodb-to-work-with-derby-js/"
  },{
    "title": "Javascript Strings - Using Array Accessor '[]' to set characters",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;ve been learning quite a bit about JavaScript in writing algorithms from Cracking the Coding Interview. I learned something new about strings in JavaScript and how they can be accessed. From MDN:\nCharacter access There are two ways to access an individual character in a string. The first is the charAt method:\nreturn \u0026#39;cat\u0026#39;.charAt(1); // returns \u0026#34;a\u0026#34; The other way is to treat the string as an array-like object, where individual characters correspond to a numerical index:\nreturn \u0026#39;cat\u0026#39;[1]; // returns \u0026#34;a\u0026#34; Array-like character access (the second way above) is not part of ECMAScript 3. It is a JavaScript and ECMAScript 5 feature. For character access using bracket notation, attempting to delete or assign a value to these properties will not succeed. The properties involved are neither writable nor configurable.\nI highlighted the important part. I know that strings are immutable in JavaScript, but why give me array access if you won\u0026rsquo;t let me use it? So if you want to use the array accessor with a string, there is a way to do it, but it requires a bit of overhead.\nvar sentence = \u0026#34;this is a proper JavaScript string.\u0026#34;; sentence = sentence.split(\u0026#34;\u0026#34;); //split into array sentence[18] = \u0026#39;j\u0026#39;; //changing values to lowercase sentence[22] = \u0026#39;s\u0026#39;; sentence = sentence.join(\u0026#34;\u0026#34;); //make the array a string again ",
    "ref": "/blog/20120905-javascript-strings-using-array-accessor-to-set-characters/"
  },{
    "title": "Cracking the Coding Interview - JavaScript Trie",
    "date": "",
    "description": "",
    "body": "I finished my third algorithm from Cracking the Coding Interview - the Trie.\nTries are a useful algorithm, if not all that well known. They can be used for efficient spell checking, auto suggestion, as well as the sorting of a collection of strings.\nThis algorithm was more complex to implement than the Linked List, but a little simpler than the Max/Min Binary Heap to implement.\nThe trie\u0026rsquo;s structure is easy to understand - it\u0026rsquo;s a word tree, where each leaf of the tree is a letter of a word. Where words share common prefixes (such as fresh and freedom), those words share a common \u0026ldquo;branch\u0026rdquo; of prefix letters, and split where the words differ.\n(This image is from Wikipedia) The insert and hasWord operations are easy to implement. Complicating the removal of words operation is the shared nature of the word prefixes.\nInsert goes something like this: For each letter in the word:\nif the letter exists on the tree, go to the letter. If it does not exist, create it. If there is another letter, return to the previous step. If not, add a word terminating marker. Here is my implementation of insert:\nvar trie = function() { this.head = {}; }; trie.prototype.validate = function(word) { if((word === undefined) || (word === null)) throw \u0026#34;The given word is invalid.\u0026#34;; if (typeof word !== \u0026#34;string\u0026#34;) throw \u0026#34;The given word is not a string\u0026#34;; } trie.prototype.add = function(word) { this.validate(word); var current = this.head; for (var i = 0; i \u0026lt; word.length; i++) { if(!(word[i] in current)) { current[word[i]] = {}; } current = current[word[i]] }; current.$ = 1; //word end marker }; The hasWord algorithm is like the insert algorithm. For each letter in the word:\nif the letter exists on the tree, go to the letter. If it does not exist, the word does not exist. If there is another letter, return to the previous step. If not, check for the word terminating marker. trie.prototype.hasWord = function(word) { this.validate(word); var current = this.head; for (var i = 0; i \u0026lt; word.length; i++) { if(!(word[i] in current)) { return false; } current = current[word[i]] }; return current.$ === 1; //word end marker }; Delete isn\u0026rsquo;t much more complicated, though the recursive nature of the algorithm does make it a bit of a pain. You have to go to the end of the word, and if no other letters are hanging off your word, delete from the end towards the head. As soon as you find a shared element, you stop the deletion.\ntrie.prototype.remove = function(word) { this.validate(word); canDelete(word, -1, this.head); function canDelete(word, index, node){ if(word === undefined ) throw \u0026#34;Bad Word\u0026#34;; if(index \u0026gt;= word.length) throw \u0026#34;Bad index to check for deletion.\u0026#34;; if(node === undefined ) throw \u0026#34;Bad Node at \u0026#34; + index + \u0026#34; for \u0026#34; + word; if(index === word.length - 1) { //last letter //always delete word marker (as we are deleting word) return (delete node.$) \u0026amp;\u0026amp; noKids(node); //if last letter of word, should be empty. } else { //any other letter in word //check child, and after child check, I am now empty if(canDelete(word, index + 1, node[word[index + 1]]) ) { //delete me return (delete node[word[index + 1]]) \u0026amp;\u0026amp; noKids(node); } } return false; }; function noKids(node) { return Object.keys(node).length === 0; }; }; My favorite advantage of using a trie is the ease in generating a sorted list of words. All you have to do is output all the letters by Pre-Order Traversal. And sorting using a trie is fast - the worst case sorting is O(kn), where k is the length of the longest word in the trie.\ntrie.prototype.sort = function() { var word = \u0026#34;\u0026#34;; var sorted = []; sortTrie(this.head, word, sorted); function sortTrie(node, word, sorted) { for(var letter in node) { if (letter == \u0026#39;$\u0026#39;) { sorted.push(word); } else { sortTrie(node[letter], word + letter, sorted); } } } console.log(sorted); return sorted; }; The source code for the project and the tests are here.\n",
    "ref": "/blog/20120901-cracking-the-coding-interview-javascript-trie/"
  },{
    "title": "Cracking the Coding Interview - JavaScript Min/Max Binary Heap",
    "date": "",
    "description": "",
    "body": "I finished my second algorithm from Cracking the Coding Interview - the Binary Heap. This algorithm racketed up the complexity from the Linked List.\nThe heap\u0026rsquo;s structure is easy to understand - it\u0026rsquo;s a binary tree (a tree where each node can have at most two children). In the case of a max heap, the parents have a greater value than their children. The values in a Max Heap decrease as you move down the tree from the parent to children.\n(This image is from Wikipedia) The complexity comes from the behavior. Though the algorithms are easy to understand, there is enough going on in each one that it\u0026rsquo;s easy to sneak in bugs. It took me a bit of time to get each of my implementations the way I wanted it. The insert operation is the easiest to implement. The algorithm is also straight forward.\nAdd the element to the bottom of the heap. Compare the added element with its parent; if they are in the correct order, stop. If not, swap the element with its parent and return to the previous step. Here is part of my implementation of insert:\nbinaryHeap.prototype.add = function(data) { if (data === undefined) { throw \u0026#34;data must be valid to add\u0026#34;; } this.array.push(data); this.bubbleUp(this.array.length - 1, data); }; binaryHeap.prototype.bubbleUp = function(childIndex, childData) { if(childIndex \u0026gt; 0) { var parentIndex = this.getParentIndex(childIndex); var parentData = this.array[parentIndex]; if (this.shouldSwap(childData, parentData)) { this.array[parentIndex] = childData; this.array[childIndex] = parentData; this.bubbleUp(parentIndex, childData); } } }; binaryHeap.prototype.getParentIndex = function (childIndex) { return Math.floor((childIndex - 1) / 2); }; Delete is more complicated though the algorithm reads about the same. To delete the top of a heap:\nReplace the root of the heap with the last element on the last level. Compare the new root with its children; if they are in the correct order, stop. If not, swap the element with one of its children and return to the previous step. * Swap with its smaller child in a min-heap and its larger child in a max-heap. binaryHeap.prototype.removeHead = function() { var headNode = this.array[0]; var tailNode = this.array.pop(); this.array[0] = tailNode; this.bubbleDown(0, tailNode); return headNode; }; binaryHeap.prototype.bubbleDown = function(parentIndex, parentData) { if(parentIndex \u0026lt; this.array.length) { var targetIndex = parentIndex; var targetData = parentData; var leftChildIndex = this.getLeftChild(parentIndex); var rightChildIndex = this.getRightChild(parentIndex); if(leftChildIndex \u0026lt; this.array.length) { var leftChildData = this.array[leftChildIndex]; if (this.shouldSwap( leftChildData, targetData )) { targetIndex = leftChildIndex; targetData = leftChildData; } } if(rightChildIndex \u0026lt; this.array.length) { var rightChildData = this.array[rightChildIndex]; if(this.shouldSwap(rightChildData, targetData )) { targetIndex = rightChildIndex; targetData = rightChildData; } } if(targetIndex !== parentIndex) { this.array[parentIndex] = targetData; this.array[targetIndex] = parentData; this.bubbleDown(targetIndex, parentData); } } }; binaryHeap.prototype.getLeftChild = function (parentIndex) { return parentIndex * 2 + 1; }; binaryHeap.prototype.getRightChild = function (parentIndex){ return parentIndex * 2 + 2; }; There is more code needed to delete the top element and reshuffle the list into the correct order. With all the extra comparisons there are many places where bugs can sneak into the code. The source code for the project and the tests are here.\n",
    "ref": "/blog/20120829-cracking-the-coding-interview-javascript-minmax-binary-heap/"
  },{
    "title": "Derby.js - Starting out with Components; Creating a Twitter Bootstrap Input Component",
    "date": "",
    "description": "",
    "body": "In working with Twitter Bootstrap Forms, one of my favorite ways to lay out a form is using the Horizontal form layout. The layout requires a bit of css/html to get each of the form elements (the text boxes and what not) to play nicely. To add form elements to the horizontal form layout, you need the following html structure for each field:\n\u0026lt;div class=\u0026#34;control-group\u0026#34;\u0026gt;\u0026lt;!-- additional classes here to change state --\u0026gt; \u0026lt;label class=\u0026#34;control-label\u0026#34;\u0026gt;INPUT_LABEL_TEXT_HERE\u0026lt;/label\u0026gt; \u0026lt;div class=\u0026#34;controls\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; /\u0026gt; \u0026lt;!-- This is the control you want to display --\u0026gt; \u0026lt;span class=\u0026#34;help-inline\u0026#34;\u0026gt;ERROR_OR_INFORMATIONAL_MESSAGE_HERE\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; That\u0026rsquo;s a hefty amount of markup to copy and paste all over your pristine views. Which makes this a great place to use a Component.\nSo what\u0026rsquo;s a Component? A component is basically a derby template you can supply parameters to. Those parameters are supplied in the form of HTML attributes and HTML content.\nThere are two types of components: application and library. Application components can only be used in a single project. Library components can be re-used across multiple projects.\nFor my project I\u0026rsquo;m going to create an application component. Eventually if I need the component on another project I\u0026rsquo;ll add it to a component library. But that process is more complicated and less documented so I\u0026rsquo;ll save that for another day.\nThere are two ways to create an application component:\nInline If your component is only being used on a single view, you can add it to the same file as your view.\nExternal If your component is going to be used on multiple views, you should create a separate file for your component. Apparently there are two ways to create a library component as well:\nThe ui directory contains a component library, which can be used to create custom components for the containing project. These are re-usable templates, scripts, and styles that can be used to create custom HTML tags for use in applications. General purpose component libraries can be created as separate npm modules.\nAll components run under the scope of the context in which they are called. Which means you can bind model data to your component without having to pass your component any values. For example:\n\u0026lt;h2\u0026gt;All toys:\u0026lt;/h2\u0026gt; {each toys as :toy} \u0026lt;!-- Alias :toy available to the component --\u0026gt; \u0026lt;app:toyStatus\u0026gt; \u0026lt;!-- All application components live in the app namespace --\u0026gt; {/} \u0026lt;toyStatus:\u0026gt; \u0026lt;!-- this tag says I am a component --\u0026gt; \u0026lt;!-- I\u0026#39;m using alias :toy here, defined above --\u0026gt; \u0026lt;span\u0026gt;The toy is located at {:toy.location}\u0026lt;/span\u0026gt; If all of this \u0026ldquo;Model-Bindy\u0026rdquo; stuff is foreign to you, check out my post Working with Views, Models, and Bindings.\nI don\u0026rsquo;t like the way you used a scoped alias from your view in your component. What if my component is in another file? What if I want to use a field with a different name? Is there a better way to pass values to a component? From the derby documentation:\nLiteral values or variable values can be passed to components. These component attributes are available through “macro” template tags, which have triple curly braces.\nWhat does that look like? Again, from the docs:\n\u0026lt;Body:\u0026gt; \u0026lt;h1\u0026gt; \u0026lt;app:greeting message=\u0026#34;Hello\u0026#34;\u0026gt; \u0026lt;/h1\u0026gt; \u0026lt;greeting:\u0026gt; I was passed this message as an attribute: {{{message}}} You can also pass html to your component as well. That is a two-part trick: First, write your component with an opening and closing tag. Put the value you want to pass to your component between the tags. Then, in your component, you use the special triple-curly bracket {{{content}}} macro-tag to reference what you passed in. For example:\n\u0026lt;Body:\u0026gt; \u0026lt;app:fancyButton\u0026gt; \u0026lt;b\u0026gt;Click me now!\u0026lt;/b\u0026gt; \u0026lt;/app:fancyButton\u0026gt; \u0026lt;fancyButton: nonvoid\u0026gt; \u0026lt;button class=\u0026#34;fancy\u0026#34;\u0026gt; {{{content}}} \u0026lt;/button\u0026gt; But I already knew all that. How do I make a component? The easiest way is to just add the component to your page, as show in the simple example above. This example is taken from the derby website, and it shows you how to reference a component in a separate file:\nshared.html (This is your component, which is located in your views folder.) \u0026lt;profile:\u0026gt; \u0026lt;div class=\u0026#34;profile\u0026#34;\u0026gt;...\u0026lt;/div\u0026gt; home.html (This is the view that will use your component.) \u0026lt;!-- This line imports your component into the view --\u0026gt; \u0026lt;import: src=\u0026#34;shared\u0026#34;\u0026gt; \u0026lt;Body:\u0026gt; Welcome to the home page \u0026lt;!-- include component from an imported namespace --\u0026gt; \u0026lt;app:shared:profile\u0026gt; The tag at the top, used to include your component into your view, can be called with variety of parameters. For more information on the \u0026lt;import\u0026gt; tag go to http://derbyjs.com/#importing_templates.\nDidn\u0026rsquo;t you say something about Twitter Bootstrap? Oh yeah. Got sidetracked there. As you can see, creating a component is relatively easy. Since I already have all the Twitter Bootstrap markup ready, I might as well create a Twitter Bootstrap Component for Derby. To do this, all you have to do is figure out what you want to be able to customize.\nboot.html \u0026lt;input:\u0026gt; {{{#with data}}} \u0026lt;div class=\u0026#34;control-group {{cssClass}}\u0026#34;\u0026gt; \u0026lt;label class=\u0026#34;control-label\u0026#34;\u0026gt;{{label}}\u0026lt;/label\u0026gt; \u0026lt;div class=\u0026#34;controls\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;{{type}}\u0026#34; value=\u0026#34;{{value}}\u0026#34; /\u0026gt; \u0026lt;span class=\u0026#34;help-inline\u0026#34;\u0026gt;{{message}}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {{{/}}} As you can see, I added bindings for {{cssClass}}, {{label}}, {{type}}, {{value}}, and {{message}}. Why did I use a #with block to set the scope of my object being passed in? There is a bug in the derby code right now (documented here) where you can\u0026rsquo;t reference an object\u0026rsquo;s child properties with the triple curly brackets syntax. So {{{data}}} will work, but {{{data.value}}} won\u0026rsquo;t. The object being bound to the component:\nvar data = function(value, label, type) { this.label = label; this.value = value; this.message = \u0026#34;\u0026#34;; this.cssClass = \u0026#34;\u0026#34;; this.type = type || \u0026#34;text\u0026#34;; }; And I call it in my view like this:\n\u0026lt;app👢input data=\u0026#34;{:person.firstName}\u0026#34;\u0026gt; Where firstName is an object like data described above. With just a little bit of markup and code, I have a reusable component that I can use to style my application without having to copy and paste code everywhere.\nI hope this it helps some of the fledging Derby developers out there.\n",
    "ref": "/blog/20120825-derby-js-starting-out-with-components-creating-a-twitter-bootstrap-input-component/"
  },{
    "title": "Cracking the Coding Interview - JavaScript Singly Linked List",
    "date": "",
    "description": "",
    "body": "I finished my first algorithm from Cracking the Coding Interview - the almighty Singly Linked List.\nThis is the low-hanging fruit of the data structures I mean to tackle. Even implementing this simple structure, I managed to somehow squeeze in a bug that luckily I caught in my testing. An unfortunate case of premature optimization.\nThe code doesn\u0026rsquo;t look as cool as it did, but at least it does the job. One thing I found in reading a bit about Linked Lists on wikipedia, which I had never heard of before; Hash Linking.\nThe link fields need not be physically part of the nodes. If the data records are stored in an array and referenced by their indices, the link field may be stored in a separate array with the same indices as the data records.\nAt first I thought it was a silly way to implement a linked list; if you have an array storing your values, what value are you getting from the list?\nOnce I thought a little more, I realized the value of the link field being stored in a separate array. You can easily re-order your list by changing the values in the array, without traversing and without touching your data.\nThis might be a valuable solution if the relationship between items constantly changes but the size of the data remains somewhat static. In the notes of various implementations of this pattern I\u0026rsquo;ve seen, people have commented on how they expand the array when more spots are needed.\nI have yet to see any information about if you shrink the array once the \u0026ldquo;list\u0026rdquo; contracts to a certain point. The source code for the project and the tests is here.\n",
    "ref": "/blog/20120824-cracking-the-coding-interview-javascript-singly-linked-list/"
  },{
    "title": "Derby.js - Integrating Twitter Bootstrap into your Application",
    "date": "",
    "description": "",
    "body": "As I\u0026rsquo;ve mentioned in a previous post, I\u0026rsquo;m a big fan of Twitter Bootstrap. Lately I\u0026rsquo;ve been playing been with JavaScript and Derby. I want to integrate bootstrap with the POC site I\u0026rsquo;m building, and the creators of Derby have already figured out a way to do this.\nStep 1: Add a dependency to the derby-ui-boot package, which is a Derby component library based on Twitter Bootstrap.\n{ .... \u0026#34;dependencies\u0026#34;: { \u0026#34;derby\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;derby-ui-boot\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;express\u0026#34;: \u0026#34;3.0.0beta4\u0026#34;, \u0026#34;gzippo\u0026#34;: \u0026#34;\u0026gt;=0.1.7\u0026#34; }, .... } Step 2: Update your project with the downloaded ui-boot code This is as simple as running npm update in your project folder, which will read package.json, and download any missing dependencies (like the derby-ui-boot entry you just added).\nStep 3: Add the derby-ui-boot component to your project. At the top of your application JavaScript (for me, this is the file located at /lib/app/index.js), after your var derby = require(\u0026quot;derby\u0026quot;); line, add the following line of code to your file:\nvar derby = require(\u0026#34;derby\u0026#34;); derby.use(require(\u0026#39;derby-ui-boot\u0026#39;)); Step 4: Profit! That should be it for you. When you load your application up, the default twitter bootstrap css and js should have loaded. To correctly style your application, you\u0026rsquo;ll have to follow the guidelines laid out here and here.\n",
    "ref": "/blog/20120818-derby-js-integrating-twitter-bootstrap-into-your-application/"
  },{
    "title": "Cracking the Coding Interview: JavaScript Data Structures",
    "date": "",
    "description": "",
    "body": "A friend and co-worker of mine (one of the best and brightest I\u0026rsquo;ve worked with) recently left our company to go work for Microsoft. Having gone through the Microsoft interview process myself (hilariously unprepared, to the enjoyment of my interviewer), I wondered what he had done to get ready for the process. He recommended one book - Cracking the Coding Interview - which he said had been recommended to him as the bible for preparation.\nInterested in what his holy grail had to offer, I picked up a copy. In the first couple of pages there is a chart that lists a bunch of CS staples (linked lists, trees, hash tables, stacks, queues, etc). After listing these concepts out (which every good programmer should know), it then goes on to say\nThese are concepts you have to understand and be able to implement.\nNow, being a couple of years out of college, I realized that I think I have a handle on these data structures, I haven\u0026rsquo;t implemented any of them in code in a LONG while. And I\u0026rsquo;m sure I haven\u0026rsquo;t implemented them all.\nIt sounds like a fun little project, and will give me an excuse to freshen up on my data structures. Since I\u0026rsquo;ve already done some of these a long time ago in C++, I decided this time around I\u0026rsquo;d give it a go in JavaScript. If you want to track my progress, I\u0026rsquo;ll be putting the JavaScript I write here.\n",
    "ref": "/blog/20120817-cracking-the-coding-interview-javascript-data-structures/"
  },{
    "title": "Derby.js - Working with Views, Models, and Bindings",
    "date": "",
    "description": "",
    "body": "In my previous post about derby, I talked a bit about how to create a model in derby and one rule you need to follow when creating models (the first two path segments should be an object).\nI\u0026rsquo;m creating a test application to help me learn derby here. In the process of doing absolutely everything wrong to start I\u0026rsquo;ve learned a bit about how Derby binds to models. Let\u0026rsquo;s say you\u0026rsquo;re got some markup like this that you\u0026rsquo;d like to bind to.\n\u0026lt;div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;firstName\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;lastName\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;tel\u0026#34; id=\u0026#34;phoneNumber\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;date\u0026#34; id=\u0026#34;birthDate\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Nothing sexy but you get the idea. You can post this information into a view and everything will show up the way you\u0026rsquo;d expect it to. If you want to bind this to a model, such as myApp.stuff.newGuy, changing the code is straight forward.\n\u0026lt;div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;firstName\u0026#34; value=\u0026#34;{myApp.stuff.newGuy.firstName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;lastName\u0026#34; value=\u0026#34;{myApp.stuff.newGuy.lastName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;tel\u0026#34; id=\u0026#34;phoneNumber\u0026#34; value=\u0026#34;{myApp.stuff.newGuy.phoneNumber}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;date\u0026#34; id=\u0026#34;birthDate\u0026#34; value=\u0026#34;{myApp.stuff.newGuy.birthDate}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Note that you don\u0026rsquo;t have to write any js code in your /lib/ folder to create this model. The binding [the {} information in the value attribute] will automatically wire up these fields to the myApp.stuff.newGuy model. If you want to add some default values to these fields you could accomplish this like so:\nget(\u0026#39;/\u0026#39;, function(page, model, params) { //set some default values for my model model.set(\u0026#39;myApp.stuff.newGuy\u0026#39;, { firstName: \u0026#39;John\u0026#39;, lastName: \u0026#39;Smith\u0026#39; }); //render my template containing the model above page.render(); }); When you browsed to the page you would see John in the firstName input and Smith in the lastName input. How would you render a similar collection of models? There are a couple of ways. To iterate through a collection of objects, you\u0026rsquo;ll most likely want to use the #each binding.\n{#each myApp.stuff.people} \u0026lt;div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value=\u0026#34;{.firstName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value=\u0026#34;{.lastName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;tel\u0026#34; value=\u0026#34;{.phoneNumber}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;date\u0026#34; value=\u0026#34;{.birthDate}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/} Several things to note here.\nFirst, you have to remove the id\u0026rsquo;s from the html inputs you are binding to. Each input needs to have a unique id. If you omit the id field from the markup, derby will generate a unique id for you. Otherwise you\u0026rsquo;ll be repeating the same id over and over again (and get strange behaviour as a result).\nSecond, in an #each binding you don\u0026rsquo;t use the full path to the model field you want to bind to (e.g. {myApp.stuff.people.firstName}), just the field with a dot prepended. (e.g. {.firstName}). Note that the dot is very important. If you just put {firstName} as your binding, because of the automatic model creation we noticed above, you will bind to a model called {firstName} for every item in the myApp.stuff.people collection. This will show itself by the very annoying behavior of every edit being mirrored in every row (since every row is binding to the same model).\nAnother way to do binding with #each is by using an alias. The documentation of creating an alias:\nAliases to a specific scope may be defined, enabling relative model path references within nested sections. Aliases begin with a colon (:), and can be defined at the end of a section tag with the as keyword.\nWhat would this look like?\n{#each myApp.stuff.people as :person} \u0026lt;div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value=\u0026#34;{:person.firstName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; value=\u0026#34;{:person.lastName}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;tel\u0026#34; value=\u0026#34;{:person.phoneNumber}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;date\u0026#34; value=\u0026#34;{:person.birthDate}\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {/} Note that when you declare your alias with your each statement (as :person) you have to keep the colon for your subsequent bindings ({:person.firstName})\n",
    "ref": "/blog/20120807-derby-js-working-with-view-templates-models-and-bindings/"
  },{
    "title": "HTML5 'formaction' attribute - An easy Modernizr test",
    "date": "",
    "description": "",
    "body": " EDIT NOTE: This no longer needs to be done outside of Modernizr. This was added to the Modernizr package about a month ago. Link to issue\nI\u0026rsquo;ve been writing some Html Forms, and in playing with submit buttons came across an interesting attribute in the HTML 5 specs: formaction. The definition, from HTML Living Standard Doc\nThe action and formaction content attributes, if specified, must have a value that is a valid non-empty URL potentially surrounded by spaces. The action of an element is the value of the element\u0026rsquo;s formaction attribute, if the element is a submit button and has such an attribute, or the value of its form owner\u0026rsquo;s action attribute, if it has one, or else the empty string.\nWhat does that mean? It means you can have a form on your page, and supply the formaction attribute to various `` buttons, and each button will post the same form to a different URL! Pretty neat, and has global acceptance in all browsers but one; Internet Explorer. Whoops. I really want to use this functionality, so I\u0026rsquo;ll come up with a shim to replace the functionality that IE is missing. For now, the only part of this problem I\u0026rsquo;ve solved is how to detect whether or not your browser supports this feature, via Modernizr\n// input[formaction] attribute // When used on an \u0026lt;input type=\u0026#39;submit\u0026#39;\u0026gt;, // this attribute signifies that the form containing // the input should post to the URL contained in the attribute // rather than the URL defined in the form\u0026#39;s \u0026#39;action\u0026#39; attribute. // By Matt Blair - Modernizr.addTest(\u0026#39;inputformaction\u0026#39;, \u0026#39;formAction\u0026#39; in document.createElement(\u0026#39;input\u0026#39;)); ",
    "ref": "/blog/20120801-html-input-formaction-attribute-an-easy-modernizr-test/"
  },{
    "title": "Australian vs US Coffee Terms Comparison",
    "date": "",
    "description": "",
    "body": "This took me a while to figure out when I first moved to Australia. I still remember the look on the barista\u0026rsquo;s face when I tried to order an Americano, and then the absolute puzzlement over what the hell a flat white vs a long black was. I hope this helps other visitors to Australia from the US order a decent cup of coffee!\nDescription Australian Name US Name A shot of espresso. Short Black Espresso A shot of espresso mixed with hot water. Long Black Americano A shot of espresso topped with milk froth. Macchiato -\u0026ndash; A cup of hot milk with a shot of expresso poured in. -\u0026ndash; Macchiato A shot of espresso with steamed milk. Flat White Latte No Foam A shot of espresso with steamed milk and a little milk froth. Latte Latte A shot of espresso with steamed milk, milk froth, and cocoa powder. Mocha Mocha A shot of espresso with half steamed milk, half milk froth. Cappuccino Cappuccino A shot of espresso with cold milk and ice cream. Iced Coffee -\u0026ndash; A cup of drip coffee over ice. -\u0026ndash; Iced Coffee ",
    "ref": "/blog/20120727-australian-vs-us-coffee-terms-comparison/"
  },{
    "title": "Derby.js - Playing with Models",
    "date": "",
    "description": "",
    "body": "Been playing around with Derby in my spare time. The idea behind the platform is smart - using node and express, you write one set of code, and that code automatically syncs data between browsers, servers, and a database.\nDerby is still raw. The documentation is comprehensive but puts important information about the same topic in different places.\nI\u0026rsquo;ve culled the following eight lines of documentation of defining models from the documentation:\nRacer Paths Racer paths are translated into database collections and documents using a natural mapping: collection.documentId.document All synced paths (anything that doesn’t start with an underscore) must follow this convention. In other words, all model data stored at the first two path segments should be an object and not a string, number, or other primitive type.\n** Private paths** Paths that contain a segment starting with an underscore (e.g. _showFooter or flowers.10._hovered) have a special meaning. These paths are considered “private,” and they are not synced back to the server or to other clients. Private paths are frequently used with references and for rendering purposes.\nNow, this information is useful if you\u0026rsquo;re trying out the model system for the first time. The most important line (at least for my initial playing around), was this one:\nIn other words, all model data stored at the first two path segments should be an object and not a string, number, or other primitive type.\nWhat this means: if, in creating your first model, you trying something like this: model.set('people', []); you will get an error. model.set('myApp.containers.people', []); will work just fine.\nA follow up to this post is here.\n",
    "ref": "/blog/20120722-derby-js-playing-with-models/"
  },{
    "title": "Some node.js and express.js beginner help",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;ve just started using node.js with express.js on both Windows (with iisnode) and Ubuntu.\nI love the stack (one programming language from front to back!), but some of the documentation has been frustrating for me. I wanted to document what I\u0026rsquo;ve learned so far in the hopes that it\u0026rsquo;ll help someone else down the line.\nGenerate the starter app At first, I wanted to just hack away some of the existing example apps that were out there.\nThis ended up being a pretty frustrating experience as most of the basic examples were just sending \u0026lsquo;Hello World\u0026rsquo; back to the browser. I didn\u0026rsquo;t want to do much more than that when I was starting out, but I did at least want to load a basic page with some basic information I passed in.\nAfter hours of browsing blogs and the express documentation, I managed what I wanted. Right after I did this from scratch, I found out that express can generate the basic application I wanted.\n**From the express.js documentation: ** The quickest way to get started with express is to utilize the executable express(1) to generate an application as shown below:\nCreate the app: $ npm install -g express $ express /tmp/foo \u0026amp;\u0026amp; cd /tmp/foo\nInstall dependencies: $ npm install -d\nStart the server: $ node app.js But what does \u0026ldquo;generate an app\u0026rdquo; mean? When I first read those lines, I skipped right past this step, as I though I already had express and its dependencies setup correctly.\nThese commands create the basic structure of a web app (with all the basic files, folders, and dependencies installed).\nLet\u0026rsquo;s walk the commands to get a better idea what each of them does\nThe installation commands, explained npm install -g express NPM, or the Node Package Manager, is a tool that comes with node that allows your install node packages quickly and easily from the command line. This command installs express, the popular MVC-ish framework for node.\nexpress /tmp/foo \u0026amp;\u0026amp; cd /tmp/foo This line of code installs express into /tmp/foo, then changes the directory to /tmp/foo. You can also run this command from the folder you want to install express in (just run express from the command line). You can also specify some options when you generate your starter app, such as the templating and stylesheet language you want to use.\nexpress -t jade -c stylus This command tells express you want to install in the current directory, using Jade as your template language, and Stylus as your stylesheet language.\nnpm install -d This command installs any dependencies that express needs for the instance you have installed. Express has a couple js packages that it needs to run, so this command goes and downloads the latest version of these dependencies.\nWhat \u0026ldquo;Generate An App\u0026rdquo; Gives You node_modules This folder contains all the js dependencies (like express, stylus, jade, etc) that you need to run express on node.\npublic This is where your static files go (by default). By default, this folder contains three sub-folders: 1. images 2. javascripts 3. stylesheets\nroutes This is where your routing logic goes. Initially this contains one route (to your example view).\nviews This folder is the default location for the views you\u0026rsquo;ll use in your application. Views usually contain dynamic content and are often written in a templating language.\nThe last thing that\u0026rsquo;s generated is app.js, which contains a good sample of configuration code as well as the only route your example route contains:\nvar express = require('express') , routes = require('./routes'); ... app.get('/', routes.index); If you jump into the routes folder, and open index.js, you\u0026rsquo;ll see your index route:\nexports.index = function(req, res) { res.render('index', { title: 'Express' }) };\nBut what does this code mean? The first line of code defines two variables, express and routes.\nThe first is a registered node module, express, and the second is just a js file.\nLater in app.js, the line app.get tells node that when the base Url of your application (something like http://localhost:3123/) is called in a browser, that the routes.index method should be called.\nBut how does routes variable in the first file get the index method, when in index.js in the routes folder only defines the index function on something calls exports?\nTo keep the system loosely coupled, node uses something called the CommonJS module format to inject dependencies into an application. One way to do this is create a function you want to be able to export to the rest of your application, then simply add your function to the exports object in your code. When you call require(PATH_TO_YOUR_FILE), any methods you added to exports will be added to the object returned by your call to require.\nThe final code is the call to res.render. This is a call to express, which is telling express to load the file \u0026lsquo;index.jade\u0026rsquo; (because in this instance, jade is the default render engine). The second parameter is a JavaScript object containing one element, title. This object is passed to the index.jade template to be rendered.\n",
    "ref": "/blog/20120710-some-node-js-and-express-js-beginner-help/"
  },{
    "title": "Using StructureMap to collect and use all instances of a given type",
    "date": "",
    "description": "",
    "body": "Had an issue at work where I wanted to store my rules and handlers for a class outside of the class definition, so I could better test the component. Found an easy way to add all your rules into StructureMap, and then retrieve those rules as a list via constructor injection.\nusing System.Collections.Generic; using System.Linq; using System.Text; using StructureMap; using StructureMap.Configuration.DSL; public class TravelRegistry : Registry { public TravelRegistry() { For\u0026lt;ITransportHandler\u0026gt;().Add\u0026lt;ApprovedAccommodationHandler\u0026gt;(); For\u0026lt;ITransportHandler\u0026gt;().Add\u0026lt;ApprovedCharterFlightHandler\u0026gt;(); For\u0026lt;ITransportHandler\u0026gt;().Add\u0026lt;ApprovedCommercialFlightHandler\u0026gt;(); For\u0026lt;ITransportHandler\u0026gt;().Add\u0026lt;ApprovedGroundTransportHandler\u0026gt;(); For\u0026lt;IEnumerable\u0026lt;ITransportHandler\u0026gt;\u0026gt;().Use(x =\u0026gt; x.GetAllInstances\u0026lt;ITransportHandler\u0026gt;()); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;StartLessThanEndRule\u0026gt;(); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;CurrentEndsAfterPreviousRule\u0026gt;(); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;CurrentStartAfterPreviousEndRule\u0026gt;(); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;UniqueEndsRule\u0026gt;(); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;UniqueStartAndEndRule\u0026gt;(); For\u0026lt;ITravelRule\u0026gt;().Add\u0026lt;UniqueStartsRule\u0026gt;(); For\u0026lt;IEnumerable\u0026lt;ITravelRule\u0026gt;\u0026gt;().Use(x =\u0026gt; x.GetAllInstances\u0026lt;ITravelRule\u0026gt;()); } } ",
    "ref": "/blog/20120618-using-structuremap-to-collect-and-use-all-instances-of-a-given-type/"
  },{
    "title": "Why use Twitter Bootstrap?",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;m a fan of Twitter Bootstrap, the simple and flexible CSS, HTML, and JavaScript user interface framework.\nWhat\u0026rsquo;s not to like? Out of the box, you\u0026rsquo;ll get:\nCross-Platform Support IE 7 to IPhone and everything else (sorry IE6)\n12-Column Grid A good grid system takes most of the pain out of laying out your site. Getting labels, inputs, and other pieces of your ui to layout consistently across different browsers at different resolutions can be one of the most painful parts of web development.\nSave yourself the work of trying to figure this stuff out on your own. The twitter kids have it under control.\nResponsive design One of my favorite parts. If you craft your css/html a certain way, as the size of your browser changes (you can see this just by resizing the browser on your desktop), the layout adapts to display the information in a consistent manner as the screen size drops.\nViewing on a tablet and want to hide a left nav bar? No problem. Viewing on a phone and want to hide the menu bar? Too easy.\nBaked In Best Practices Basically, if you want to get anything out of Bootstrap, you\u0026rsquo;ll have to adhere to their best practices. Following someone\u0026rsquo;s best practices is better than just hacking away at your CSS.\njQuery Plugins Great interactive components, built on everyone\u0026rsquo;s favorite JS framework, that look and interactive fantastically with the rest of Bootstrap.\nLESS Infrastructure I am a proponent of LESS/SASS/Stylus etc. If you\u0026rsquo;ve never used one, they allow you to do all sort of great software developy things with your CSS. Like set variables in one place for all the colors and sizes used by your app. Or re-use common styles without copy and paste. Or display certain styles if certain conditions are met.\nWhat are you waiting for? Check out some of the docs here and here to get started.\n",
    "ref": "/blog/20120504-why-use-twitter-bootstrap/"
  },{
    "title": "Posting an IEnumerable of Interfaces back from your Views by extending the DefaultModelBinder",
    "date": "",
    "description": "",
    "body": " Please note I came across a bug in the code, and revised this post on 31/07/2012.\nCame across an interesting problem today. In ASP.Net MVC, you can easily pass an enumerable of interfaces to your views from your controllers. As long as you have DisplayTemplates and EditorTemplates defined for the subclasses, then those classes will be rendered correctly from your enumerable of the parent interfaces.\nHowever, if you then POST to a controller method that accepts an IEnumerable, you\u0026rsquo;ll get the error message:\nCannot create an instance of an Interface\nIn looking for a solution, I found some examples online that handled abstract classes. Unfortunately, none of those examples had a way to post data back without modifying the views, and I couldn\u0026rsquo;t figure out a way either.\nHere is my solution:\nModify your EditorTemplates to use the Type extension method defined below. This will write a hidden field to the view that defines the class being used. Example: @Html.Type(Model)\nRegister the SectionModelBinder below in Global.asax. Example: ModelBinders.Binders.DefaultBinder = new SectionModelBinder();\nThat\u0026rsquo;s it! You should be on your way to POSTing a generic list of different subclasses to a controller method. using System; using System.Collections; using System.Collections.Generic; using System.Linq; using System.Web.Mvc; namespace ProofOfConcept { public class SectionModelBinder : DefaultModelBinder { public const string ModelTypeNameKey = \u0026#34;ModelTypeName\u0026#34;; ///\u0026lt;summary\u0026gt; /// Creates the model. /// \u0026lt;/summary\u0026gt; /// The controller context. /// The binding context. /// Type of the base. /// The instantiated model /// /// You must create a hidden field named \u0026#39;ModelTypeName\u0026#39; on the View, /// where the value is the Full name of the class you are trying to create. /// The HtmlHelper extension method \u0026#39;Type\u0026#39; was designed to create this field /// and hide the implementation details. /// /// Currently the model you trying to create must inherit from a base class /// that is the same assembly. /// protected override object CreateModel(ControllerContext controllerContext, ModelBindingContext bindingContext, Type baseType) { if (baseType.IsInterface \u0026amp;\u0026amp; (baseType != typeof(IEnumerable)) \u0026amp;\u0026amp; !baseType.GetInterfaces().Any(t =\u0026gt; t == typeof(IEnumerable)) \u0026amp;\u0026amp; !(baseType.IsGenericType \u0026amp;\u0026amp; baseType.GetGenericTypeDefinition() == typeof(IEnumerable))) { var modelTypeValue = bindingContext.ValueProvider.GetValue(bindingContext.ModelName + \u0026#34;.\u0026#34; + ModelTypeNameKey); if (modelTypeValue == null) throw new Exception(\u0026#34;View does not contain \u0026#34; + bindingContext.ModelName + \u0026#34;.\u0026#34; + ModelTypeNameKey + \u0026#34; field.\u0026#34;); var subclassName = modelTypeValue.AttemptedValue; if(string.IsNullOrWhiteSpace(subclassName )) throw new Exception(\u0026#34;View for \u0026#34; + bindingContext.ModelName + \u0026#34; does not have a value set for the \u0026#34; + ModelTypeNameKey + \u0026#34; field.\u0026#34;); var subclassType = baseType.Assembly.GetTypes().SingleOrDefault(x =\u0026gt; (x.FullName == subclassName)); var model = CreateInstance(baseType, subclassType, subclassName); if (model != null) { bindingContext.ModelMetadata = ModelMetadataProviders.Current.GetMetadataForType(() =\u0026gt; model, subclassType); } return model; } return base.CreateModel(controllerContext, bindingContext, baseType); } protected virtual object CreateInstance(Type baseType, Type subclassType, string subclassName) { if (subclassName == null) throw new ArgumentNullException(\u0026#34;subclassName\u0026#34;); if (subclassType == null) throw new Exception(\u0026#34;Could not find model \u0026#34; + subclassName); if (!subclassType.GetInterfaces().Any(t =\u0026gt; t == baseType)) throw new Exception(\u0026#34;The model of type \u0026#34; + subclassName + \u0026#34; does not implement \u0026#34; + baseType.FullName); return Activator.CreateInstance(subclassType); } } } namespace System.Web.Mvc.Html { public static class HtmlHelperExtension { public static MvcHtmlString Type(this HtmlHelper htmlHelper, object value) { if (htmlHelper == null) throw new ArgumentNullException(\u0026#34;htmlHelper\u0026#34;); if (value == null) throw new ArgumentNullException(\u0026#34;value\u0026#34;); return htmlHelper.Hidden(SectionModelBinder.ModelTypeNameKey, value.GetType().FullName); } } } ",
    "ref": "/blog/20120426-posting-an-ienumerable-of-interfaces-back-from-your-views-by-extending-the-defaultmodelbinder/"
  },{
    "title": "Horrible, Slow, Stupid, Scary Build Process",
    "date": "",
    "description": "",
    "body": "So we\u0026rsquo;ve rolled out a new build process at work. I\u0026rsquo;ve started working with a new company, and when I arrived, the build process for a new environment consisted of a 20 page manual somebody had written. The process of putting a build on an environment was slow, the manual had steps missing that everyone just \u0026lsquo;knew\u0026rsquo;, the process had multiple failure points, and was more or less a complete disaster. Every other release to PRODUCTION would have some release process error that would force devs to spend all night at work on release night, sometimes having to come in during the weekend as well.\nUsing the manual deploy to production, it took me four hours to deploy our code. I made a small mistake along the way, and it took two hours to recover.\nWith the latest release to production, we used the first iteration of a new release process. We automated the whole process, taking no more than three manual steps. While not the one step recommended in The Joel Test, a noticeable improvement and an increase in productively and reliability.\nFrom start to finish, the new process takes about a half hour. Much shorter than the manual process.\nWhy am I writing about this? Today we had a meeting about the new release process. Assigned to the next release to production was one of my co-workers, who has been with this company for a while. They made the following comment:\n\u0026ldquo;The old build process was horrible, slow, stupid and scary, but at least I knew it.\u0026rdquo;\nAnd was serious. I guess I don\u0026rsquo;t have to wonder anymore why no one had fixed the build process earlier.\n",
    "ref": "/blog/20120303-horrible-slow-stupid-scary-build-process/"
  },{
    "title": "Windows 7 - Problem Steps Recorder",
    "date": "",
    "description": "",
    "body": "Just found out about a good tool that ships with Windows 7.\nOne of the hardest things about debugging software can be getting the users to document what went wrong so you can test the scenario. Problem Steps Recorder - which ships with Windows 7 - records a user\u0026rsquo;s actions and documents them in an easy to understand format. It even gives the user the option of sending the recording via e-mail right from the program.\nProblem Steps Recorder takes screen shots and records input, timings, comments, app versions. It outputs them in a zipped web package. Pretty cool for recording steps to reproduce a bug! To use: start \u0026gt; run \u0026gt; psr\n",
    "ref": "/blog/20120216-windows-7-problem-steps-recorder/"
  },{
    "title": "Setting up a .NET build server WITHOUT installing Visual Studio",
    "date": "",
    "description": "",
    "body": "My client tasked me with upgrading their build server. Today, their platform builds VS 2080 solutions in .NET 3.5 - and I\u0026rsquo;ve been pushing to upgrade everyone to Visual Studio (VS) 2010 and eventually .NET 4.0. I want to upgrade the server to build a VS 2010 solution in .NET 3.5.\nThis will allow everyone to upgrade to VS 2010 while leaving the task of upgrading the production web servers to another day. I tried the easy approach. I install .NET 4.0 on the build server and run the MSBuild scripts that already exist. Nothing good happens.\nI do a little digging and find out that you need to install the Windows SDK to get MSBuild to work. I get the Windows SDK - Microsoft Windows SDK for Windows 7 and .NET Framework 4 - and install it. Nothing good happens.\nI dig a little further and find out that by default MSBuild installs pointing at the VS version of the Windows SDK whether it is there or not. Also, the Windows SDK does not care about the settings of MSBuild, so when you install the SDK it doesn\u0026rsquo;t fix this or update this. Which I understand from the SDK team\u0026rsquo;s point of view, but it would have been a nice fix.\nThe important thing to note is the keys which have \u0026ldquo;7.0a\u0026rdquo; in their values. 7.0a is the version of the Windows SDK that ships with Visual Studio 2010. If you download the SDK from Microsoft you get version 7.1. I go in and manually change all those 7.0a to 7.1. It builds! But it fails.\nFor some reason, I can\u0026rsquo;t get any of the XmlSerializers dll (web projects that have web services or WCF need these) to generate correctly. The normal dll\u0026rsquo;s compile into .NET 3.5 versions (which is what I want), but the XmlSerializers dlls all generate in .NET 4.0. What\u0026rsquo;s going on here? Another bug.\nThe Windows SDK installer, by default, installs the WRONG keys into the registry. This apparently only affects certain edge cases, like trying to generate XmlSerializer dll\u0026rsquo;s with MSBuild from .NET 4.0 into .NET 3.5. I\u0026rsquo;m guessing the Visual Studio installer fixes this when it runs. The issue is documented here: Windows 7.1 SDK targeting .NET 3.5 generates wrong embedded Resources.\nSo, another trip to the registry. This time, to the Microsoft-SDKS section. There are two bugs here:\nAll the keys need to have a dash after the \u0026ldquo;WinSDK\u0026rdquo; portion Some of the fields have an \u0026ldquo;-86\u0026rdquo; in their key, which needs to be \u0026ldquo;-x86\u0026rdquo; One more try. Build successful. :)\nValuable Old Comment Note: Antek: Unfortunately the changes in the MsBuild/ToolVersions/4.0 section can (and will) be lost when .NET patches are applied through Windows Update.\n",
    "ref": "/blog/20111031-setting-up-a-net-build-server-without-installing-visual-studio/"
  },{
    "title": "Enable/Disable jQuery buttons in Knockout with a Custom Binding Handler",
    "date": "",
    "description": "",
    "body": "Still working on those jQuery buttons. Trying to update old ASP.Net Webforms using jQuery, Knockout, and Amplify.\nNew problem today.\nI was having problems getting Knockout to enable/disable my jQuery buttons using the Knockout \u0026rsquo;enable\u0026rsquo; bindingHandler. It would enable/disable the underlying element that I had run the .button() method on, but it had no idea about the div that jQuery had wrapped my element in, or how to handle it.\nI wrote a custom bindingHandler for Knockout to handle this case. It also can handle non-jQuery elements as well, so you could change the declaration from \u0026lsquo;jEnable\u0026rsquo; to \u0026rsquo;enable\u0026rsquo;, and this would work as a all-comers enable function.\nSince this method uses jQuery (and is more expensive than the plain old \u0026rsquo;enable\u0026rsquo;), I figured the extra binding was the best approach.\nif (ko \u0026amp;\u0026amp; ko.bindingHandlers) { ko.bindingHandlers[\u0026#39;jEnable\u0026#39;] = { \u0026#39;update\u0026#39;: function(element, valueAccessor) { var value = ko.utils.unwrapObservable(valueAccessor()); var $element = $(element); $element.prop(\u0026#34;disabled\u0026#34;, !value); if ($element.hasClass(\u0026#34;ui-button\u0026#34;)) { $element.button(\u0026#34;option\u0026#34;, \u0026#34;disabled\u0026#34;, !value); } } }; } An example on how to use this:\n\u0026lt;input id=\u0026#34;btnToEnable\u0026#34; type=\u0026#34;button\u0026#34; data-bind=\u0026#34;jEnable: isEnabled\u0026#34; /\u0026gt; \u0026lt;script\u0026gt; $(\u0026#34;#btnToEnable\u0026#34;).button(); var viewModel = { isEnabled: ko.observable(true) }; ko.applyBindings(viewModel); \u0026lt;/script\u0026gt; A gist of this code is here.\n",
    "ref": "/blog/20111021-enabledisable-jquery-buttons-in-knockout-with-a-custom-binding-handler/"
  },{
    "title": "Auto Creation of jQuery Buttons using Knockout Templates",
    "date": "",
    "description": "",
    "body": "While converting ASP.NET Webforms to be more clienty using HTML 5, Knockout, and jQuery, I came across a problem.\nI want to use jQuery buttons on my Knockout-rendered rows, but whenever a new row gets added via a template, the buttons were not created as jQuery buttons. The issue was that I was calling a method to create the buttons after the page was fully rendered but never again. All the new rows wouldn\u0026rsquo;t have the .button method run on them, and thus no sparkly jQuery buttons.\nWhat to do? I\u0026rsquo;ve got button markup that looks like this:\n\u0026lt;div class=\u0026#34;jButton\u0026#34; data-icon-name=\u0026#34;refresh\u0026#34; data-bind=\u0026#34;click: refresh\u0026#34;\u0026gt; Refresh \u0026lt;/div\u0026gt; And some existing code, that given an element with class \u0026ldquo;jButton\u0026rdquo; and optionally the data-icon-name set the icon you want, creates buttons out of divs. I saw one person handle this via a new binding on the button, but I didn\u0026rsquo;t want to have to change to my existing template to get the behavior I was looking at.\nI tried a couple of different options, and while looking through the Knockout examples for other options came across the afterAdd option in the template binding. A quick change to my template binding:\n\u0026lt;tbody data-bind=\u0026#34;template: {name:\u0026#39;rowCostItem\u0026#39;, foreach: CostItems, afterAdd: function(elem) { var row = $(elem); Buttons.createFrom(row); }}\u0026#34;\u0026gt; Now I get nice jQuery buttons for all my new rows. P.S. The heart of the Buttons.createFrom() method:\nvar btn = $(this); var iconName = btn.data(\u0026#34;iconName\u0026#34;); if (iconName) { btn.button({ icons: { primary: \u0026#39;ui-icon-\u0026#39; + iconName} }); } else { btn.button(); } ",
    "ref": "/blog/20111019-auto-creation-of-jquery-buttons-using-knockout-templates/"
  },{
    "title": "Alas, it was not to be",
    "date": "",
    "description": "",
    "body": "My jQuery bug was already documented. :(\n",
    "ref": "/blog/20111014-alas-it-was-not-to-be/"
  },{
    "title": "Finished the Nike+ Importer for www.runningahead.com",
    "date": "",
    "description": "",
    "body": "I finished up the Nike+ data importer for www.runningahead.com. You can check out the code for the importer at this Github repository:\nhttps://github.com/duereg/NikePlusImporter\nI got a small test project up for this. It walks through everything but doesn\u0026rsquo;t Mock up the calls to the Nike+ service (I couldn\u0026rsquo;t be bothered). Let me know what you think.\n",
    "ref": "/blog/20111010-finished-the-nike-importer-for-www-runningahead-com/"
  },{
    "title": "jQuery UI Bug - 1.8.16, buttonset() method",
    "date": "",
    "description": "",
    "body": "I love to find bugs in good software! Came across a little jQuery UI bug today. It\u0026rsquo;s for one browser, but it always excited to be able to create an easy-to-replicate bug. The bug is small - it deals with the buttonset() method.\nThe buttons, instead of having the rounded corners on the outside, have the rounded corners on the inside. Not critical but it made the UI I was working on look strange. If you have Chrome, and are dealing with jQuery 1.6.3 and jQuery UI 1.8.16, check out the bug here:\nhttp://jsfiddle.net/AJbff/14/\n",
    "ref": "/blog/20111006-jquery-ui-bug-1-8-16-buttonset-method/"
  },{
    "title": "Beautiful LINQ to Xml",
    "date": "",
    "description": "",
    "body": "Is there anything better in life than finding a better way to do something? An easier commute, a better night\u0026rsquo;s sleep, a tastier cake recipe? In starting the Nike+ importer for www.runningahead.com, I knew I was going to have to deal with a bit of XML. Which used to mean XPath. Not so much anymore. LINQ to XML, you rock my world. It turns XML like this\u0026hellip;\n\u0026lt;extendedDataList\u0026gt; \u0026lt;extendedData dataType=\u0026#34;distance\u0026#34; intervalType=\u0026#34;time\u0026#34; intervalUnit=\u0026#34;s\u0026#34; intervalValue=\u0026#34;10\u0026#34;\u0026gt; 0.0, 0.0372, 0.0705, 0.1041, .... \u0026lt;/extendedData\u0026gt; \u0026lt;extendedData dataType=\u0026#34;speed\u0026#34; intervalType=\u0026#34;time\u0026#34; intervalUnit=\u0026#34;s\u0026#34; intervalValue=\u0026#34;10\u0026#34;\u0026gt; 0.0, 13.3866, 12.6856, 12.4970, .... \u0026lt;/extendedData\u0026gt; \u0026lt;extendedData dataType=\u0026#34;heartRate\u0026#34; intervalType=\u0026#34;time\u0026#34; intervalUnit=\u0026#34;s\u0026#34; intervalValue=\u0026#34;10\u0026#34;\u0026gt; 0, 88, 108, 115, .... \u0026lt;/extendedData\u0026gt; \u0026lt;/extendedDataList\u0026gt; With a little bit of code like this:\nwork.Snapshots = from n in extendedData.Elements(\u0026#34;extendedData\u0026#34;) select new Workout.SnapShot { DataType = n.Attribute(\u0026#34;dataType\u0026#34;).Value, Interval = (int) n.Attribute(\u0026#34;intervalValue\u0026#34;), IntervalType = n.Attribute(\u0026#34;intervalType\u0026#34;).Value, IntervalUnit = n.Attribute(\u0026#34;intervalUnit\u0026#34;).Value, Intervals = n.Value.Split(\u0026#39;,\u0026#39;).Select(p =\u0026gt; Convert.ToSingle(p.Trim())) }; into something useful. The best part - no more XPath string literals in your code. 2nd best part - that (int) cast. That isn\u0026rsquo;t really a cast - it\u0026rsquo;s actually an indirect call to Convert.ToInt32. It parses the underlying value contained in the Attribute (or Element), then converts it into the correct type. That\u0026rsquo;s the kind of coding magic I like.\n",
    "ref": "/blog/20110924-beautiful-linq-to-xml/"
  },{
    "title": "About Me",
    "date": "",
    "description": "",
    "body": "My name is Matt Blair. Born in Virginia and now in the Bay Area. I write code during the day, play underwater hockey when I get a chance, and do other things occasionally.\nI\u0026rsquo;m the author of libraries such as songbird, js-algorithms, esvalidate, grunt-extract-sourcemap, and laboratory.\nI\u0026rsquo;m a mediocre presenter at meetups and conferences.\nYou can read about my management style here.\nI\u0026rsquo;ve contributed to projects such as emberjs, ember-data, browserify-middleware, fluentmigrator, amplify, and cassette. I help maintain write-good.\nI\u0026rsquo;ve also the author of the semi-decent sublime plugin sublime-jsvalidate and the partially worthwhile sublime-write-gooder.\nWhy a blog?\nI want to keep learning. I like to try new technologies. I am a imperfect individual. I make more than my share of mistakes. As I learn from them, I hope others out there can as well.\nI read that you learn more from a poor example than from a correct one. I don\u0026rsquo;t believe this but that means my site will be a success.\n",
    "ref": "/about/"
  },{
    "title": "Working on Nike+ Importer for RunningAhead.com",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;m a fan of the website www.runningahead.com. I use it to track all my sporting life activities. The primary reason I use this site, instead of one of the hundreds like it, is that you can track anything - yoga, rowing, running, P-90x, underwater hockey, tiddlywinks, whatever. Throw in some customizable reporting and some great hardware integration, and it\u0026rsquo;s free, and you\u0026rsquo;ve got a winner.\nThat doesn\u0026rsquo;t mean there aren\u0026rsquo;t things I don\u0026rsquo;t like about the site, and things I wish could be better. But since it\u0026rsquo;s a free site, I\u0026rsquo;d like to help out and make the site better. I\u0026rsquo;ve talked to the site\u0026rsquo;s creator (Eric Yee) and volunteered to help craft some plugins for the site for him.\nFirst up: a Nike+ data importer. I will write the importer in C#, calling some RESTful web services, parsing XML, etc etc.\n",
    "ref": "/blog/20110921-working-on-nike-importer-for-runningahead-com/"
  },{
    "title": "",
    "date": "",
    "description": "",
    "body": "title = \u0026#34;Introducing Songbird\u0026#34; description = \u0026#34;How to have promises everywhere, all the time\u0026#34; date = 2014-02-09 post_name = \u0026#34;introducing-songbird\u0026#34; status = \u0026#34;publish\u0026#34; tags = [\u0026#34;development\u0026#34;,\u0026#34;software\u0026#34;,\u0026#34;coding\u0026#34;,\u0026#34;web\u0026#34;,\u0026#34;html\u0026#34;,\u0026#34;JavaScript\u0026#34;,\u0026#34;CoffeeScript\u0026#34;,\u0026#34;EMCAScript\u0026#34;,\u0026#34;Songbird\u0026#34;,\u0026#34;Bluebird\u0026#34;,\u0026#34;Promises\u0026#34;,\u0026#34;Generators\u0026#34;,\u0026#34;EMCAScript\u0026#34;] categories = [\u0026#34;engineering\u0026#34;, \u0026#34;technical\u0026#34;, \u0026#34;javascript\u0026#34;] layout = \u0026#34;post\u0026#34; +++ Would you rather write this: ```javascript var updateUser = function(id, attributes, callback) { User.findOne(id, function (err, user) { if (err) return callback(err); user.set(attributes); user.save(function(err, updated) { if (err) return callback(err); console.log(\u0026#34;Updated\u0026#34;, updated); callback(null, updated); }); }); }); +++ Or this: ```coffeescript User.promise.findOne(id).then( (user) → user.set(attributes) user.promise.save() ).then (user) -\u0026gt; console.log(\u0026#34;Updated\u0026#34;, user) Songbird allows you to easily mix asynchronous and synchronous programming styles in node.js.\nI based Songbird on the bluebird promise library (hence the name).\nInstall Songbird requires node version 0.6.x or greater.\nnpm install songbird Examples Without Songbird Using standard node callback-style APIs without Songbird, we write (from the fs docs):\nfs.readFile(\u0026#39;/etc/passwd\u0026#39;, function (err, data) { if (err) throw err; console.log(data); }); Using the promise property Using Songbird, we write:\nfs.promise.readFile(\u0026#39;/etc/passwd\u0026#39;).then(console.log); Object \u0026amp; Function mixins Songbird mixes promise into Function.prototype so you can use them directly as in:\nreadFile = require(\u0026#39;fs\u0026#39;).readFile; readFile.promise(\u0026#39;/etc/passwd\u0026#39;).then(console.log); Songbird adds promise to Object.prototype correctly so they are not enumerable.\nThese proxy methods also ignore all getters, even those that may return functions. If you need to call a getter with Songbird that returns an asynchronous function, you can do:\nfunc = obj.getter func.promise.call(obj, args) Handling Multiple Promises Requiring the songbird library updates the Object and Function prototype and returns a Promise library. This library allows you to carry out certain actions that are hard to handle from the promise property.\nFor example: You\u0026rsquo;re dealing with multiple promises but don\u0026rsquo;t care what order they complete in.\nPromise = require(\u0026#34;songbird\u0026#34;); Promise.all([task1, task2, task3]).spread(function(result1, result2, result3){ }); Normally when using .then the code would look like:\nPromise = require(\u0026#34;songbird\u0026#34;); Promise.all([task1, task2, task3]).then(function(results){ var result1 = results[0]; var result2 = results[1]; var result3 = results[2]; }); For more information about the underlying bluebird promise API, the API docs are here.\nDisclaimer Some people don\u0026rsquo;t like libraries that mix in to Object.prototype and Function.prototype. If that\u0026rsquo;s how you feel, then Songbird is not for you.\nContributing git clone git://github.com/duereg/songbird.git npm install npm test Songbird is written in CoffeeScript with source in src/ compiled to lib/.\nTests are written with mocha and chai in test/.\nRun tests with npm test which will also compile the CoffeeScript to lib/.\nPull requests are welcome. Please provide tests for your changes and features. Thanks!\n",
    "ref": "/blog/20140209-introducing-songbird/"
  },{
    "title": "Contact",
    "date": "",
    "description": "",
    "body": "\n{{ .Render \"content-list\" }}\n",
    "ref": "/contact/"
  }]
